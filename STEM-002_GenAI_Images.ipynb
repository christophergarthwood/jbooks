{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg3iJooMQjWA"
      },
      "source": [
        "# Artificial Intelligence\n",
        "## Image Generator\n",
        "\n",
        "OpenAI Dall-E (and others) are text-to-image models developed by OpenAI using deep learning methodologies to generate digital images from natural language descriptions, called \"prompts\".\n",
        "\n",
        "Reference:\n",
        "\n",
        "+ https://gemini.google.com/app\n",
        "+ https://openai.com/index/dall-e-2/\n",
        "+ https://cloud.google.com/vertex-ai/generative-ai/docs/image/img-gen-prompt-guide\n",
        "+ https://tech.co/news/use-google-bard-ai-image-generator\n",
        "+ https://builtin.com/artificial-intelligence/prompt-engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jljx58WFBpXo",
        "tags": []
      },
      "outputs": [],
      "source": [
        "BUCKET_NAME =\"cio-training-vertex-colab\"\n",
        "PROJECT_ID  =\"usfs-ai-bootcamp\"\n",
        "LOCATION    = \"us-central1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zramkw-P93C-"
      },
      "source": [
        "## Environment Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shY7a4DVQjWB",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "#- Google Colab Check\n",
        "# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "import datetime\n",
        "\n",
        "RunningInCOLAB = False\n",
        "RunningInCOLAB = 'google.colab' in str(get_ipython())\n",
        "current_time   = datetime.datetime.now()\n",
        "\n",
        "if RunningInCOLAB:\n",
        "    print(f\"You are running this notebook in Google Colab at {current_time} in the {PROJECT_ID} lab.\")\n",
        "else:\n",
        "    print(f\"You are likely running this notebook with Jupyter iPython runtime at {current_time} in the {PROJECT_ID} lab.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5kZDFBsXcoq"
      },
      "source": [
        "# GCP Gemini Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsDkV2olXfGJ"
      },
      "outputs": [],
      "source": [
        "#Download Google Vextex/AI Libraries\n",
        "subprocess.run([\"pip\", \"install\" , \"--upgrade\", \"google-cloud-aiplatform\", \"--quiet\"])\n",
        "\n",
        "\n",
        "libraries=[\"google-generativeai\", \"google-cloud-secret-manager\", \"openai\"]\n",
        "\n",
        "for library in libraries:\n",
        "    spec = importlib.util.find_spec(library)\n",
        "    if spec is None:\n",
        "      print(\"Installing library \" + library)\n",
        "      subprocess.run([\"pip\", \"install\" , library, \"--quiet\"])\n",
        "    else:\n",
        "      print(\"Library \" + library + \" already installed.\")\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "import vertexai.preview\n",
        "from google.cloud import secretmanager\n",
        "import vertexai\n",
        "import openai\n",
        "from google.auth import default, transport"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO_Hq5eq9joH"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJuXEPlkSo9p",
        "tags": []
      },
      "outputs": [],
      "source": [
        "############################################\n",
        "# INCLUDES\n",
        "############################################\n",
        "#libraries specific to this example\n",
        "## Imports\n",
        "#import tensorflow as tf\n",
        "#from tensorflow import keras\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "#a set of libraries that perhaps should always be in Python source\n",
        "import os\n",
        "import datetime\n",
        "import sys\n",
        "import gc\n",
        "import getopt\n",
        "import inspect\n",
        "import math\n",
        "import warnings\n",
        "import textwrap\n",
        "import random\n",
        "import glob\n",
        "import os\n",
        "import PIL\n",
        "import time\n",
        "import subprocess\n",
        "\n",
        "#images\n",
        "import imageio\n",
        "import matplotlib as matplt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#data science\n",
        "import numpy as np\n",
        "\n",
        "#a darn useful library for creating paths and one I recommend you load to your environment\n",
        "from pathlib import Path\n",
        "\n",
        "from pydoc import help                          # can type in the python console `help(name of function)` to get the documentation\n",
        "\n",
        "warnings.filterwarnings('ignore')               # don't print out warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9gpU3zJ9l9H"
      },
      "source": [
        "## Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoQDWB9s9n7H",
        "tags": []
      },
      "outputs": [],
      "source": [
        "############################################\n",
        "# GLOBAL VARIABLES\n",
        "############################################\n",
        "DEBUG = 1\n",
        "DEBUG_DATA = 0\n",
        "\n",
        "# CODE CONSTRAINTS\n",
        "VERSION_NAME    = \"MLGENIMG\"\n",
        "VERSION_MAJOR   = 0\n",
        "VERSION_MINOR   = 0\n",
        "VERSION_RELEASE = 1\n",
        "\n",
        "#used for values outside standard ASCII, just do it, you'll need it\n",
        "ENCODING  =\"utf-8\"\n",
        "\n",
        "############################################\n",
        "# GLOBAL CONSTANTS\n",
        "############################################\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256\n",
        "TEXT_WIDTH=77\n",
        "############################################\n",
        "# APPLICATION VARIABLES\n",
        "############################################\n",
        "start = \"\\033[1m\"\n",
        "end = \"\\033[0;0m\"\n",
        "\n",
        "############################################\n",
        "# GLOBAL CONFIGURATION\n",
        "############################################\n",
        "os.environ['PYTHONIOENCODING']=ENCODING\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FUa8QJT9tw_"
      },
      "source": [
        "## Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_CqUVLZ98Mz",
        "tags": []
      },
      "outputs": [],
      "source": [
        "## Outputs library version history of effort.\n",
        "#\n",
        "def lib_diagnostics() -> None:\n",
        "\n",
        "    import pkg_resources\n",
        "\n",
        "    package_name_length=40\n",
        "    package_version_length=20\n",
        "\n",
        "    # Get installed packages\n",
        "    the_packages=[\"nltk\", \"numpy\", \"os\", \"pandas\"]\n",
        "    installed = {pkg.key: pkg.version for pkg in pkg_resources.working_set}\n",
        "    for package_idx, package_name in enumerate(installed):\n",
        "         if package_name in the_packages:\n",
        "             installed_version = installed[package_name]\n",
        "             print(f\"{package_name:<40}#: {str(pkg_resources.parse_version(installed_version)):<20}\")\n",
        "\n",
        "    try:\n",
        "        print(f\"{'OpenAI version':<40}#: {str(openai.__version__):<20}\")\n",
        "    except Exception as e:\n",
        "        pass\n",
        "\n",
        "\n",
        "    try:\n",
        "        print(f\"{'TensorFlow version':<40}#: {str(tf.__version__):<20}\")\n",
        "        print(f\"{'     gpu.count:':<40}#: {str(len(tf.config.experimental.list_physical_devices('GPU')))}\")\n",
        "        print(f\"{'     cpu.count:':<40}#: {str(len(tf.config.experimental.list_physical_devices('CPU')))}\")\n",
        "    except Exception as e:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        print(f\"{'Torch version':<40}#: {str(torch.__version__):<20}\")\n",
        "        print(f\"{'     GPUs available?':<40}#: {torch.cuda.is_available()}\")\n",
        "        print(f\"{'     count':<40}#: {torch.cuda.device_count()}\")\n",
        "        print(f\"{'     current':<40}#: {torch.cuda.current_device()}\")\n",
        "    except Exception as e:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "      print(f\"{'GCP AI Platform version':<40}#: {str(aiplatform.__version__):<20}\")\n",
        "    except Exception as e:\n",
        "      pass\n",
        "\n",
        "    try:\n",
        "      print(f\"{'GCP Vertex version':<40}#: {str(vertexai.__version__):<20}\")\n",
        "    except Exception as e:\n",
        "      pass\n",
        "\n",
        "    try:\n",
        "      print(f\"{'Secret Manager version':<40}#: {str(secretmanager.__version__):<20}\")\n",
        "    except Exception as e:\n",
        "      pass\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG0mFzUX-DV1"
      },
      "source": [
        "## Function Call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSOOEwn8-FKg",
        "tags": []
      },
      "outputs": [],
      "source": [
        "lib_diagnostics()\n",
        "wrapper = textwrap.TextWrapper(width=TEXT_WIDTH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46JMSTY2QjWD"
      },
      "source": [
        "## Model Parameters and Model Selection\n",
        "\n",
        "Imagen 2 for Generation and Editing brings Google's advanced text-to-image technology to application developers. Imagen 2 boasts a variety of image generation features to help organizations create images that match their specific brand requirements with the same enterprise-grade reliability and governance you're used to with Imagen.\n",
        "\n",
        "With Imagen 2 for Generation and Editing, you can use text prompts to generate novel images or edit existing ones, or edit only parts of images using a mask.\n",
        "\n",
        "Image generation is delivered by model versions @006 (default) and @005.\n",
        "Mask-based image editing works best using model version @006 (@002 also supports it).\n",
        "Mask-free image editing is available by using model version @002.\n",
        "Supported languages for text prompts in Imagen 2 Generation include English, Chinese, Hindi, Japanese, Korean, Portuguese, and Spanish.\n",
        "\n",
        "Use cases\n",
        "+ Generate images: Enter text prompts to generate a series of images. For example, \"A French cafe with the Golden Gate Bridge in the background.\"\n",
        "\n",
        "+ Edit images: Edit images with built-in segmentation features that enable you to segment the imageâ€™s background, foreground, or ~175 subject classes\n",
        "\n",
        "+ Product editing: Provide an image of a product and a text prompt describing a new scenery to easily enhance product images\n",
        "+ Inpainting (removal): Provide an image and a mask that highlights a subject that you want to remove from the image\n",
        "\n",
        "+ Inpainting (insert): Provide an image and a mask to insert a subject based on your input text prompt\n",
        "Outpainting: Provide an image and a mask to extend the image to a custom size that you desire\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtRDeZQ_Ysyj"
      },
      "outputs": [],
      "source": [
        "###########################################\n",
        "#- API Parameters for things like WordCloud\n",
        "#- Variables help hold information for later use\n",
        "#- The \"constants\" represent variables that we don't anticipate changing over the course of the program.\n",
        "###########################################\n",
        "#model parameters\n",
        "#changing the model can influence the type of response you get at the end.\n",
        "\n",
        "#AVAILABLE MODELS - https://firebase.google.com/docs/vertex-ai/gemini-models\n",
        "#GCP LLM Info     - https://cloud.google.com/ai/llms?hl=en\n",
        "#Gemini 1.5 Flash\tgoogle/gemini-1.5-flash-001\n",
        "#Gemini 1.5 Prov\tgoogle/gemini-1.5-pro-001\n",
        "#Gemini 1.0 Prov\tgoogle/gemini-1.0-pro-002\n",
        "#                   google/gemini-1.0-pro-001\n",
        "#                   google/gemini-1.0-pro\n",
        "# Select ai model type, for detailed information about each model see: https://firebase.google.com/docs/vertex-ai/gemini-models#detailed-info\n",
        "# Model names for Gemini, see: https://firebase.google.com/docs/vertex-ai/gemini-models#available-model-names\n",
        "# All model reference, see: https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/explore-models\n",
        "# Image Model Developer's Guide, see: https://cloud.google.com/blog/products/ai-machine-learning/a-developers-guide-to-imagen-3-on-vertex-ai?e=0?utm_source%3Dlinkedin\n",
        "# Example Notebook, see: https://github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/imagen3_image_generation.ipynb\n",
        "\n",
        "AI_MODEL_TYPE = \"imagegeneration@006\"\n",
        "AI_MODEL_TYPE = \"imagen-3.0-generate-001\"\n",
        "\n",
        "model_temperature=0.5                     #Model temperature is a parameter that controls the randomness and creativity of a language model's output.\n",
        "                                          #It's a key factor in the quality of the text generated by the model, and is used in many natural language processing (NLP) tasks,\n",
        "                                          #such as summarization, translation, and text generation.\n",
        "\n",
        "model_max_tokens=8000                     #Model max tokens refers to the maximum number of tokens a language model can process in a single input, including both the prompt\n",
        "                                          #provided and the generated output, essentially setting the upper limit on the length of the text the model can generate in a single\n",
        "                                          #response; exceeding this limit will result in the model truncating the output or potentially returning an error message\n",
        "\n",
        "model_max_token_response=8000             #Maximum reponse you're preparing to return with, sets limits for future calculations.\n",
        "\n",
        "model_top_p=1                             #Top P specifies the cumulative probability score threshold that the tokens must reach.\n",
        "                                          #For example, if you set Top P to 0.6, then only the first two tokens, for and to, are sampled\n",
        "                                          #because their probabilities (0.4 and 0.25) add up to 0.65.\n",
        "\n",
        "model_top_k=1                             #Top-k sampling samples tokens with the highest probabilities until the specified number of\n",
        "                                          #tokens is reached. Top-p sampling samples tokens with the highest probability scores until\n",
        "                                          #the sum of the scores reaches the specified threshold value. (Top-p sampling is also called nucleus sampling.)\n",
        "\n",
        "summary_token_max=150\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ADGObWZZN3B"
      },
      "source": [
        "# AI Filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYX18Vt9ZPrs"
      },
      "outputs": [],
      "source": [
        "# import the required libraries\n",
        "import vertexai\n",
        "from vertexai.generative_models import (\n",
        "    GenerationConfig,\n",
        "    GenerativeModel,\n",
        "    HarmBlockThreshold,\n",
        "    HarmCategory,\n",
        "    Part,\n",
        "    SafetySetting,\n",
        ")\n",
        "\n",
        "# safety settings\n",
        "\n",
        "safety = [\n",
        "    SafetySetting(\n",
        "        category = HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
        "        threshold = HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category = HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
        "        threshold = HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category = HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
        "        threshold = HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category = HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
        "        threshold = HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvlYNerhGp7f"
      },
      "source": [
        "## Large Language Model (LLM) ~ Gemini Visual Model (Google)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7J5-zMedkVL"
      },
      "outputs": [],
      "source": [
        "from vertexai.preview.vision_models import ImageGenerationModel\n",
        "\n",
        "# Create the model\n",
        "# See https://ai.google.dev/api/python/google/generativeai/GenerativeModel\n",
        "\n",
        "try:\n",
        "    model = ImageGenerationModel.from_pretrained(AI_MODEL_TYPE)\n",
        "except (ValueError, Exception) as e:\n",
        "    print(\"ERROR: Problem loading your image model, see the exception below, inspect your code and try again.\")\n",
        "    print(repr(e))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pI0FSnAjNU3"
      },
      "source": [
        "## Create Your Picture Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMxl-xK1jAZn"
      },
      "outputs": [],
      "source": [
        "#options for creating an image\n",
        "style=[\"normal\", \"abstract\", \"surrealism\", \"cubism\", \"impressionism\", \"3d\", \"expressionist painting\", \"manga\", \"pop art\", \"pencil sketch\", \"watercolor\"]\n",
        "detail=[\"normal\", \"realistic\", \"ultrarealistic\", \"photorealistic\", \"photorealistic\", \"photorealistic\", \"photorealistic\", \"photorealistic\", \"photorealistic\", \"intricate\", \"highly detailed\"]\n",
        "position=[\"normal\", \"on the wall\", \"in the background\", \"in the foreground\", \"in the middle\", \"in the left\", \"in the right\"]\n",
        "mood=[\"normal\", \"stunning\", \"elegant\", \"radiant\", \"delicate\", \"cute\", \"striking\" \"glamorous\"]\n",
        "lights=[\"normal\", \"warm lighting\", \"natural lighting\", \"cold lighting\", \"dark aesthetic\", \"red tones\", \"blue tones\"]\n",
        "viewpoint=[\"portrait\", \"landscape\", \"close-up\", \"headshot\", \"mid-range\", \"3/4 shot\", \"full body shot\", \"wide shot\", \"low angle shot\", \"high angle shot\"]\n",
        "subject=[\"penguin\", \"bear\", \"tree\", \"dog\", \"cat\"]\n",
        "verb=[\"running\", \"surfing\", \"on the computer\", \"sleeping\", \"eating\", \"playing\", \"dancing\", \"sitting\", \"standing\", \"walking\"]\n",
        "\n",
        "\n",
        "\n",
        "#generate a picture from random choices above\n",
        "picture_prompt=f\"{style[random.randint(0, len(style)-1)]} \\\n",
        " {detail[random.randint(0, len(detail)-1)]} \\\n",
        " {position[random.randint(0, len(position)-1)]} \\\n",
        " {mood[random.randint(0, len(mood)-1)]} \\\n",
        " {lights[random.randint(0, len(lights)-1)]} \\\n",
        " {viewpoint[random.randint(0, len(viewpoint)-1)]}\\\n",
        " {subject[random.randint(0, len(subject)-1)]} \\\n",
        " {verb[random.randint(0, len(verb)-1)]}\"\n",
        "\n",
        "#examples\n",
        "#picture_prompt=\"magazine style, 4k, photorealistic, modern red armchair, natural\"\n",
        "picture_prompt=\"hyper-realistic, 4k, bear smoking a cigar holding a tommy gun while standing surfing a shark\"\n",
        "\n",
        "\n",
        "#format the output to make it legible\n",
        "#string = wrapper.fill(text=picture_prompt)\n",
        "print(f\"Random text created: {picture_prompt}\")\n",
        "\n",
        "#############################################################\n",
        "# REPLACE picture_prompt with your own\n",
        "# input if you want the image created to change\n",
        "#############################################################\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3_zbPFkjUHy"
      },
      "source": [
        "## Execute the Image Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLguZitVjWAu"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "try:\n",
        "  images = model.generate_images(\n",
        "      prompt=picture_prompt,\n",
        "\n",
        "      # Optional parameters\n",
        "      number_of_images=1,\n",
        "      language=\"en\",\n",
        "\n",
        "      # You can't use a seed value and watermark at the same time.\n",
        "      add_watermark=False,\n",
        "      #seed=100,\n",
        "      aspect_ratio=\"1:1\",\n",
        "      safety_filter_level=\"block_some\",\n",
        "      person_generation=\"allow_all\",\n",
        "  )\n",
        "\n",
        "  try:\n",
        "    output_file=\"./output.png\"\n",
        "    images[0].save(location=output_file, include_generation_parameters=False)\n",
        "    print(f\"Your save location is {output_file}.\")\n",
        "    print(f\"For prompt: {picture_prompt}\")\n",
        "  except Exception as e:\n",
        "    print(\"There was a problem saving your image.\")\n",
        "    print(f\"{start}See exception:{end} \")\n",
        "    string = wrapper.fill(text=str(e))\n",
        "    print(string)\n",
        "    print(f\"Your save location was {output_file}.\")\n",
        "\n",
        "  # Optional. View the generated image in a notebook.\n",
        "  try:\n",
        "    #images[0].show(). #without modification to size (which is huge)\n",
        "    image = Image.open(output_file)\n",
        "    scale = 0.75\n",
        "    display(image.resize(( int(image.width * scale), int(image.height * scale))))\n",
        "\n",
        "    print(f\"Created output image using {len(images[0]._image_bytes)} bytes\")\n",
        "  except Exception as e:\n",
        "    print(\"There was a problem displaying your image.\")\n",
        "    print(f\"{start}See exception:{end} \")\n",
        "    string = wrapper.fill(text=str(e))\n",
        "    print(string)\n",
        "\n",
        "except Exception as e:\n",
        "  print(\"There was a problem creating your image.\")\n",
        "  print(\"\\n\")\n",
        "  print(f\"{start}See exception:{end} \")\n",
        "  string = wrapper.fill(text=str(e))\n",
        "  print(string)\n",
        "  print(\"\\n\")\n",
        "  print(f\"{start}Your prompt was:{end} \")\n",
        "  string = wrapper.fill(text=picture_prompt)\n",
        "  print(string)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyh-6i-abGNB"
      },
      "source": [
        "# Do you understand the stochastic nature of AI?\n",
        "\n",
        "Definition of stochastic: randomly determined; having a random probability distribution or pattern that may be analyzed statistically but may not be predicted precisely.\n",
        "\n",
        "*** If this same prompt runs multiple times, do you expect to see the same picture every time....??? ***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dg7gDHTvbAf-"
      },
      "outputs": [],
      "source": [
        "number_of_times=3\n",
        "for index, value in enumerate(range(1,number_of_times)):\n",
        "\n",
        "  try:\n",
        "    images = model.generate_images(\n",
        "        prompt=picture_prompt,\n",
        "\n",
        "        # Optional parameters\n",
        "        number_of_images=1,\n",
        "        language=\"en\",\n",
        "\n",
        "        # You can't use a seed value and watermark at the same time.\n",
        "        # add_watermark=False,\n",
        "        # seed=100,\n",
        "        aspect_ratio=\"1:1\",\n",
        "        safety_filter_level=\"block_some\",\n",
        "        person_generation=\"allow_adult\",\n",
        "    )\n",
        "\n",
        "    try:\n",
        "      output_file=f\"./output_{str(index)}.png\"\n",
        "      images[0].save(location=output_file, include_generation_parameters=False)\n",
        "      print(f\"Image Number: {str(index)}\")\n",
        "      print(f\"Your save location is {output_file}.\")\n",
        "      print(f\"For prompt: {picture_prompt}\")\n",
        "    except Exception as e:\n",
        "      print(\"There was a problem saving your image.\")\n",
        "      print(f\"{start}See exception:{end} \")\n",
        "      string = wrapper.fill(text=str(e))\n",
        "      print(string)\n",
        "      print(f\"Your save location was {output_file}.\")\n",
        "\n",
        "    # Optional. View the generated image in a notebook.\n",
        "    try:\n",
        "      #images[0].show(). #without modification to size (which is huge)\n",
        "      image = Image.open(output_file)\n",
        "      scale = 0.3\n",
        "      display(image.resize(( int(image.width * scale), int(image.height * scale))))\n",
        "\n",
        "      print(f\"Created output image using {len(images[0]._image_bytes)} bytes\")\n",
        "      print(\"\\n\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "      print(\"There was a problem displaying your image.\")\n",
        "      print(f\"{start}See exception:{end} \")\n",
        "      string = wrapper.fill(text=str(e))\n",
        "      print(string)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(\"There was a problem creating your image.\")\n",
        "    print(\"\\n\")\n",
        "    print(f\"{start}See exception:{end} \")\n",
        "    string = wrapper.fill(text=str(e))\n",
        "    print(string)\n",
        "    print(\"\\n\")\n",
        "    print(f\"{start}Your prompt was:{end} \")\n",
        "    string = wrapper.fill(text=picture_prompt)\n",
        "    print(string)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "STEM-002_GenAI_Images.ipynb",
      "provenance": [
        {
          "file_id": "https://github.com/christophergarthwood/jbooks/blob/main/STEM-001_WordClouds.ipynb",
          "timestamp": 1716214402332
        }
      ]
    },
    "environment": {
      "kernel": "conda-env-tensorflow-tensorflow",
      "name": "workbench-notebooks.m125",
      "type": "gcloud",
      "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
    },
    "kernelspec": {
      "display_name": "TensorFlow 2-11 (Local)",
      "language": "python",
      "name": "conda-env-tensorflow-tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}