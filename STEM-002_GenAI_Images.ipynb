{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg3iJooMQjWA"
      },
      "source": [
        "# Artificial Intelligence\n",
        "## Image Generator\n",
        "\n",
        "OpenAI Dall-E (and others) are text-to-image models developed by OpenAI using deep learning methodologies to generate digital images from natural language descriptions, called \"prompts\".\n",
        "\n",
        "Reference:\n",
        "\n",
        "+ https://gemini.google.com/app\n",
        "  + https://cloud.google.com/vertex-ai/generative-ai/docs/image/img-gen-prompt-guide\n",
        "  + https://tech.co/news/use-google-bard-ai-image-generator\n",
        "+ https://www.midjourney.com/explore?tab=top\n",
        "\n",
        "+ https://openai.com/index/dall-e-2/\n",
        "\n",
        "+ https://builtin.com/artificial-intelligence/prompt-engineering\n",
        "\n",
        "+ https://flux-ai.io/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jljx58WFBpXo",
        "tags": []
      },
      "outputs": [],
      "source": [
        "BUCKET_NAME =\"cio-training-vertex-colab\"\n",
        "PROJECT_ID  =\"usfs-ai-bootcamp\"\n",
        "LOCATION    =\"us-central1\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import minimal libraries to support installation of additional tools\n",
        "import sys\n",
        "import subprocess\n",
        "import importlib.util"
      ],
      "metadata": {
        "id": "148_yL2HDaUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zramkw-P93C-"
      },
      "source": [
        "## Environment Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shY7a4DVQjWB",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "#- Google Colab Check\n",
        "# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "import datetime\n",
        "\n",
        "RunningInCOLAB = False\n",
        "RunningInCOLAB = 'google.colab' in str(get_ipython())\n",
        "current_time   = datetime.datetime.now()\n",
        "\n",
        "if RunningInCOLAB:\n",
        "    print(f\"You are running this notebook in Google Colab at {current_time} in the {PROJECT_ID} lab.\")\n",
        "else:\n",
        "    print(f\"You are likely running this notebook with Jupyter iPython runtime at {current_time} in the {PROJECT_ID} lab.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5kZDFBsXcoq"
      },
      "source": [
        "# GCP Gemini Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsDkV2olXfGJ"
      },
      "outputs": [],
      "source": [
        "#Download Google Vextex/AI Libraries\n",
        "subprocess.run([\"pip\", \"install\" , \"--upgrade\", \"google-cloud-aiplatform\", \"--quiet\"])\n",
        "\n",
        "\n",
        "libraries=[\"google-generativeai\", \"google-cloud-secret-manager\", \"openai\"]\n",
        "\n",
        "for library in libraries:\n",
        "    spec = importlib.util.find_spec(library)\n",
        "    if spec is None:\n",
        "      print(\"Installing library \" + library)\n",
        "      subprocess.run([\"pip\", \"install\" , library, \"--quiet\"])\n",
        "    else:\n",
        "      print(\"Library \" + library + \" already installed.\")\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "import vertexai.preview\n",
        "from google.cloud import secretmanager\n",
        "import vertexai\n",
        "import openai\n",
        "from google.auth import default, transport"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO_Hq5eq9joH"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJuXEPlkSo9p",
        "tags": []
      },
      "outputs": [],
      "source": [
        "############################################\n",
        "# INCLUDES\n",
        "############################################\n",
        "#libraries specific to this example\n",
        "## Imports\n",
        "#import tensorflow as tf\n",
        "#from tensorflow import keras\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "#a set of libraries that perhaps should always be in Python source\n",
        "import os\n",
        "import datetime\n",
        "import sys\n",
        "import gc\n",
        "import getopt\n",
        "import inspect\n",
        "import math\n",
        "import warnings\n",
        "import textwrap\n",
        "import random\n",
        "import glob\n",
        "import os\n",
        "import PIL\n",
        "import time\n",
        "import subprocess\n",
        "\n",
        "#images\n",
        "import imageio\n",
        "import matplotlib as matplt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#data science\n",
        "import numpy as np\n",
        "\n",
        "#a darn useful library for creating paths and one I recommend you load to your environment\n",
        "from pathlib import Path\n",
        "\n",
        "from pydoc import help                          # can type in the python console `help(name of function)` to get the documentation\n",
        "\n",
        "warnings.filterwarnings('ignore')               # don't print out warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9gpU3zJ9l9H"
      },
      "source": [
        "## Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoQDWB9s9n7H",
        "tags": []
      },
      "outputs": [],
      "source": [
        "############################################\n",
        "# GLOBAL VARIABLES\n",
        "############################################\n",
        "DEBUG = 1\n",
        "DEBUG_DATA = 0\n",
        "\n",
        "# CODE CONSTRAINTS\n",
        "VERSION_NAME    = \"MLGENIMG\"\n",
        "VERSION_MAJOR   = 0\n",
        "VERSION_MINOR   = 0\n",
        "VERSION_RELEASE = 1\n",
        "\n",
        "#used for values outside standard ASCII, just do it, you'll need it\n",
        "ENCODING  =\"utf-8\"\n",
        "\n",
        "############################################\n",
        "# GLOBAL CONSTANTS\n",
        "############################################\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256\n",
        "TEXT_WIDTH=77\n",
        "IMG_SCALE=0.75\n",
        "############################################\n",
        "# APPLICATION VARIABLES\n",
        "############################################\n",
        "start = \"\\033[1m\"\n",
        "end = \"\\033[0;0m\"\n",
        "\n",
        "############################################\n",
        "# GLOBAL CONFIGURATION\n",
        "############################################\n",
        "os.environ['PYTHONIOENCODING']=ENCODING\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FUa8QJT9tw_"
      },
      "source": [
        "## Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_CqUVLZ98Mz",
        "tags": []
      },
      "outputs": [],
      "source": [
        "## Outputs library version history of effort.\n",
        "#\n",
        "def lib_diagnostics() -> None:\n",
        "\n",
        "    import pkg_resources\n",
        "\n",
        "    package_name_length=40\n",
        "    package_version_length=20\n",
        "\n",
        "    # Get installed packages\n",
        "    the_packages=[\"nltk\", \"numpy\", \"os\", \"pandas\"]\n",
        "    installed = {pkg.key: pkg.version for pkg in pkg_resources.working_set}\n",
        "    for package_idx, package_name in enumerate(installed):\n",
        "         if package_name in the_packages:\n",
        "             installed_version = installed[package_name]\n",
        "             print(f\"{package_name:<40}#: {str(pkg_resources.parse_version(installed_version)):<20}\")\n",
        "\n",
        "    try:\n",
        "        print(f\"{'OpenAI version':<40}#: {str(openai.__version__):<20}\")\n",
        "    except Exception as e:\n",
        "        pass\n",
        "\n",
        "\n",
        "    try:\n",
        "        print(f\"{'TensorFlow version':<40}#: {str(tf.__version__):<20}\")\n",
        "        print(f\"{'     gpu.count:':<40}#: {str(len(tf.config.experimental.list_physical_devices('GPU')))}\")\n",
        "        print(f\"{'     cpu.count:':<40}#: {str(len(tf.config.experimental.list_physical_devices('CPU')))}\")\n",
        "    except Exception as e:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        print(f\"{'Torch version':<40}#: {str(torch.__version__):<20}\")\n",
        "        print(f\"{'     GPUs available?':<40}#: {torch.cuda.is_available()}\")\n",
        "        print(f\"{'     count':<40}#: {torch.cuda.device_count()}\")\n",
        "        print(f\"{'     current':<40}#: {torch.cuda.current_device()}\")\n",
        "    except Exception as e:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "      print(f\"{'GCP AI Platform version':<40}#: {str(aiplatform.__version__):<20}\")\n",
        "    except Exception as e:\n",
        "      pass\n",
        "\n",
        "    try:\n",
        "      print(f\"{'GCP Vertex version':<40}#: {str(vertexai.__version__):<20}\")\n",
        "    except Exception as e:\n",
        "      pass\n",
        "\n",
        "    try:\n",
        "      print(f\"{'Secret Manager version':<40}#: {str(secretmanager.__version__):<20}\")\n",
        "    except Exception as e:\n",
        "      pass\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG0mFzUX-DV1"
      },
      "source": [
        "## Function Call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSOOEwn8-FKg",
        "tags": []
      },
      "outputs": [],
      "source": [
        "lib_diagnostics()\n",
        "wrapper = textwrap.TextWrapper(width=TEXT_WIDTH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46JMSTY2QjWD"
      },
      "source": [
        "## Model Parameters and Model Selection\n",
        "\n",
        "Imagen 3 sets a new standard in quality and control over your generated images. This text-to-image model produces photorealistic visuals with exceptional composition, sharpness, color accuracy, and resolution. With Imagen 3, you can explore a wider spectrum of artistic styles and formats. From photorealistic masterpieces to whimsical claymation scenes, the model's expanded range of styles and formats provides the tools to express your unique artistic vision.\n",
        "\n",
        "**Text rendering**\n",
        "\n",
        "Imagen 3 also brings new possibilities when it comes to rendering text within images. A fun way to play around with this feature is to generate images of greeting cards, posters, and social media posts with captions in various fonts and colors. This feature is as easy as adding a short text description you would like to see to the prompt. Let’s say you would like to add a title and regenerate a cookbook cover.\n",
        "\n",
        "**Closer to your intent**\n",
        "\n",
        "Imagen 3's prompt comprehension translates your natural language descriptions, no matter how nuanced, into closely matched visuals. You can specify everything from specific camera angles to types of lenses to image compositions in your description. Imagen 3 adheres closely to the prompt, which helps close the gap between your mental picture and the final image. You can provide the model with simple subject-action-setting prompts or intricate, multi-layered descriptions, and the model adapts to your creative process to enable a broad range of styles.\n",
        "\n",
        "Since Imagen 3 does well with elaborate prompts, providing robust details usually yields higher quality and more precise results. Below are a few options to consider when crafting your prompts:\n",
        "\n",
        "Arrangement: Direct the scene by specifying where you want subjects positioned.\n",
        "\n",
        "Lighting: Create atmosphere with soft or harsh lighting, and control its direction and focus.\n",
        "\n",
        "Angles & lenses: Add depth and perspective with camera angles and lens choices.\n",
        "\n",
        "Styles: Go beyond photorealism and generate digital art, cinematic, vintage, minimalist images, and more.\n",
        "\n",
        "***Reduced latency***\n",
        "\n",
        "While Imagen 3 is our highest quality model to date, we are also offering Imagen 3 Fast, which is optimized for generation speed. Imagen 3 Fast is suitable for creating brighter, higher contrast images. Compared to Imagen 2, you can see a 40% decrease in latency. To demonstrate these two models, you can generate two images with the same prompt. Let’s generate two options for a photo of a salad to add to the same cookbook from earlier.\n",
        "\n",
        "**Protect your work and create responsibly**\n",
        "\n",
        "Imagen 3 has built in safeguards that let you focus on your artistic vision without compromising control. In partnership with Google DeepMind, Imagen 3 utilizes SynthID, a technology which embeds an invisible watermark at the pixel level. By default, a digital watermark is added to all Imagen 3 generated images, but you can explicitly enable this feature with the add_watermark parameter. You can also use the API to verify whether an image was generated using Imagen. This verifies the authenticity of your AI-generated images, providing transparency and helping to safeguard your work from misuse.\n",
        "\n",
        "With Imagen 3's advanced safety filters, you can also control the types of images generated to make sure they meet your brand values or principles. To configure safety filter thresholds for generated images, modify the safety_filter_level. The safety level can be changed to “block_most”, “block_some”, or “block_few”. To change the safety setting that controls the type of people generated, modify person_generation to “allow_all”, “allow_adult”, or “dont_allow”.\n",
        "\n",
        "### Use cases\n",
        "+ Generate images: Enter text prompts to generate a series of images. For example, \"A French cafe with the Golden Gate Bridge in the background.\"\n",
        "\n",
        "+ Edit images: Edit images with built-in segmentation features that enable you to segment the image’s background, foreground, or ~175 subject classes\n",
        "\n",
        "+ Product editing: Provide an image of a product and a text prompt describing a new scenery to easily enhance product images\n",
        "+ Inpainting (removal): Provide an image and a mask that highlights a subject that you want to remove from the image\n",
        "\n",
        "+ Inpainting (insert): Provide an image and a mask to insert a subject based on your input text prompt\n",
        "Outpainting: Provide an image and a mask to extend the image to a custom size that you desire\n",
        "\n",
        "### Temperature Settings\n",
        "\n",
        "The temperature is a numerical value (often set between 0 and 1, but sometimes higher) that adjusts how much the model takes risks or plays it safe in its choices. It modifies the probability distribution of the next word.\n",
        "\n",
        "The different LLM temperature parameters:\n",
        "\n",
        "**Low Temperature (<1.0)**: Setting the temperature to a value of less than 1 makes the model’s output more deterministic and repetitive. Lower temperatures lead to the model picking the most likely next word more often, reducing the variability of the output. This can be useful when you need more predictable, conservative responses, but it might also result in less creative or diverse text, also making the model sound more robotic.\n",
        "\n",
        "**High Temperature (>1.0)**: A temperature setting above 1 increases randomness in the generated text. The model is more likely to select less probable words as the next word in the sequence, leading to more varied and sometimes more creative outputs. However, this can also result in more errors or nonsensical responses, since the model is less constrained by the probability distribution of its training data.\n",
        "\n",
        "**Temperature of 1.0**: This is often the default setting, aiming for a balance between randomness and determinism. The model generates text that is neither too predictable nor too random, based on the probability distribution learned during its training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtRDeZQ_Ysyj"
      },
      "outputs": [],
      "source": [
        "###########################################\n",
        "#- API Parameters for things like WordCloud\n",
        "#- Variables help hold information for later use\n",
        "#- The \"constants\" represent variables that we don't anticipate changing over the course of the program.\n",
        "###########################################\n",
        "#model parameters\n",
        "#changing the model can influence the type of response you get at the end.\n",
        "\n",
        "#AVAILABLE MODELS - https://firebase.google.com/docs/vertex-ai/gemini-models\n",
        "#  Select ai model type, for detailed information about each model see: https://firebase.google.com/docs/vertex-ai/gemini-models#detailed-info\n",
        "#  Model names for Gemini, see: https://firebase.google.com/docs/vertex-ai/gemini-models#available-model-names\n",
        "#  All model reference, see: https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/explore-models\n",
        "#  Image Model Developer's Guide, see: https://cloud.google.com/blog/products/ai-machine-learning/a-developers-guide-to-imagen-3-on-vertex-ai\n",
        "#  Example Notebook, see: https://github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/imagen3_image_generation.ipynb\n",
        "\n",
        "#AI_MODEL_TYPE = \"imagegeneration@006\"\n",
        "AI_MODEL_TYPE = \"imagen-3.0-generate-001\"\n",
        "\n",
        "model_temperature=0.5                     #Model temperature is a parameter that controls the randomness and creativity of a language model's output.\n",
        "                                          #It's a key factor in the quality of the text generated by the model, and is used in many natural language processing (NLP) tasks,\n",
        "                                          #such as summarization, translation, and text generation.\n",
        "\n",
        "model_max_tokens=8000                     #Model max tokens refers to the maximum number of tokens a language model can process in a single input, including both the prompt\n",
        "                                          #provided and the generated output, essentially setting the upper limit on the length of the text the model can generate in a single\n",
        "                                          #response; exceeding this limit will result in the model truncating the output or potentially returning an error message\n",
        "\n",
        "model_max_token_response=8000             #Maximum reponse you're preparing to return with, sets limits for future calculations.\n",
        "\n",
        "model_top_p=1                             #Top P specifies the cumulative probability score threshold that the tokens must reach.\n",
        "                                          #For example, if you set Top P to 0.6, then only the first two tokens, for and to, are sampled\n",
        "                                          #because their probabilities (0.4 and 0.25) add up to 0.65.\n",
        "\n",
        "model_top_k=1                             #Top-k sampling samples tokens with the highest probabilities until the specified number of\n",
        "                                          #tokens is reached. Top-p sampling samples tokens with the highest probability scores until\n",
        "                                          #the sum of the scores reaches the specified threshold value. (Top-p sampling is also called nucleus sampling.)\n",
        "\n",
        "summary_token_max=150\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ADGObWZZN3B"
      },
      "source": [
        "# AI Filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYX18Vt9ZPrs"
      },
      "outputs": [],
      "source": [
        "# import the required libraries\n",
        "import vertexai\n",
        "from vertexai.generative_models import (\n",
        "    GenerationConfig,\n",
        "    GenerativeModel,\n",
        "    HarmBlockThreshold,\n",
        "    HarmCategory,\n",
        "    Part,\n",
        "    SafetySetting,\n",
        ")\n",
        "\n",
        "# safety settings\n",
        "\n",
        "safety = [\n",
        "    SafetySetting(\n",
        "        category = HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
        "        threshold = HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category = HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
        "        threshold = HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category = HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
        "        threshold = HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category = HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
        "        threshold = HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvlYNerhGp7f"
      },
      "source": [
        "## Large Language Model (LLM) ~ Gemini Visual Model (Google)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7J5-zMedkVL"
      },
      "outputs": [],
      "source": [
        "from vertexai.preview.vision_models import ImageGenerationModel\n",
        "\n",
        "# Create the model\n",
        "# See https://ai.google.dev/api/python/google/generativeai/GenerativeModel\n",
        "\n",
        "try:\n",
        "    model = ImageGenerationModel.from_pretrained(AI_MODEL_TYPE)\n",
        "except (ValueError, Exception) as e:\n",
        "    print(\"ERROR: Problem loading your image model, see the exception below, inspect your code and try again.\")\n",
        "    print(repr(e))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pI0FSnAjNU3"
      },
      "source": [
        "## Create Your Picture Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMxl-xK1jAZn"
      },
      "outputs": [],
      "source": [
        "#options for creating an image\n",
        "style=[\"normal\", \"abstract\", \"surrealism\", \"cubism\", \"impressionism\", \"3d\", \"expressionist painting\", \"manga\", \"pop art\", \"pencil sketch\", \"watercolor\"]\n",
        "detail=[\"normal\", \"realistic\", \"ultrarealistic\", \"photorealistic\", \"photorealistic\", \"photorealistic\", \"photorealistic\", \"photorealistic\", \"photorealistic\", \"intricate\", \"highly detailed\"]\n",
        "position=[\"normal\", \"on the wall\", \"in the background\", \"in the foreground\", \"in the middle\", \"in the left\", \"in the right\"]\n",
        "mood=[\"normal\", \"stunning\", \"elegant\", \"radiant\", \"delicate\", \"cute\", \"striking\" \"glamorous\"]\n",
        "lights=[\"normal\", \"warm lighting\", \"natural lighting\", \"cold lighting\", \"dark aesthetic\", \"red tones\", \"blue tones\"]\n",
        "viewpoint=[\"portrait\", \"landscape\", \"close-up\", \"headshot\", \"mid-range\", \"3/4 shot\", \"full body shot\", \"wide shot\", \"low angle shot\", \"high angle shot\"]\n",
        "\n",
        "subject=[\"penguin\", \"bear\", \"tree\", \"dog\", \"cat\", \"plan\", \"spotted lantern fly\", \"eastern longhorn beetle\"]\n",
        "\n",
        "verb=[\"running\", \"surfing\", \"on the computer\", \"sleeping\", \"eating\", \"playing\", \"dancing\", \"sitting\", \"standing\", \"walking\"]\n",
        "\n",
        "\n",
        "\n",
        "#generate a picture from random choices above\n",
        "picture_prompt=f\"{style[random.randint(0, len(style)-1)]} \\\n",
        " {detail[random.randint(0, len(detail)-1)]} \\\n",
        " {position[random.randint(0, len(position)-1)]} \\\n",
        " {mood[random.randint(0, len(mood)-1)]} \\\n",
        " {lights[random.randint(0, len(lights)-1)]} \\\n",
        " {viewpoint[random.randint(0, len(viewpoint)-1)]}\\\n",
        " {subject[random.randint(0, len(subject)-1)]} \\\n",
        " {verb[random.randint(0, len(verb)-1)]}\"\n",
        "\n",
        "#examples\n",
        "#picture_prompt=\"magazine style, 4k, photorealistic, modern red armchair, natural\"\n",
        "#picture_prompt=\"hyper-realistic, 4k, bear smoking a cigar holding a tommy gun while standing surfing on a shark\"\n",
        "\n",
        "\n",
        "#format the output to make it legible\n",
        "string = wrapper.fill(text=picture_prompt)\n",
        "print(f\"Random text created: {picture_prompt}\")\n",
        "\n",
        "#############################################################\n",
        "# REPLACE picture_prompt with your own\n",
        "# input if you want the image created to change\n",
        "#############################################################\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3_zbPFkjUHy"
      },
      "source": [
        "## Execute the Image Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLguZitVjWAu"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "try:\n",
        "  images = model.generate_images(\n",
        "      prompt=picture_prompt,\n",
        "\n",
        "      # Optional parameters\n",
        "      number_of_images=1,\n",
        "      language=\"en\",\n",
        "\n",
        "      # You can't use a seed value and watermark at the same time.\n",
        "      add_watermark=False,\n",
        "      #seed=100,\n",
        "      aspect_ratio=\"1:1\",\n",
        "      safety_filter_level=\"block_some\",\n",
        "      person_generation=\"allow_all\",\n",
        "  )\n",
        "\n",
        "  try:\n",
        "    output_file=\"./stem-002-genai-images-output.png\"\n",
        "    images[0].save(location=output_file, include_generation_parameters=False)\n",
        "    print(f\"Your save location is {output_file}.\")\n",
        "    print(f\"For prompt: {picture_prompt}\")\n",
        "  except Exception as e:\n",
        "    print(\"There was a problem saving your image.\")\n",
        "    print(f\"{start}See exception:{end} \")\n",
        "    string = wrapper.fill(text=str(e))\n",
        "    print(string)\n",
        "    print(f\"Your save location was {output_file}.\")\n",
        "\n",
        "  try:\n",
        "    #images[0].show(). #without modification to size (which is huge)\n",
        "    image = Image.open(output_file)\n",
        "    display(image.resize(( int(image.width * IMG_SCALE), int(image.height * IMG_SCALE))))\n",
        "    print(f\"Created output image using {len(images[0]._image_bytes)} bytes\")\n",
        "  except Exception as e:\n",
        "    print(\"There was a problem displaying your image.  Contact your instructor for assistance.\")\n",
        "    print(f\"{start}See exception:{end} \")\n",
        "    string = wrapper.fill(text=str(e))\n",
        "    print(string)\n",
        "\n",
        "except Exception as e:\n",
        "  print(\"There was a problem creating your image.  Contact your instructor for assistance.\")\n",
        "  print(\"\\n\")\n",
        "  print(f\"{start}See exception:{end} \")\n",
        "  string = wrapper.fill(text=str(e))\n",
        "  print(string)\n",
        "  print(\"\\n\")\n",
        "  print(f\"{start}Your prompt was:{end} \")\n",
        "  string = wrapper.fill(text=picture_prompt)\n",
        "  print(string)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyh-6i-abGNB"
      },
      "source": [
        "# Do you understand the stochastic nature of AI?\n",
        "\n",
        "Definition of stochastic: randomly determined; having a random probability distribution or pattern that may be analyzed statistically but may not be predicted precisely.\n",
        "\n",
        "***The behavior and performance of many machine learning algorithms are referred to as stochastic.***\n",
        "\n",
        "Stochastic refers to a variable process where the outcome involves some randomness and has some uncertainty. It is a mathematical term and is closely related to “randomness” and “probabilistic” and can be contrasted to the idea of “deterministic.”\n",
        "\n",
        "The stochastic nature of machine learning algorithms is an important foundational concept in machine learning and is required to be understand in order to effectively interpret the behavior of many predictive models.\n",
        "\n",
        "+ A variable or process is stochastic if there is uncertainty or randomness involved in the outcomes.\n",
        "\n",
        "+ Stochastic is a synonym for random and probabilistic, although is different from non-deterministic.\n",
        "\n",
        "+ Many machine learning algorithms are stochastic because they explicitly use randomness during optimization or learning.\n",
        "\n",
        "#### *** If this same prompt runs multiple times, do you expect to see the same picture every time....??? ***\n",
        "\n",
        "References:\n",
        "+ https://www.geeksforgeeks.org/deterministic-vs-stochastic-environment-in-ai/\n",
        "+ https://machinelearningmastery.com/stochastic-in-machine-learning/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dg7gDHTvbAf-"
      },
      "outputs": [],
      "source": [
        "number_of_times=3\n",
        "for index, value in enumerate(range(1,number_of_times)):\n",
        "\n",
        "  try:\n",
        "    images = model.generate_images(\n",
        "        prompt=picture_prompt,\n",
        "\n",
        "        # Optional parameters\n",
        "        number_of_images=1,\n",
        "        language=\"en\",\n",
        "\n",
        "        # You can't use a seed value and watermark at the same time.\n",
        "        # add_watermark=False,\n",
        "        # seed=100,\n",
        "        aspect_ratio=\"1:1\",\n",
        "        safety_filter_level=\"block_some\",\n",
        "        person_generation=\"allow_adult\",\n",
        "    )\n",
        "\n",
        "    try:\n",
        "      output_file=f\"./output_{str(index)}.png\"\n",
        "      images[0].save(location=output_file, include_generation_parameters=False)\n",
        "      print(f\"Image Number: {str(index)}\")\n",
        "      print(f\"Your save location is {output_file}.\")\n",
        "      print(f\"For prompt: {picture_prompt}\")\n",
        "    except Exception as e:\n",
        "      print(\"There was a problem saving your image.\")\n",
        "      print(f\"{start}See exception:{end} \")\n",
        "      string = wrapper.fill(text=str(e))\n",
        "      print(string)\n",
        "      print(f\"Your save location was {output_file}.\")\n",
        "\n",
        "    # Optional. View the generated image in a notebook.\n",
        "    try:\n",
        "      #images[0].show(). #without modification to size (which is huge)\n",
        "      image = Image.open(output_file)\n",
        "      scale = 0.5\n",
        "      display(image.resize(( int(image.width * scale), int(image.height * scale))))\n",
        "\n",
        "      print(f\"Created output image using {len(images[0]._image_bytes)} bytes\")\n",
        "      print(\"\\n\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "      print(\"There was a problem displaying your image.\")\n",
        "      print(f\"{start}See exception:{end} \")\n",
        "      string = wrapper.fill(text=str(e))\n",
        "      print(string)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(\"There was a problem creating your image.\")\n",
        "    print(\"\\n\")\n",
        "    print(f\"{start}See exception:{end} \")\n",
        "    string = wrapper.fill(text=str(e))\n",
        "    print(string)\n",
        "    print(\"\\n\")\n",
        "    print(f\"{start}Your prompt was:{end} \")\n",
        "    string = wrapper.fill(text=picture_prompt)\n",
        "    print(string)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "STEM-002_GenAI_Images.ipynb",
      "provenance": [
        {
          "file_id": "https://github.com/christophergarthwood/jbooks/blob/main/STEM-001_WordClouds.ipynb",
          "timestamp": 1716214402332
        }
      ]
    },
    "environment": {
      "kernel": "conda-env-tensorflow-tensorflow",
      "name": "workbench-notebooks.m125",
      "type": "gcloud",
      "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
    },
    "kernelspec": {
      "display_name": "TensorFlow 2-11 (Local)",
      "language": "python",
      "name": "conda-env-tensorflow-tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}