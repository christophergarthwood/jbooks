{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jg3iJooMQjWA"
   },
   "source": [
    "# Artificial Intelligence Classifier\n",
    "## Generative AI (GenAI) - 005\n",
    "\n",
    "<center>\n",
    "<table align=\"center\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/christophergarthwood/jbooks/blob/main/STEM-005_Classifier.ipynb\">\n",
    "      <img src=\"./img/GoogleColab-logo.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/notebooks?referrer=search&hl=en&project=usfs-ai-bootcamp\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Link to Colab Enterprise\n",
    "    </a>\n",
    "  </td>   \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/christophergarthwood/jbooks/blob/main/STEM-005_CLassifier.ipynb\">\n",
    "      <img src=\"./img/GitHub-logo.jpg\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/instances?referrer=search&hl=en&project=usfs-ai-bootcamp\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Link to Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "</center>\n",
    "</br></br></br>\n",
    "\n",
    "| | |\n",
    "|-|-|\n",
    "|Author(s) | [Christopher G Wood](https://github.com/christophergarthwood)  |\n",
    "\n",
    "# Overview\n",
    "\n",
    "Basic classification: Classify images of clothing.\n",
    "\n",
    "Classification is the process of predicting the class of given data points. Classes are sometimes called as targets/ labels or categories. Classification predictive modeling is the task of approximating a mapping function (f) from input variables (X) to discrete output variables (y).\n",
    "\n",
    "Said another way...\n",
    "\n",
    "A classifier in machine learning is an algorithm that automatically orders or categorizes data into one or more of a set of “classes.” The process of categorizing or classifying information based on certain characteristics is known as classification.\n",
    "\n",
    "For example, spam detection in email service providers can be identified as a classification problem. This is s binary classification since there are only 2 classes as spam and not spam. A classifier utilizes some training data to understand how given input variables relate to the class. In this case, known spam and non-spam emails have to be used as the training data. When the classifier is trained accurately, it can be used to detect an unknown email.\n",
    "\n",
    "Classification belongs to the category of supervised learning where the targets also provided with the input data. There are many applications in classification in many domains such as in credit approval, medical diagnosis, target marketing etc.\n",
    "\n",
    "\n",
    "Types of Classifiers:\n",
    "+ Binary Classifiers: These are used when there are only two possible classes. For example, an email classifier might be designed to detect spam and non-spam emails.\n",
    "+ Multiclass Classifiers: These handle situations where there are more than two classes. For instance, a classifier that categorizes news articles into topics like sports, politics, and technology.\n",
    "+ Multilabel Classifiers: These can assign multiple labels to each instance. For example, a movie could be classified into multiple genres like comedy,drama, and action simultaneously.\n",
    "\n",
    "\n",
    "## References:\n",
    "\n",
    "+ https://www.tensorflow.org/tutorials/keras/classification\n",
    "+ https://towardsdatascience.com/machine-learning-classifiers-a5cc4e1b0623\n",
    "+ https://github.com/christophergarthwood/jbooks/blob/main/ML-000-d_KerasTensorFlowGPU.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1737662703613,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "EvWPDwom_wCc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's define some variables (information holders) for our project overall\n",
    "\n",
    "global PROJECT_ID, BUCKET_NAME, LOCATION\n",
    "BUCKET_NAME =\"cio-training-vertex-colab\"\n",
    "PROJECT_ID  =\"usfs-ai-bootcamp\"\n",
    "LOCATION    = \"us-central1\"\n",
    "\n",
    "BOLD_START=\"\\033[1m\"\n",
    "BOLD_END=\"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509,
     "referenced_widgets": [
      "e9eae00320e74b3587e85c55e8d7688c",
      "fd7779ddb26f4611b0a4f52289915ade",
      "8119b099c8834c1c8cf40292824bfcb0",
      "54fcd04b1c474fbc96cde3b35afcddf9",
      "5319161667c547f1ba6240c426fba8b8",
      "35c3b2bbc1324552b5ab4d2b1f076ca1",
      "c7559d0f0bab4c58b7905432d1026bd4",
      "ca2f6fe8655d4ac2a673ec508f165221",
      "0cae0449cbaa40c4abd69027ed4b8a52",
      "ad544439b79f498186efaf5ebbd9a9c5",
      "9b941a36785e460ca8596b3971973925",
      "1e8c438f2fc3435f8b69ec9158fb9ef9",
      "cf67f07a92034b00b24616b43d828deb",
      "d1530ba138d841bf817892b3807c488b",
      "06d2f305876c4b37b5d403d3a8c09017",
      "c734f36fdc7d408f9e9ee69bd0615730"
     ]
    },
    "executionInfo": {
     "elapsed": 213,
     "status": "ok",
     "timestamp": 1737662703822,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "i-Yo24ko7LMj",
    "outputId": "041eeb8c-f076-4f50-c03f-e8ee2dec0ae2"
   },
   "outputs": [],
   "source": [
    "# Now create a means of enforcing project id selection\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def wait_for_button_press():\n",
    "\n",
    "    button_pressed = False\n",
    "\n",
    "    # Create widgets\n",
    "    html_widget = widgets.HTML(\n",
    "\n",
    "    value=\"\"\"\n",
    "        <center><table><tr><td><h1 style=\"font-family: Roboto;font-size: 24px\"><b>&#128721; &#9888;&#65039; WARNING &#9888;&#65039;\t&#128721; </b></h1></td></tr></table</center></br></br>\n",
    "\n",
    "        <table><tr><td>\n",
    "            <span style=\"font-family: Tahoma;font-size: 18\">\n",
    "              This notebook was designed to work in Jupyter Notebook or Google Colab with the understnading that certain permissions might be enabled.</br>\n",
    "              Please verify that you are in the appropriate project and that the:</br>\n",
    "              <center><code><b>PROJECT_ID</b></code> </br></center>\n",
    "              aligns with the Project Id in the upper left corner of this browser and that the location:\n",
    "              <center><code><b>LOCATION</b></code> </br></center>\n",
    "              aligns with the instructions provided.\n",
    "            </span>\n",
    "          </td></tr></table></br></br>\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "    project_list=[\"usfs-ai-bootcamp\", \"usfa-ai-advanced-training\", \"I will setup my own\"]\n",
    "    dropdown = widgets.Dropdown(\n",
    "        options=project_list,\n",
    "        value=project_list[0],\n",
    "        description='Set Your Project:',\n",
    "    )\n",
    "\n",
    "    html_widget2 = widgets.HTML(\n",
    "    value=\"\"\"\n",
    "        <center><table><tr><td><h1 style=\"font-family: Roboto;font-size: 24px\"><b>&#128721; &#9888;&#65039; WARNING &#9888;&#65039;\t&#128721; </b></h1></td></tr></table</center></br></br>\n",
    "          \"\"\")\n",
    "\n",
    "    button = widgets.Button(description=\"Accept\")\n",
    "\n",
    "    # Function to handle the selection change\n",
    "    def on_change(change):\n",
    "        global PROJECT_ID\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            #print(\"Selected option:\", change['new'])\n",
    "            PROJECT_ID=change['new']\n",
    "\n",
    "    # Observe the dropdown for changes\n",
    "    dropdown.observe(on_change)\n",
    "\n",
    "    def on_button_click(b):\n",
    "        nonlocal button_pressed\n",
    "        global PROJECT_ID\n",
    "        button_pressed = True\n",
    "        #button.disabled = True\n",
    "        button.close()  # Remove the button from display\n",
    "        with output:\n",
    "          #print(f\"Button pressed...continuing\")\n",
    "          #print(f\"Selected option: {dropdown.value}\")\n",
    "          PROJECT_ID=dropdown.value\n",
    "\n",
    "    button.on_click(on_button_click)\n",
    "    output = widgets.Output()\n",
    "\n",
    "    # Create centered layout\n",
    "    centered_layout = widgets.VBox([\n",
    "                                    html_widget,\n",
    "                                    widgets.HBox([dropdown, button]),\n",
    "                                    html_widget2,\n",
    "    ], layout=widgets.Layout(\n",
    "                              display='flex',\n",
    "                              flex_flow='column',\n",
    "                              align_items='center',\n",
    "                              width='100%'\n",
    "    ))\n",
    "    # Display the layout\n",
    "    display(centered_layout)\n",
    "\n",
    "\n",
    "wait_for_button_press()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zramkw-P93C-"
   },
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1737662703823,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "shY7a4DVQjWB",
    "outputId": "025b3f49-7626-4865-8e2c-870ae59475a2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "#- Google Colab Check\n",
    "# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "import datetime\n",
    "\n",
    "RunningInCOLAB = False\n",
    "RunningInCOLAB = 'google.colab' in str(get_ipython())\n",
    "current_time   = datetime.datetime.now()\n",
    "\n",
    "if RunningInCOLAB:\n",
    "    print(f\"You are running this notebook in Google Colab at {current_time} in the {PROJECT_ID} lab.\")\n",
    "else:\n",
    "    print(f\"You are likely running this notebook with Jupyter iPython runtime at {current_time} in the {PROJECT_ID} lab.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nO_Hq5eq9joH"
   },
   "source": [
    "## Library Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1737662703823,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "UrY5xyjS7Zm-"
   },
   "outputs": [],
   "source": [
    "# Import key libraries necessary to support dynamic installation of additional libraries\n",
    "import sys\n",
    "# Use subprocess to support running operating system commands from the program, using the \"bang\" (!)\n",
    "# symbology is supported, however that does not translate to an actual python script, this is a more\n",
    "# agnostic approach.\n",
    "import subprocess\n",
    "import importlib.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14515,
     "status": "ok",
     "timestamp": 1737662718332,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "fuldWHHM7a2e",
    "outputId": "1d66233f-7c84-43f4-be50-25ca8e0e5839"
   },
   "outputs": [],
   "source": [
    "# Identify the libraries you'd like to add to this Runtime environment.\n",
    "libraries=[\"backoff\", \"nltk\", \"bs4\", \"wordcloud\", \"pathlib\", \"numpy\", \"Pillow\", \"pandas\",\n",
    "           \"python-dotenv\", \"seaborn\", \"rich\", \"rich[jupyter]\", \"piexif\", \"PyMuPDF\",\"unidecode\",\n",
    "           \"spacy\", \"gensim\", \"cluestar\", \"watermark\", \"watermark[GPU]\", \"scattertext\",]\n",
    "\n",
    "# Loop through each library and test for existence, if not present install quietly\n",
    "for library in libraries:\n",
    "    if library == \"Pillow\":\n",
    "      spec = importlib.util.find_spec(\"PIL\")\n",
    "    else:\n",
    "      spec = importlib.util.find_spec(library)\n",
    "    if spec is None:\n",
    "      print(\"Installing library \" + library)\n",
    "      subprocess.run([\"pip\", \"install\" , library, \"--quiet\"], check=True)\n",
    "    else:\n",
    "      print(\"Library \" + library + \" already installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9JLJtz17fpJ"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9922,
     "status": "ok",
     "timestamp": 1737662728244,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "PJuXEPlkSo9p",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#- Import additional libraries that add value to the project related to NLP\n",
    "\n",
    "# Beautiful Soup (BS4) is used to parse HTML documents.\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Word cloud building library\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "#- Set of libraries that perhaps should always be in Python source\n",
    "import backoff\n",
    "import datetime\n",
    "from dotenv import load_dotenv\n",
    "import gc\n",
    "import getopt\n",
    "import glob\n",
    "import inspect\n",
    "import io\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import platform\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "from io import StringIO\n",
    "import subprocess\n",
    "import socket\n",
    "import sys\n",
    "import textwrap\n",
    "import tqdm\n",
    "import traceback\n",
    "import warnings\n",
    "import time\n",
    "from time import perf_counter\n",
    "from rich import print as rprint\n",
    "from rich.console import Console\n",
    "from rich.traceback import install\n",
    "import locale\n",
    "\n",
    "#- Displays system info\n",
    "from watermark import watermark as the_watermark\n",
    "from py3nvml import py3nvml\n",
    "\n",
    "#- Additional libraries for this work\n",
    "import math\n",
    "from base64 import b64decode\n",
    "from IPython.display import Image, Markdown\n",
    "import pandas, IPython.display as display, io, jinja2, base64\n",
    "import requests\n",
    "import unidecode\n",
    "\n",
    "#- Data Science Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "#- Graphics\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.cbook import get_sample_data\n",
    "from matplotlib.offsetbox import (AnnotationBbox, DrawingArea, OffsetImage,\n",
    "                                  TextArea)\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib.patches import Circle\n",
    "from PIL import Image as PIL_Image\n",
    "import PIL.ImageOps\n",
    "\n",
    "#- Image meta-data for Section 508 compliance\n",
    "import piexif\n",
    "from piexif.helper import UserComment\n",
    "\n",
    "\n",
    "#- Progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ML Libs\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9gpU3zJ9l9H"
   },
   "source": [
    "## Application Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1737662728245,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "DoQDWB9s9n7H",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Versioning\n",
    "VERSION_NAME    = \"MLCLASSIFIER\"\n",
    "VERSION_MAJOR   = 0\n",
    "VERSION_MINOR   = 0\n",
    "VERSION_RELEASE = 1\n",
    "\n",
    "# API Parameters for things like WordCloud, variables help hold information for later use\n",
    "# The \"constants\" represent variables that we don't anticipate changing over the course of the program.\n",
    "IMG_BACKGROUND=\"black\"     #options are black, white, another color or None\n",
    "IMG_FONT_SIZE_MIN=10\n",
    "IMG_WIDTH=1024\n",
    "IMG_HEIGHT=768\n",
    "IMG_INTERP=\"bilinear\"\n",
    "IMG_ALPHA=0.8\n",
    "IMG_ASPECT=\"equal\"\n",
    "FIGURE_WIDTH=11\n",
    "FIGURE_HEIGHT=8.5\n",
    "WORD_FREQ=10\n",
    "\n",
    "# specify how image formats will be saved\n",
    "IMG_EXT=\".jpg\"\n",
    "\n",
    "# used to fully display the error stack, set to 1 if you want to see a ridiculous amount of debugging information\n",
    "DEBUG_STACKTRACE=0\n",
    "\n",
    "# location of our working files\n",
    "WORKING_FOLDER=\"/content/folderOnColab\"\n",
    "\n",
    "# Notebook Author details\n",
    "AUTHOR_NAME=\"Christopher G Wood\"\n",
    "GITHUB_USERNAME=\"christophergarthwood\"\n",
    "AUTHOR_EMAIL=\"christopher.g.wood@gmail.com\"\n",
    "\n",
    "# GenAI\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "TEXT_WIDTH=77\n",
    "IMG_SCALE=0.75\n",
    "\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "\n",
    "# Encoding\n",
    "ENCODING  =\"utf-8\"\n",
    "os.environ['PYTHONIOENCODING']=ENCODING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FUa8QJT9tw_"
   },
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1737662728245,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "v_CqUVLZ98Mz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functions are like legos that do one thing, this function outputs library version history of effort.\n",
    "def lib_diagnostics() -> None:\n",
    "\n",
    "    import pkg_resources\n",
    "\n",
    "    package_name_length=20\n",
    "    package_version_length=10\n",
    "\n",
    "    # Show notebook details\n",
    "    #%watermark?\n",
    "    #%watermark --github_username christophergwood --email christopher.g.wood@gmail.com --date --time --iso8601 --updated --python --conda --hostname --machine --githash --gitrepo --gitbranch --iversions --gpu\n",
    "    # Watermark\n",
    "    rprint(the_watermark(author=f\"{AUTHOR_NAME}\", github_username=f\"GITHUB_USERNAME\", email=f\"{AUTHOR_EMAIL}\",iso8601=True, datename=True, current_time=True, python=True, updated=True, hostname=True, machine=True, gitrepo=True, gitbranch=True, githash=True))\n",
    "\n",
    "\n",
    "    print(f\"{BOLD_START}Packages:{BOLD_END}\")\n",
    "    print(\"\")\n",
    "    # Get installed packages\n",
    "    the_packages=[\"nltk\", \"numpy\", \"os\", \"pandas\", \"seaborn\"]\n",
    "    installed = {pkg.key: pkg.version for pkg in pkg_resources.working_set}\n",
    "    for package_idx, package_name in enumerate(installed):\n",
    "         if package_name in the_packages:\n",
    "             installed_version = installed[package_name]\n",
    "             rprint(f\"{package_name:<40}#: {str(pkg_resources.parse_version(installed_version)):<20}\")\n",
    "\n",
    "    try:\n",
    "        rprint(f\"{'TensorFlow version':<40}#: {str(tf.__version__):<20}\")\n",
    "        rprint(f\"{'     gpu.count:':<40}#: {str(len(tf.config.experimental.list_physical_devices('GPU')))}\")\n",
    "        rprint(f\"{'     cpu.count:':<40}#: {str(len(tf.config.experimental.list_physical_devices('CPU')))}\")\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        rprint(f\"{'Torch version':<40}#: {str(torch.__version__):<20}\")\n",
    "        rprint(f\"{'     GPUs available?':<40}#: {torch.cuda.is_available()}\")\n",
    "        rprint(f\"{'     count':<40}#: {torch.cuda.device_count()}\")\n",
    "        rprint(f\"{'     current':<40}#: {torch.cuda.current_device()}\")\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "      print(f\"{'OpenAI Azure Version':<40}#: {str(the_openai_version):<20}\")\n",
    "    except Exception as e:\n",
    "      pass\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1737662728246,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "d45FxezC7_vm"
   },
   "outputs": [],
   "source": [
    "# Routines designed to support adding ALT text to an image generated through Matplotlib.\n",
    "\n",
    "def capture(figure):\n",
    "   buffer = io.BytesIO()\n",
    "   figure.savefig(buffer)\n",
    "   #return F\"data:image/png;base64,{base64.b64encode(buffer.getvalue()).decode()}\"\n",
    "   return F\"data:image/jpg;base64,{base64.b64encode(buffer.getvalue()).decode()}\"\n",
    "\n",
    "def make_accessible(figure, template, **kwargs):\n",
    "   return display.Markdown(F\"\"\"![]({capture(figure)} \"{template.render(**globals(), **kwargs)}\")\"\"\")\n",
    "\n",
    "\n",
    "# requires JPG's or TIFFs\n",
    "def add_alt_text(image_path, alt_text):\n",
    "    try:\n",
    "        if os.path.isfile(image_path):\n",
    "          img = PIL_Image.open(image_path)\n",
    "          if \"exif\" in img.info:\n",
    "              exif_dict = piexif.load(img.info[\"exif\"])\n",
    "          else:\n",
    "              exif_dict={}\n",
    "\n",
    "          w, h = img.size\n",
    "          if \"0th\" not in exif_dict:\n",
    "            exif_dict[\"0th\"]={}\n",
    "          exif_dict[\"0th\"][piexif.ImageIFD.XResolution] = (w, 1)\n",
    "          exif_dict[\"0th\"][piexif.ImageIFD.YResolution] = (h, 1)\n",
    "\n",
    "          software_version=\" \".join([\"STEM-001 with Python v\", str(sys.version).split(\" \")[0]])\n",
    "          exif_dict[\"0th\"][piexif.ImageIFD.Software]=software_version.encode(\"utf-8\")\n",
    "\n",
    "          if \"Exif\" not in exif_dict:\n",
    "            exif_dict[\"Exif\"]={}\n",
    "          exif_dict[\"Exif\"][piexif.ExifIFD.UserComment] = UserComment.dump(alt_text, encoding=\"unicode\")\n",
    "\n",
    "          exif_bytes = piexif.dump(exif_dict)\n",
    "          img.save(image_path, \"jpeg\", exif=exif_bytes)\n",
    "        else:\n",
    "          rprint(f\"Cound not fine {image_path} for ALT text modification, please check your paths.\")\n",
    "\n",
    "    except (FileExistsError, FileNotFoundError, Exception) as e:\n",
    "        process_exception(e)\n",
    "\n",
    "# Appears to solve a problem associated with GPU use on Colab, see: https://github.com/explosion/spaCy/issues/11909\n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1737662728246,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "FCz9ew8r8CX3"
   },
   "outputs": [],
   "source": [
    "# this function displays the stack trace on errors from a central location making adjustments to the display on an error easier to manage\n",
    "# functions perform useful solutions for highly repetitive code\n",
    "def process_exception(inc_exception: Exception) -> None:\n",
    "  if DEBUG_STACKTRACE==1:\n",
    "    traceback.print_exc()\n",
    "    console.print_exception(show_locals=True)\n",
    "  else:\n",
    "    rprint(repr(inc_exception))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbUYh6Tr8GTq"
   },
   "source": [
    "## Setup Instances of Variables for System Configuration and Library Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1737662728246,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "ykbqu-Ku8Lm4"
   },
   "outputs": [],
   "source": [
    "# Setup the rich print console for future use\n",
    "if DEBUG_STACKTRACE==1:\n",
    "  console = Console()\n",
    "\n",
    "# Use the 'Agg' backend for non-interactive environments\n",
    "#matplotlib.use('Agg')\n",
    "\n",
    "# Ensure UTF-8 Encoding is set\n",
    "locale.getpreferredencoding = getpreferredencoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RG0mFzUX-DV1"
   },
   "source": [
    "## Function Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 664
    },
    "executionInfo": {
     "elapsed": 1018,
     "status": "ok",
     "timestamp": 1737662729260,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "SSOOEwn8-FKg",
    "outputId": "f064f361-a318-4809-d7e8-4d4119adb22e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now call the function just created and get input on what versions of software we're using.\n",
    "lib_diagnostics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46JMSTY2QjWD"
   },
   "source": [
    "## Input Sources\n",
    "\n",
    "### Load and prepare the dataset\n",
    "\n",
    "You will use the MNIST dataset to obtain data.\n",
    "\n",
    "*Note*:\n",
    "MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems.  Reference: https://en.wikipedia.org/wiki/MNIST_database\n",
    "\n",
    "This example uses the Fashion MNIST: https://github.com/zalandoresearch/fashion-mnist\n",
    "\n",
    "Fashion MNIST is intended as a drop-in replacement for the classic MNIST dataset—often used as the \"Hello, World\" of machine learning programs for computer vision. The MNIST dataset contains images of handwritten digits (0, 1, 2, etc.) in a format identical to that of the articles of clothing you'll use here.\n",
    "\n",
    "This guide uses Fashion MNIST for variety, and because it's a slightly more challenging problem than regular MNIST. Both datasets are relatively small and are used to verify that an algorithm works as expected. They're good starting points to test and debug code.\n",
    "\n",
    "Here, 60,000 images are used to train the network and 10,000 images to evaluate how accurately the network learned to classify images. You can access the Fashion MNIST directly from TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1737662729260,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "M5y1sWDB8V54",
    "outputId": "c5074799-4594-4eb1-885f-fd94feed844f"
   },
   "outputs": [],
   "source": [
    "# Create the folder that will hold our content.\n",
    "target_folder=WORKING_FOLDER\n",
    "rprint(f\"Creating a folder ({target_folder}) to store project data.\")\n",
    "\n",
    "try:\n",
    "  if os.path.isfile(target_folder):\n",
    "    raise OSError(\"Cannot create your folder a file of the same name already exists there, work with your instructor or remove it yourself.\")\n",
    "  elif os.path.isdir(target_folder):\n",
    "    print(f\"The folder named ({target_folder}) {BOLD_START}already exists{BOLD_END}, we won't try to create a new folder.\")\n",
    "  else:\n",
    "    subprocess.run([\"mkdir\", \"-p\" , target_folder], check=True)\n",
    "except (subprocess.CalledProcessError, Exception) as e:\n",
    "  process_exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1337,
     "status": "ok",
     "timestamp": 1737662730591,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "zVDRXgc1-UZo",
    "outputId": "48f5094d-2058-44ab-9898-0b7ed075dbff",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create reference to dataset\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "#load the data and split into train/test datasets\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1737662730591,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "ooY_0D7N-Yuo",
    "outputId": "6c5c5f48-dd86-4f79-da7f-5569908173d7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Train variable details\n",
    "print(f\"Your {BOLD_START}training data{BOLD_END}:\")\n",
    "rprint(\"{} shape is {}.\".format(\"Train images \", train_images.shape) )\n",
    "rprint(\"{} shape is {}.\".format(\"Train labels \", train_labels.shape) )\n",
    "rprint(\"{} sample structure is {}\".format(\"Train labels\", train_labels))\n",
    "rprint(\"These images and thier corresponding labels represent trusted data to train the model on.\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "#Test variable details\n",
    "print(f\"Your {BOLD_START}testing data{BOLD_END}:\")\n",
    "rprint(\"{} shape is {}.\".format(\"Test images \", test_images.shape) )\n",
    "rprint(\"{} shape is {}.\".format(\"Test labels \", test_labels.shape) )\n",
    "rprint(\"{} sample structure is {}\".format(\"Test labels\", test_labels))\n",
    "rprint(\"These images and thier corresponding labels represent trusted data to test the model on.  How does the model know if it's performing well?\")\n",
    "rprint(\"By using the test data per iteration to check itself.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjHVk42F-lVq"
   },
   "source": [
    "### Dataset Definition\n",
    "\n",
    "The images are 28x28 NumPy arrays, with pixel values ranging from 0 to 255. The labels are an array of integers, ranging from 0 to 9. These correspond to the class of clothing the image represents:\n",
    "\n",
    "Label \tClass\n",
    "\n",
    "+ 0 \tT-shirt/top\n",
    "+ 1 \tTrouser\n",
    "+ 2 \tPullover\n",
    "+ 3 \tDress\n",
    "+ 4 \tCoat\n",
    "+ 5 \tSandal\n",
    "+ 6 \tShirt\n",
    "+ 7 \tSneaker\n",
    "+ 8 \tBag\n",
    "+ 9 \tAnkle boot\n",
    "\n",
    "Each image is mapped to a single label. Since the class names are not included with the dataset, store them here to use later when plotting the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1737662730591,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "9jTKLszX-o8A",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#associate \"human legible\" labels to the actual dataset\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaILuoePQNmj"
   },
   "source": [
    "## Example Image from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1737662730592,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "PCTjK9jR_F93",
    "outputId": "01da0361-e399-4ac1-c8e8-b9d26a893b31",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a random number to pull an image from the training dataset, let's make sure we're getting what's expected.\n",
    "import random\n",
    "x = random.randint(0,train_labels.shape[0])\n",
    "\n",
    "# Show the first image from the training dataset\n",
    "caption_text=f\"28 x 28 image from the training dataset representing a {class_names[train_labels[x]]}, random number is {x}.\"\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f\"Image of {class_names[train_labels[x]]}\")\n",
    "plt.imshow(train_images[x])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "rprint(caption_text)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPMjfihG_CnA"
   },
   "source": [
    "## Preprocess the data\n",
    "\n",
    "Deep learning neural networks learn how to map inputs to outputs from examples in a training dataset.\n",
    "\n",
    "The weights of the model are initialized to small random values and updated via an optimization algorithm in response to estimates of error on the training dataset.\n",
    "\n",
    "Given the use of small weights in the model and the use of error between predictions and expected values, the scale of inputs and outputs used to train the model are an important factor. Unscaled input variables can result in a slow or unstable learning process, whereas unscaled target variables on regression problems can result in exploding gradients causing the learning process to fail.\n",
    "\n",
    "Data preparation involves using techniques such as the normalization and standardization to rescale input and output variables prior to training a neural network model.\n",
    "\n",
    "The data must be preprocessed before training the network. If you inspect the first image in the training set, you will see that the pixel values fall in the range of 0 to 255.\n",
    "\n",
    "Scale these values to a range of 0 to 1 before feeding them to the neural network model. To do so, divide the values by 255. It's important that the training set and the testing set be preprocessed in the same way.  Ultimately your inference / prediction of data will follow the same method of scaling.\n",
    "\n",
    "If you don't make your inference inputs align to the same method(s) you used during training, you cannot expect the same level of quality result obtained during training.\n",
    "\n",
    "**Reference**: https://machinelearningmastery.com/how-to-improve-neural-network-stability-and-modeling-performance-with-data-scaling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 355,
     "status": "ok",
     "timestamp": 1737662730938,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "fdBgQHkF_Roe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scale the images between 0 - 1\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oa3V9P3H_ZMH"
   },
   "source": [
    "## Show Sample Data\n",
    "Show the first 25 images from the training dataset and display the classification name with each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 762
    },
    "executionInfo": {
     "elapsed": 1082,
     "status": "ok",
     "timestamp": 1737662732018,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "4ogHRMro_cqp",
    "outputId": "8007c45e-8d82-464d-cfe9-112a4d7f0331",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verification of dataset.\n",
    "# Did you notice a difference in the output of the data?  What's the difference between the first image seen and these images?\n",
    "\n",
    "IMG_TO_SHOW=20\n",
    "\n",
    "caption_start=f\"28 x 28 image from the training dataset representing a:\"\n",
    "caption_end = \" as seen from top to bottom, left to right.\"\n",
    "the_labels=[]\n",
    "for idx in range(IMG_TO_SHOW):\n",
    "    the_labels.append(class_names[train_labels[idx]])\n",
    "caption_labels=\", \".join(the_labels)\n",
    "caption_text = \" \".join([caption_start, caption_labels, caption_end])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(FIGURE_WIDTH,FIGURE_HEIGHT))\n",
    "plt.title(\"Training Dataset of MNIST Clothing\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "for i in range(IMG_TO_SHOW):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "target_filename=target_folder+os.sep+f\"STEM-005_MNIST_Clothing_Normalized_TrainingData{IMG_EXT}\";\n",
    "plt.savefig(target_filename);\n",
    "plt.show()\n",
    "print(\"\")\n",
    "rprint(caption_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jm3e80M4Ka47"
   },
   "source": [
    "## Before we start...\n",
    "\n",
    "*Let's talk about CPU versus GPU.*\n",
    "\n",
    "A central processing unit (CPU) and a graphics processing unit (GPU) are both essential components of a computer, but they have different functions and architectures:\n",
    "\n",
    "### CPU\n",
    "\n",
    "The CPU is the core of a computer's processing system and is responsible for handling all the computing tasks that allow the operating system and applications to run. CPUs are often referred to as the \"brain\" of the computer and are well suited to a wide range of tasks.\n",
    "\n",
    "### GPU\n",
    "\n",
    "GPUs are considered superior for Artificial Intelligence and Machine Learning (AIML) because of their unique architecture designed for parallel processing, allowing them to perform a large number of calculations simultaneously, which is ideal for the complex mathematical operations involved in training and running AI models, especially when dealing with large datasets; essentially, GPUs can process massive amounts of data much faster than CPUs due to their numerous cores optimized for parallel computations.\n",
    "\n",
    "Here are some other differences between CPUs and GPUs:\n",
    "\n",
    "+ Parallel Processing:\n",
    "GPUs have thousands of smaller cores that can handle multiple calculations simultaneously, making them perfect for tasks that involve repetitive operations on large datasets, like matrix multiplications used in neural networks.\n",
    "\n",
    "+ High Memory Bandwidth:\n",
    "GPUs have dedicated high-speed memory (like GDDR6) which allows for rapid data transfer between the processing cores, crucial for feeding large amounts of data efficiently.\n",
    "\n",
    "+ Optimized for AI Frameworks:\n",
    "Major GPU manufacturers like NVIDIA have developed specialized libraries and frameworks (like CUDA) that are highly optimized for AI workloads, further accelerating performance.\n",
    "\n",
    "+Faster Training Time:\n",
    "By leveraging parallel processing, GPUs significantly reduce the time needed to train complex AI models, enabling faster iteration and experimentation.\n",
    "\n",
    "***If the only thing you remember is this then you're okay...ALWAYS try to utilize the GPU and make sure you're actually using it.***\n",
    "\n",
    "**Reference:** https://blogs.nvidia.com/blog/why-gpus-are-great-for-ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1737662732019,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "UyI-12xpMfGH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup some basic timers material\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WtYiLzbLOsS"
   },
   "source": [
    "## Let's see what we've got..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "executionInfo": {
     "elapsed": 169,
     "status": "ok",
     "timestamp": 1737662732177,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "FQfbIdZcLNSu",
    "outputId": "a73f6ce6-7a22-43d8-973c-0d72d6de35d5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"{BOLD_START}List Devices{BOLD_END} #########################################\")\n",
    "try:\n",
    "  from tensorflow.python.client import device_lib\n",
    "  rprint(device_lib.list_local_devices())\n",
    "  print(\"\")\n",
    "except RuntimeError as e:\n",
    "  # Visible devices must be set before GPUs have been initialized\n",
    "  rprint(str(repr(e)))\n",
    "\n",
    "print(f\"{BOLD_START}Devices Counts{BOLD_END} ########################################\")\n",
    "try:\n",
    "  rprint(f\"Num GPUs Available: {str(len(tf.config.experimental.list_physical_devices('GPU')))}\" )\n",
    "  rprint(f\"Num CPUs Available: {str(len(tf.config.experimental.list_physical_devices('CPU')))}\" )\n",
    "  print(\"\")\n",
    "except RuntimeError as e:\n",
    "  # Visible devices must be set before GPUs have been initialized\n",
    "  rprint(str(repr(e)))\n",
    "\n",
    "print(f\"{BOLD_START}Optional Enablement{BOLD_END} ####################################\")\n",
    "try:\n",
    "  gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "except RuntimeError as e:\n",
    "  # Visible devices must be set before GPUs have been initialized\n",
    "  rprint(str(repr(e)))\n",
    "\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    rprint( str( str(len(gpus)) + \" Physical GPUs,\" + str(len(logical_gpus)) + \" Logical GPU\") )\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    rprint(str(repr(e)))\n",
    "  print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpnTDr3-OYRf"
   },
   "source": [
    "## Set logging constructs and use the OS environment to control access to hardware\n",
    "\n",
    "TensorFlow uses the standard Python logging levels, which are:\n",
    "\n",
    "+ DEBUG: Detailed information, typically only useful for debugging.\n",
    "\n",
    "+ INFO: General information about the progress of the program.\n",
    "\n",
    "+ WARN: Warnings about potential issues that may not cause the program to fail.\n",
    "\n",
    "+ ERROR: Errors that prevent the program from continuing.\n",
    "\n",
    "+ FATAL: Critical errors that cause the program to terminate immediately.\n",
    "\n",
    "How to control logging levels:\n",
    "\n",
    "**TF_CPP_MIN_LOG_LEVEL** environment variable: This variable controls the minimum log level for TensorFlow's C++ backend.\n",
    "\n",
    "+ 0: Log all messages.\n",
    "+ 1: Log all messages except INFO.\n",
    "+ 2: Log all messages except INFO and WARNING (default).\n",
    "+3: Log all messages except INFO, WARNING, and ERROR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1737662732177,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "20rbSkh3ObtS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '10'\n",
    "#To disable GPU access to the current runtime enable -1 for \"no GPUs\"\n",
    "#confirmed to work on the Command Line Interface (CLI) of all systems but this one...\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqcT6UOLLSL3"
   },
   "source": [
    "## Now Train on CPU only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spqo9lXN_hKo"
   },
   "source": [
    "## Build the model\n",
    "\n",
    "Building the neural network requires configuring the layers of the model, then compiling the model.\n",
    "\n",
    "### Set up the layers\n",
    "\n",
    "The basic building block of a neural network is the layer. Layers extract representations from the data fed into them.\n",
    "\n",
    "Most of deep learning consists of chaining together simple layers. Most layers, such as tf.keras.layers.Dense, have parameters that are learned during training.\n",
    "\n",
    "Rectified linear unit (ReLU), is an activation function which means, this is how the neuron determines if it's going to fire (weighting of probabilities). See: https://en.wikipedia.org/wiki/Rectifier_(neural_networks) The short version is that ReLU is considered an excellent tool and using a vanishing gradient to determine probabilities always making sure any value less than zero is set to 0.\n",
    "\n",
    "Your output layer must equal the number of questions you're seeking to ask.  In this case we have ten (10) categories of clothing so we need 10 neurons to represent those different potential answers.\n",
    "\n",
    "Notice that the \"shape\" of the first layer corresponds to the shape of the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33405,
     "status": "ok",
     "timestamp": 1737663900579,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "y61jBamv_kQu",
    "outputId": "6fc79d34-0aa8-413e-8286-b33e64431e26",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Given the images and labels begin learning from the train_* dataset for multiple \"iterations\".\n",
    "# Note that you are ACTIVELY training a neural layer (AI) solution now.\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "start_t=perf_counter()\n",
    "\n",
    "try:\n",
    "  # by using \"with\" you assign the memory and processing to that device\n",
    "  with tf.device('/job:localhost/replica:0/task:0/device:CPU:0'):\n",
    "\n",
    "    #DESIGN/BUILD\n",
    "    #capture the function calls return into a variable, this encapsulate a complex object that defines the entire neural model\n",
    "    model = tf.keras.Sequential([\n",
    "        #one-D array are preferred for all processing\n",
    "        #The first layer in this network, tf.keras.layers.Flatten, transforms the format of the images from a two-dimensional array\n",
    "        #(of 28 by 28 pixels) to a one-dimensional array (of 28 * 28 = 784 pixels). Think of this layer as unstacking rows of pixels\n",
    "        #in the image and lining them up. This layer has no parameters to learn; it only reformats the data.\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "\n",
    "        #first layer is 128 neurons and a ReLU activation function.\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "\n",
    "        #output layer defined\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    #COMPILE\n",
    "    model.compile(optimizer='adam',\n",
    "              #v2.1 accepts this activation method but previous versions DO NOT\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    #FIT/TRAIN\n",
    "    model.fit(train_images, train_labels, epochs=10)\n",
    "except RuntimeError as e:\n",
    "  print(str(repr(e)))\n",
    "\n",
    "\n",
    "end_t=perf_counter()\n",
    "print(f\"Elapsed time: {end_t - start_t}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWtT5s9z_oer"
   },
   "source": [
    "## Compile the model\n",
    "\n",
    "Before the model is ready for training, it needs a few more settings. These are added during the model's compile step:\n",
    "\n",
    "+ Loss function —This measures how accurate the model is during training. You want to minimize this function to \"steer\" the model in the right direction.\n",
    "\n",
    "+ Optimizer —This is how the model is updated based on the data it sees and its loss function.\n",
    "\n",
    "+ Metrics —Used to monitor the training and testing steps. The following example uses accuracy, the fraction of the images that are correctly classified.\n",
    "\n",
    "### Loss Functions\n",
    "\n",
    "In artificial intelligence (AI), a \"loss function\" is a mathematical function that measures the difference between a model's predicted output and the actual target value, essentially quantifying how \"wrong\" the model's prediction is; the goal during training is to minimize this loss value by adjusting the model's parameters to improve its accuracy on the data.\n",
    "\n",
    "Examples of common loss functions:\n",
    "\n",
    "+ Mean Squared Error (MSE):\n",
    "Used in regression tasks, calculates the average squared difference between predicted and actual values.\n",
    "\n",
    "+ Cross-Entropy Loss:\n",
    "Commonly used in classification problems, measures the difference between the model's predicted probability distribution and the true class distribution.\n",
    "\n",
    "+ Hinge Loss:\n",
    "Often used in support vector machines (SVMs), penalizes predictions that are not sufficiently far from the correct class boundary.\n",
    "\n",
    "How loss functions work in practice:\n",
    "\n",
    "+ Prediction: The model makes a prediction on a data point.\n",
    "\n",
    "+ Loss calculation: The loss function compares the prediction to the actual target value, calculating the error.\n",
    "\n",
    "+Backpropagation: The calculated loss is used to adjust the model's parameters (weights) through a process called backpropagation, aiming to reduce the loss on subsequent iterations.\n",
    "\n",
    "### Optimization Algorithms\n",
    "\n",
    "Optimization algorithms:Optimization algorithms are a class of algorithms that are used to find the best possible solution to a given problem. The goal of an optimization algorithm is to find the optimal solution that minimizes or maximizes a given objective function. There are many different types of optimization algorithms, each with its own strengths and weaknesses. Some of the most popular optimization algorithms include gradient descent, conjugate gradient, Newton's Method, and Simulated Annealing.\n",
    "\n",
    "Optimization algorithms are powerful tools for solving complex problems. They have the potential to revolutionize how we interact with data. The optimization process involves taking a given set of parameters and finding the optimal solution that maximizes value or minimizes cost, depending on the objective function being optimized. In this article, an overview of optimization algorithms is presented along with some examples of their application in real-world scenarios.\n",
    "\n",
    "The power of these algorithms lies in their ability to make decisions based on accurate models and data obtained from physical experiments or simulations. This means they can be used to solve problems quickly without having to rely solely on manual processes. For example, optimization algorithms can be used to find solutions for traveling salesman problems (TSPs), which involve finding the shortest route between multiple destinations while minimizing costs associated with time, fuel consumption, etc.\n",
    "\n",
    "In addition to TSPs, many other applications exist including scheduling tasks and resources efficiently, controlling robotic arms accurately and achieving maximum profit in manufacturing operations. Put simply, when it comes to problem-solving, optimization algorithms provide a way for us to optimize our outcomes quickly and precisely - making them invaluable assets for many different industries today.\n",
    "\n",
    "What Is The Meaning Of Optimization Algorithm?\n",
    "Optimization algorithms are powerful tools used to solve optimization problems. They can be characterized as algorithms that try to find the most efficient solution when given a set of conditions or constraints. Optimization algorithms have been employed in various fields, such as engineering and operations research. The type of algorithm used depends on the nature of the problem being solved; for example, convex optimization is suitable for continuous functions while discrete optimization may be used if an integer value is desired. Additionally, there are approximation algorithms which search for near-optimal solutions and combinatorial optimization techniques which focus on finding effective ways to combine elements from distinct sets.\n",
    "\n",
    "Stochastic gradient descent (SGD) is one of the most popular optimization techniques because it has proven to be extremely efficient in practice and easy to implement with little computation cost. SGD works by iteratively calculating a parameter vector using data points sampled from a training dataset until convergence or maximum iterations are reached. This method guarantees high accuracy results even with limited computational resources since it only requires small adjustments at each iteration step instead of optimizing all parameters simultaneously. Furthermore, SGD performs well in presence of noisy data due to its robustness against outliers compared to other approaches like quadratic programming and trust region methods.\n",
    "\n",
    "In summary, optimization algorithms are essential components for solving complex optimization problems efficiently with few resources required. While some techniques such as stochastic gradient descent provide fast and reliable results, others like convex optimisation require more careful analysis before use depending on the specific problem requirements. All these methods make up a comprehensive suite of options available for tackling any kind of task requiring optimal solutions quickly and reliably.\n",
    "\n",
    "### Metrics\n",
    "\n",
    "AI metrics are mathematical formulas that measure the performance of AI systems. They can be used to assess the accuracy, efficiency, and fairness of AI systems.\n",
    "\n",
    "#### Accuracy metrics\n",
    "\n",
    "+ Accuracy: The proportion of correct predictions out of all predictions\n",
    "\n",
    "+ Precision: The proportion of correct positive predictions out of all positive predictions\n",
    "\n",
    "+ Recall: The proportion of correct positive predictions out of all positive instances\n",
    "\n",
    "+F1 score: The harmonic mean of precision and recall\n",
    "\n",
    "+ Mean Squared Error (MSE): The average squared difference between predicted and actual values\n",
    "\n",
    "#### Efficiency metrics\n",
    "\n",
    "+ Throughput: The amount of work processed in a given time\n",
    "\n",
    "+ Resource utilization rates: How much resources are used to complete tasks\n",
    "\n",
    "+ Human intervention: How much human intervention is required for automated processes\n",
    "\n",
    "#### Fairness metrics\n",
    "\n",
    "+ Bias: Whether the AI system is making biased decisions\n",
    "\n",
    "+ Accountability: Whether the AI system can be held accountable for its decisions\n",
    "\n",
    "#### Performance metrics\n",
    "\n",
    "+ System uptime: How long the system is available\n",
    "\n",
    "+ Response times: How long it takes for the system to respond\n",
    "\n",
    "+ Error rates: How often the system makes errors\n",
    "\n",
    "+ User interactions: How well the system interacts with users\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3K60Ov0_w-C"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "### Training the neural network model requires the following steps:\n",
    "\n",
    "    1. Feed the training data to the model. In this example, the training data is in the train_images and train_labels arrays.\n",
    "    2. The model learns to associate images and labels.\n",
    "    3. You ask the model to make predictions about a test set—in this example, the test_images array.\n",
    "    4. Verify that the predictions match the labels from the test_labels array.\n",
    "\n",
    "## Train the model\n",
    "\n",
    "### Training the neural network model requires the following steps:\n",
    "\n",
    "    1. Feed the training data to the model. In this example, the training data is in the train_images and train_labels arrays.\n",
    "    2. The model learns to associate images and labels.\n",
    "    3. You ask the model to make predictions about a test set—in this example, the test_images array.\n",
    "    4. Verify that the predictions match the labels from the test_labels array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWlucJVxMQyx"
   },
   "source": [
    "## Now Train on GPU only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1737662732816,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "xUoizdzYMTXy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Given the images and labels begin learning from the train_* dataset for 10 \"iterations\".\n",
    "# Note that you are ACTIVELY training a neural layer (AI) solution now.\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "start_t=perf_counter()\n",
    "\n",
    "try:\n",
    "  with tf.device('/job:localhost/replica:0/task:0/device:GPU:0'):\n",
    "\n",
    "    #DESIGN/BUILD\n",
    "    #capture the function calls return into a variable, this encapsulate a complex object that defines the entire neural model\n",
    "    model = tf.keras.Sequential([\n",
    "        #one-D array are preferred for all processing\n",
    "        #The first layer in this network, tf.keras.layers.Flatten, transforms the format of the images from a two-dimensional array\n",
    "        #(of 28 by 28 pixels) to a one-dimensional array (of 28 * 28 = 784 pixels). Think of this layer as unstacking rows of pixels\n",
    "        #in the image and lining them up. This layer has no parameters to learn; it only reformats the data.\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "\n",
    "        #first layer is 128 neurons and a ReLU activation function.\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "\n",
    "        #output layer defined\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    #COMPILE\n",
    "    model.compile(optimizer='adam',\n",
    "              #v2.1 accepts this activation method but previous versions DO NOT\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    #FIT/TRAIN\n",
    "    model.fit(train_images, train_labels, epochs=20)\n",
    "except RuntimeError as e:\n",
    "  print(str(repr(e)))\n",
    "\n",
    "\n",
    "end_t=perf_counter()\n",
    "print(f\"Elapsed time: {end_t - start_t}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvscSmDkAARI"
   },
   "source": [
    "## Epochs\n",
    "\n",
    "Notice each epoc completion demonstrates an accuracy improvement.  You can add a *patience* function to drop out when your training reaches an optimal level to avoid overfitting.  Additional *drop out* functions are available as well.\n",
    "\n",
    "In artificial intelligence, an \"epoch\" refers to a single complete pass of the entire training dataset through a machine learning model, where the model processes every data point once and updates its internal parameters based on that pass, essentially representing one full cycle of learning from the training data; it's a key metric used to measure how many times the model has seen the entire dataset during training.\n",
    "\n",
    "## Key points about epochs:\n",
    "\n",
    "+ Full data pass:\n",
    "An epoch is completed when the model has processed every data point in the training set once.\n",
    "\n",
    "+ Hyperparameter:\n",
    "The number of epochs to run is considered a hyperparameter that needs to be tuned for optimal model performance.\n",
    "\n",
    "+ Batching:\n",
    "While processing the data, the dataset is often split into smaller batches, and the model updates its parameters after each batch, but one full pass through all batches constitutes an epoch.\n",
    "\n",
    "### Why epochs matter:\n",
    "\n",
    "+ Learning progression:\n",
    "By running multiple epochs, the model can gradually learn more complex patterns from the data.\n",
    "\n",
    "+ Overfitting risk:\n",
    "Training for too many epochs can lead to overfitting, where the model becomes too specialized to the training data and performs poorly on new data.\n",
    "\n",
    "+ Validation monitoring:\n",
    "To avoid overfitting, it's crucial to monitor the model's performance on a separate validation set after each epoch and stop training when validation accuracy starts to decline.\n",
    "\n",
    "***Ask the instructor what other drop out functions are available.***\n",
    "\n",
    "## Evaluate accuracy\n",
    "\n",
    "Now we see how well the model performs.  The `evaluate()` function performs a prediction by taking the test_* inputs and and performing a diff between actual data and predicted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1737662732816,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "EpjzICjlABCl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "teG2v-OjAR-g"
   },
   "source": [
    "As previously discussed overfitting is a concern.  Notes from the demonstration code:\n",
    "\n",
    "It turns out that the accuracy on the test dataset is a little less than the accuracy on the training dataset. This gap between training accuracy and test accuracy represents overfitting. Overfitting happens when a machine learning model performs worse on new, previously unseen inputs than it does on the training data. An overfitted model \"memorizes\" the noise and details in the training dataset to a point where it negatively impacts the performance of the model on the new data. For more information, see the following:\n",
    "\n",
    "1.  Demonstration of overfitting - https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#demonstrate_overfitting\n",
    "2.  Strategies to prevent overfitting - https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#strategies_to_prevent_overfitting\n",
    "\n",
    "\n",
    "## Make Predictions\n",
    "\n",
    "With the model trained, you can use it to make predictions about some images. The model's linear outputs, logits. Attach a softmax layer to convert the logits to probabilities, which are easier to interpret.\n",
    "\n",
    "### Logits\n",
    "\n",
    "The vector of raw (non-normalized) predictions that a classification model generates, which is ordinarily then passed to a normalization function. If the model is solving a multi-class classification problem, logits typically become an input to the softmax function. The softmax function then generates a vector of (normalized) probabilities with one value for each possible class.\n",
    "\n",
    "Said another way...\n",
    "\n",
    "For multi-class classification, the model outputs a logit for each class. The softmax function is then applied to these logits to convert them into probabilities which will sum up to 1. The class with the highest probability, determined by the largest logit, is chosen as the model's prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1737662732817,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "V1qIb9l0AS58",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define another model designed to help identify classes\n",
    "\n",
    "probability_model = tf.keras.Sequential([model,\n",
    "                                         tf.keras.layers.Softmax()])\n",
    "\n",
    "# Given the test images what labels have precipitated out?\n",
    "predictions = probability_model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1737662732817,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "mmr5ALYlAYb5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's see what the predictions resulting data structure looks like on the inside.\n",
    "predictions\n",
    "\n",
    "#the resultant is an array of arrays [][]\n",
    "# each row represents each image predicted against\n",
    "#   each column in each row are the probabilities for each \"class\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4tnwTd4AAfxh"
   },
   "source": [
    "## Let's see what the predictions resulting data structure looks like on the inside.\n",
    "\n",
    "Predictions for the first input (image) submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1737662732817,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "mL4lkSKPAggd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# raw output\n",
    "print(predictions[0])\n",
    "print(\"\")\n",
    "\n",
    "# cleaned output\n",
    "rprint(predictions[0])\n",
    "print(\"\")\n",
    "\n",
    "# or said another way\n",
    "rprint(\"For the first inference the following probabilities are calculated:\")\n",
    "for idx, value in enumerate(predictions[0]):\n",
    "  rprint(f\"[{idx}] {class_names[idx]:15}- {value:0.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1737662732817,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "aFIkYri6AiIK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Numpy magic, obtain the highest value of the array\n",
    "the_answer=np.argmax(predictions[0])\n",
    "\n",
    "# So for the first test image the most likely candidate for a class is element 9 in the array (remember, arrays go from 0..9)\n",
    "# What does element 9 in the classes array defined earlier represent?  what class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Yle-wTgAoxg"
   },
   "source": [
    "So, the model is most confident that this image is an ankle boot, or class_names[9]. Examining the test label shows that this classification is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1737662732817,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "8IC1_sl3AmvW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "rprint(\"Label {} relates to a {}.\".format(the_answer,class_names[np.argmax(predictions[0])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0Bj-6h7A41S"
   },
   "source": [
    "Graph this to look at the full set of 10 class predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1737662732817,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "0MsE2JLBAt3r",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#functions defined to show the item and relevance of the prediction\n",
    "\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  predictions_array, true_label = predictions_array, true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(10))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFx6OGloA-E6"
   },
   "source": [
    "Let's plot several images with their predictions. Note that the model can be wrong even when very confident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1737662732817,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "JnDI7RqwA7YR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the first X test images, their predicted labels, and the true labels.\n",
    "# Color correct predictions in blue and incorrect predictions in red.\n",
    "num_rows = 3\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "\n",
    "caption_start=f\"28 x 28 image from the test dataset representing an image of the actual test data and a corresponding plot to the right of the image showing the probability distribution for the following data:\"\n",
    "caption_end = \" as seen from top to bottom, left to right.\"\n",
    "the_labels=[]\n",
    "for idx in range(num_images):\n",
    "    the_labels.append(class_names[train_labels[idx]])\n",
    "caption_labels=\", \".join(the_labels)\n",
    "caption_text = \" \".join([caption_start, caption_labels, caption_end])\n",
    "\n",
    "\n",
    "plt.figure(figsize=((2*2*num_cols, 2*num_rows)))\n",
    "plt.title(\"Inferences of MNIST Clothing Test Data\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(i, predictions[i], test_labels, test_images)\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(i, predictions[i], test_labels)\n",
    "    plt.tight_layout()\n",
    "    plt.grid(False)\n",
    "    #plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "\n",
    "target_filename=target_folder+os.sep+f\"STEM-005_MNIST_Clothing_Inference_TestData{IMG_EXT}\";\n",
    "plt.savefig(target_filename);\n",
    "plt.show()\n",
    "print(\"\")\n",
    "rprint(caption_text)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "STEM-005_Classifier.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/christophergarthwood/jbooks/blob/main/STEM-001_WordClouds.ipynb",
     "timestamp": 1716214402332
    }
   ]
  },
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06d2f305876c4b37b5d403d3a8c09017": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0cae0449cbaa40c4abd69027ed4b8a52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Accept",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_06d2f305876c4b37b5d403d3a8c09017",
      "style": "IPY_MODEL_c734f36fdc7d408f9e9ee69bd0615730",
      "tooltip": ""
     }
    },
    "1e8c438f2fc3435f8b69ec9158fb9ef9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35c3b2bbc1324552b5ab4d2b1f076ca1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5319161667c547f1ba6240c426fba8b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "54fcd04b1c474fbc96cde3b35afcddf9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b941a36785e460ca8596b3971973925",
      "placeholder": "​",
      "style": "IPY_MODEL_1e8c438f2fc3435f8b69ec9158fb9ef9",
      "value": "\n        <center><table><tr><td><h1 style=\"font-family: Roboto;font-size: 24px\"><b>&#128721; &#9888;&#65039; WARNING &#9888;&#65039;\t&#128721; </b></h1></td></tr></table</center></br></br>\n          "
     }
    },
    "8119b099c8834c1c8cf40292824bfcb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ca2f6fe8655d4ac2a673ec508f165221",
       "IPY_MODEL_0cae0449cbaa40c4abd69027ed4b8a52"
      ],
      "layout": "IPY_MODEL_ad544439b79f498186efaf5ebbd9a9c5"
     }
    },
    "9b941a36785e460ca8596b3971973925": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad544439b79f498186efaf5ebbd9a9c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c734f36fdc7d408f9e9ee69bd0615730": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "c7559d0f0bab4c58b7905432d1026bd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca2f6fe8655d4ac2a673ec508f165221": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "usfs-ai-bootcamp",
       "usfa-ai-advanced-training",
       "I will setup my own"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Set Your Project:",
      "description_tooltip": null,
      "disabled": false,
      "index": 0,
      "layout": "IPY_MODEL_cf67f07a92034b00b24616b43d828deb",
      "style": "IPY_MODEL_d1530ba138d841bf817892b3807c488b"
     }
    },
    "cf67f07a92034b00b24616b43d828deb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1530ba138d841bf817892b3807c488b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e9eae00320e74b3587e85c55e8d7688c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fd7779ddb26f4611b0a4f52289915ade",
       "IPY_MODEL_8119b099c8834c1c8cf40292824bfcb0",
       "IPY_MODEL_54fcd04b1c474fbc96cde3b35afcddf9"
      ],
      "layout": "IPY_MODEL_5319161667c547f1ba6240c426fba8b8"
     }
    },
    "fd7779ddb26f4611b0a4f52289915ade": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35c3b2bbc1324552b5ab4d2b1f076ca1",
      "placeholder": "​",
      "style": "IPY_MODEL_c7559d0f0bab4c58b7905432d1026bd4",
      "value": "\n        <center><table><tr><td><h1 style=\"font-family: Roboto;font-size: 24px\"><b>&#128721; &#9888;&#65039; WARNING &#9888;&#65039;\t&#128721; </b></h1></td></tr></table</center></br></br>\n\n        <table><tr><td>\n            <span style=\"font-family: Tahoma;font-size: 18\">\n              This notebook was designed to work in Jupyter Notebook or Google Colab with the understnading that certain permissions might be enabled.</br>\n              Please verify that you are in the appropriate project and that the:</br>\n              <center><code><b>PROJECT_ID</b></code> </br></center>\n              aligns with the Project Id in the upper left corner of this browser and that the location:\n              <center><code><b>LOCATION</b></code> </br></center>\n              aligns with the instructions provided.\n            </span>\n          </td></tr></table></br></br>\n\n    "
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
