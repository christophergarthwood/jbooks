{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jg3iJooMQjWA"
   },
   "source": [
    "# Artificial Intelligence\n",
    "## AI Ready Data - 006\n",
    "### Download, curate, and process weather and tree data.\n",
    "\n",
    "<center>\n",
    "<table align=\"center\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/christophergarthwood/jbooks/blob/main/STEM-006_AIReadyData.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/notebooks?referrer=search&hl=en&project=usfs-ai-bootcamp\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Link to Colab Enterprise\n",
    "    </a>\n",
    "  </td>   \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/christophergarthwood/jbooks/blob/main/STEM-006_AIReadyData.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/instances?referrer=search&hl=en&project=usfs-ai-bootcamp\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Link to Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "</center>\n",
    "</br></br></br>\n",
    "\n",
    "| | |\n",
    "|-|-|\n",
    "|Author(s) | [Christopher G Wood](https://github.com/christophergarthwood)  |\n",
    "\n",
    "# Overview\n",
    "\n",
    "Using various data sources we will download, review, and package data in various formats exploring the options for \"AI Ready\" data and what that means.\n",
    "\n",
    "## What is a \"**AI Ready**\" Data?\n",
    "\n",
    "\n",
    "## References:\n",
    "\n",
    "#### Data Formats\n",
    "+ [List of ML File Formats](https://github.com/trailofbits/ml-file-formats)\n",
    "+ [ML Guide to Data Formats](https://www.hopsworks.ai/post/guide-to-file-formats-for-machine-learning)\n",
    "+ [Why are ML Data Structures Different?](https://stackoverflow.blog/2023/01/04/getting-your-data-in-shape-for-machine-learning/)\n",
    "\n",
    "#### FAIR\n",
    "+ [FAIR and AI-Ready](https://repository.niddk.nih.gov/public/NIDDKCR_Office_Hours_AI-Readiness_and_Preparing_AI-Ready_+Datasets_12_2023.pdf)\n",
    "+ [AI-Ready-Data](https://www.rishabhsoft.com/blog/ai-ready-data)\n",
    "+ [AI-Ready FAIR Data](https://medium.com/@sean_hill/ai-ready-fair-data-accelerating-science-through-responsible-ai-and-data-stewardship-3b4f21c804fd)\n",
    "+ [AI-Ready Data ... Quality](https://www.elucidata.io/blog/building-ai-ready-data-why-quality-matters-more-than-quantity)\n",
    "+ [AI-Ready Data Explained](https://acodis.io/hubfs/pdfs/AI-ready%20data%20Explained%20Whitepaper%20(1).pdf)\n",
    "\n",
    "+ [GCP with BigQuery DataFrames](https://cloud.google.com/blog/products/data-analytics/building-aiml-apps-in-python-with-bigquery-dataframes)\n",
    "\n",
    "#### Format Libraries / Standards\n",
    "+ [Earth Science Information partners (ESIP)](https://www.esipfed.org/checklist-ai-ready-data/)\n",
    "+ [Zarr - Storage of N-dimensional arrays (tensors)](https://zarr.dev/#description)\n",
    "  + [Zarr explained](https://aijobs.net/insights/zarr-explained/)\n",
    "+ [Apache Parquet](https://parquet.apache.org/)\n",
    "  + [All about Parquet](https://medium.com/data-engineering-with-dremio/all-about-parquet-part-01-an-introduction-b62a5bcf70f8)\n",
    "+ [PySTAC - SpatioTemporal Asset Catalogs](https://pystac.readthedocs.io/en/stable/)\n",
    "  + [John Hogland's Spatial Modeling Tutorials](https://github.com/jshogland/SpatialModelingTutorials/blob/main/README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1737665372909,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "M3qlCehNBu-_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's define some variables (information holders) for our project overall\n",
    "\n",
    "global PROJECT_ID, BUCKET_NAME, LOCATION\n",
    "BUCKET_NAME =\"cio-training-vertex-colab\"\n",
    "PROJECT_ID  =\"usfs-ai-bootcamp\"\n",
    "LOCATION    = \"us-central1\"\n",
    "\n",
    "BOLD_START=\"\\033[1m\"\n",
    "BOLD_END=\"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508,
     "referenced_widgets": [
      "1015b1ce380943d48c7a6386444c768a",
      "f5405303114146a28663cb1c46db7beb",
      "bdc74a6d20a041819b6fc6d1c3f85a25",
      "033cb5a8c21c4ca5a13b5d03e8b78fa0",
      "2b447186de7a4571821ca59295744ce3",
      "cf363ab273bf4eeba7fbea4d79ed3a64",
      "479233081fbc44c8afe9a044ebb95faf",
      "202c8798fdda4778bf09a2124c37a6c7",
      "ad3b9f4855d541e49303c03fb9f07db7",
      "0d8988d435644a928829ef71435a3e83",
      "ebb9ca01cf52473699f21f15c5ec7d34",
      "689fe090492947608518efc9f3bd6d5d",
      "dd3de71c792f4762af3b280ac9b7f5e6",
      "fc3fc48bdebe4501998819fbda36152c",
      "f196621910824a00a97d06e5433cb294",
      "31b012d7d41a4d06933aa38e8e3bd74a"
     ]
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1737665373417,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "3TrA1A5nIeCV",
    "outputId": "65ad0051-dd12-4511-e88f-62bf0f35300e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9440744cb274a1596012e4b176c3ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n        <center><table><tr><td><h1 style=\"font-family: Roboto;font-size: 24px\"><bâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now create a means of enforcing project id selection\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def wait_for_button_press():\n",
    "\n",
    "    button_pressed = False\n",
    "\n",
    "    # Create widgets\n",
    "    html_widget = widgets.HTML(\n",
    "\n",
    "    value=\"\"\"\n",
    "        <center><table><tr><td><h1 style=\"font-family: Roboto;font-size: 24px\"><b>&#128721; &#9888;&#65039; WARNING &#9888;&#65039;\t&#128721; </b></h1></td></tr></table</center></br></br>\n",
    "\n",
    "        <table><tr><td>\n",
    "            <span style=\"font-family: Tahoma;font-size: 18\">\n",
    "              This notebook was designed to work in Jupyter Notebook or Google Colab with the understnading that certain permissions might be enabled.</br>\n",
    "              Please verify that you are in the appropriate project and that the:</br>\n",
    "              <center><code><b>PROJECT_ID</b></code> </br></center>\n",
    "              aligns with the Project Id in the upper left corner of this browser and that the location:\n",
    "              <center><code><b>LOCATION</b></code> </br></center>\n",
    "              aligns with the instructions provided.\n",
    "            </span>\n",
    "          </td></tr></table></br></br>\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "    project_list=[\"usfs-ai-bootcamp\", \"usfa-ai-advanced-training\", \"I will setup my own\"]\n",
    "    dropdown = widgets.Dropdown(\n",
    "        options=project_list,\n",
    "        value=project_list[0],\n",
    "        description='Set Your Project:',\n",
    "    )\n",
    "\n",
    "    html_widget2 = widgets.HTML(\n",
    "    value=\"\"\"\n",
    "        <center><table><tr><td><h1 style=\"font-family: Roboto;font-size: 24px\"><b>&#128721; &#9888;&#65039; WARNING &#9888;&#65039;\t&#128721; </b></h1></td></tr></table</center></br></br>\n",
    "          \"\"\")\n",
    "\n",
    "    button = widgets.Button(description=\"Accept\")\n",
    "\n",
    "    # Function to handle the selection change\n",
    "    def on_change(change):\n",
    "        global PROJECT_ID\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            #print(\"Selected option:\", change['new'])\n",
    "            PROJECT_ID=change['new']\n",
    "\n",
    "    # Observe the dropdown for changes\n",
    "    dropdown.observe(on_change)\n",
    "\n",
    "    def on_button_click(b):\n",
    "        nonlocal button_pressed\n",
    "        global PROJECT_ID\n",
    "        button_pressed = True\n",
    "        #button.disabled = True\n",
    "        button.close()  # Remove the button from display\n",
    "        with output:\n",
    "          #print(f\"Button pressed...continuing\")\n",
    "          #print(f\"Selected option: {dropdown.value}\")\n",
    "          PROJECT_ID=dropdown.value\n",
    "\n",
    "    button.on_click(on_button_click)\n",
    "    output = widgets.Output()\n",
    "\n",
    "    # Create centered layout\n",
    "    centered_layout = widgets.VBox([\n",
    "                                    html_widget,\n",
    "                                    widgets.HBox([dropdown, button]),\n",
    "                                    html_widget2,\n",
    "    ], layout=widgets.Layout(\n",
    "                              display='flex',\n",
    "                              flex_flow='column',\n",
    "                              align_items='center',\n",
    "                              width='100%'\n",
    "    ))\n",
    "    # Display the layout\n",
    "    display(centered_layout)\n",
    "\n",
    "\n",
    "wait_for_button_press()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zramkw-P93C-"
   },
   "source": [
    "## Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1737666212893,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "shY7a4DVQjWB",
    "outputId": "606fe1d2-f3de-47cf-f457-bb449cca5b52",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are likely running this notebook with Jupyter iPython runtime at 2025-03-11 11:04:21.276489 in the usfs-ai-bootcamp lab.\n"
     ]
    }
   ],
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "#- Google Colab Check\n",
    "# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "import datetime\n",
    "\n",
    "RunningInCOLAB = False\n",
    "RunningInCOLAB = 'google.colab' in str(get_ipython())\n",
    "current_time   = datetime.datetime.now()\n",
    "\n",
    "if RunningInCOLAB:\n",
    "    print(f\"You are running this notebook in Google Colab at {current_time} in the {BOLD_START}{PROJECT_ID}{BOLD_END}lab.\")\n",
    "else:\n",
    "    print(f\"You are likely running this notebook with Jupyter iPython runtime at {current_time} in the {PROJECT_ID} lab.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZVkISRuLURi"
   },
   "source": [
    "# Library Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1737665373426,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "logDyNfnLURj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import key libraries necessary to support dynamic installation of additional libraries\n",
    "import sys\n",
    "# Use subprocess to support running operating system commands from the program, using the \"bang\" (!)\n",
    "# symbology is supported, however that does not translate to an actual python script, this is a more\n",
    "# agnostic approach.\n",
    "import subprocess\n",
    "import importlib.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74882,
     "status": "ok",
     "timestamp": 1737665448288,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "ldXG-5fhsV1e",
    "outputId": "5941b5ee-93f4-41df-ccc2-8915e0e73ed7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library backoff already installed.\n",
      "Installing library python-dotenv\n",
      "Library seaborn already installed.\n",
      "Library piexif already installed.\n",
      "Library unidecode already installed.\n",
      "Library icecream already installed.\n",
      "Library watermark already installed.\n",
      "Installing library watermark[GPU]\n",
      "Library rich already installed.\n",
      "Installing library rich[jupyter]\n",
      "Library numpy already installed.\n",
      "Library pydot already installed.\n",
      "Installing library polars[all]\n",
      "Installing library dask[complete]\n",
      "Library xarray already installed.\n",
      "Library pandas already installed.\n",
      "Library pystac already installed.\n",
      "Installing library pystac[jinja2]\n",
      "Installing library pystac[orjson]\n",
      "Installing library pystac[validation]\n",
      "Library fastparquet already installed.\n",
      "Library zarr already installed.\n",
      "Library gdown already installed.\n"
     ]
    }
   ],
   "source": [
    "# Identify the libraries you'd like to add to this Runtime environment.\n",
    "\n",
    "libraries=[\"backoff\", \"python-dotenv\", \"seaborn\",\"piexif\", \"unidecode\", \"icecream\",\"watermark\", \"watermark[GPU]\", \"rich\", \"rich[jupyter]\", \n",
    "           \"numpy\", \"pydot\", \"polars[all]\", \"dask[complete]\", \"xarray\",\"pandas\",\n",
    "           \"pystac\", \"pystac[jinja2]\", \"pystac[orjson]\", \"pystac[validation]\",\n",
    "           \"fastparquet\",\n",
    "           \"zarr\",\n",
    "           \"gdown\",\n",
    "           ]\n",
    "\n",
    "# Loop through each library and test for existence, if not present install quietly\n",
    "for library in libraries:\n",
    "    if library == \"Pillow\":\n",
    "      spec = importlib.util.find_spec(\"PIL\")\n",
    "    else:\n",
    "      spec = importlib.util.find_spec(library)\n",
    "    if spec is None:\n",
    "      print(\"Installing library \" + library)\n",
    "      subprocess.run([\"pip\", \"install\" , library, \"--quiet\"], check=True)\n",
    "    else:\n",
    "      print(\"Library \" + library + \" already installed.\")\n",
    "    \n",
    "# Specialized install for GPU enabled capability with CUDF\n",
    "#pip install --extra-index-url=https://pypi.nvidia.com \"cudf-cu12==25.2.*\" \"dask-cudf-cu12==25.2.*\" \"cuml-cu12==25.2.*\" \"cugraph-cu12==25.2.*\" \"nx-cugraph-cu12==25.2.*\" \"cuspatial-cu12==25.2.*\"     \"cuproj-cu12==25.2.*\" \"cuxfilter-cu12==25.2.*\" \"cucim-cu12==25.2.*\"\n",
    "try:\n",
    "    subprocess.run([\"pip\", \"install\" , \"--extra-index-url=https://pypi.nvidia.com\", \"cudf-cu12\", \"dask-cudf-cu12\",\"--quiet\",], check=True)\n",
    "except (subprocess.CalledProcessError, RuntimeError, Exception) as e:\n",
    "  print(repr(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nO_Hq5eq9joH"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5041,
     "status": "ok",
     "timestamp": 1737665453315,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "PJuXEPlkSo9p",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 12:26:31.139686: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-11 12:26:31.490941: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741713991.629652    5967 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741713991.668862    5967 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-11 12:26:32.021059: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#- Import additional libraries that add value to the project related to NLP\n",
    "\n",
    "#- Set of libraries that perhaps should always be in Python source\n",
    "import backoff\n",
    "import datetime\n",
    "from dotenv import load_dotenv\n",
    "import gc\n",
    "import getopt\n",
    "import glob\n",
    "import inspect\n",
    "import io\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import platform\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "from io import StringIO\n",
    "import subprocess\n",
    "import socket\n",
    "import sys\n",
    "import textwrap\n",
    "import tqdm\n",
    "import traceback\n",
    "import warnings\n",
    "import time\n",
    "from time import perf_counter\n",
    "from rich import print as rprint\n",
    "from rich.console import Console\n",
    "from rich.traceback import install\n",
    "from tabulate import tabulate\n",
    "import locale\n",
    "\n",
    "#- Displays system info\n",
    "from watermark import watermark as the_watermark\n",
    "from py3nvml import py3nvml\n",
    "\n",
    "#- Additional libraries for this work\n",
    "import math\n",
    "from base64 import b64decode\n",
    "from IPython.display import Image, Markdown\n",
    "import pandas, IPython.display as display, io, jinja2, base64\n",
    "from IPython.display import clear_output #used to support real-time plotting\n",
    "import requests\n",
    "import unidecode\n",
    "import pydot\n",
    "\n",
    "#- Data Science Libraries\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import dask as da\n",
    "import xarray as xr\n",
    "import pystac as pys\n",
    "import fastparquet as fq\n",
    "import zarr\n",
    "import netCDF4 as nc\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "try:\n",
    "    import cudf \n",
    "    import cudf.pandas\n",
    "    cudf.pandas.install()\n",
    "except Exception as e:\n",
    "    pass\n",
    "finally:\n",
    "    import pandas as pd\n",
    "\n",
    "\n",
    "# Tensorflow and related AI libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import data as tf_data\n",
    "\n",
    "# Torch \n",
    "import torch\n",
    "\n",
    "\n",
    "#- Graphics\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.cbook import get_sample_data\n",
    "from matplotlib.offsetbox import (AnnotationBbox, DrawingArea, OffsetImage,\n",
    "                                  TextArea)\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib.patches import Circle\n",
    "from PIL import Image as PIL_Image\n",
    "import PIL.ImageOps\n",
    "import matplotlib.image as mpimg\n",
    "from imageio import imread\n",
    "import seaborn as sns\n",
    "\n",
    "#- Image meta-data for Section 508 compliance\n",
    "import piexif\n",
    "from piexif.helper import UserComment\n",
    "\n",
    "#- Progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# progress bar\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "# Setup some basic timers material\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9gpU3zJ9l9H"
   },
   "source": [
    "## Application Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 387,
     "status": "ok",
     "timestamp": 1737665453699,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "DoQDWB9s9n7H",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Semantic Versioning\n",
    "VERSION_NAME    = \"MLDATAREADY\"\n",
    "VERSION_MAJOR   = 0\n",
    "VERSION_MINOR   = 0\n",
    "VERSION_RELEASE = 1\n",
    "\n",
    "# API Parameters for things like WordCloud, variables help hold information for later use\n",
    "# The \"constants\" represent variables that we don't anticipate changing over the course of the program.\n",
    "IMG_BACKGROUND=\"black\"     #options are black, white, another color or None\n",
    "IMG_FONT_SIZE_MIN=10\n",
    "IMG_WIDTH=1024\n",
    "IMG_HEIGHT=768\n",
    "IMG_INTERP=\"bilinear\"\n",
    "IMG_ALPHA=0.8\n",
    "IMG_ASPECT=\"equal\"\n",
    "FIGURE_WIDTH=11\n",
    "FIGURE_HEIGHT=8.5\n",
    "WORD_FREQ=10\n",
    "\n",
    "# specify how image formats will be saved\n",
    "IMG_EXT=\".jpg\"\n",
    "\n",
    "# used to fully display the error stack, set to 1 if you want to see a ridiculous amount of debugging information\n",
    "DEBUG_STACKTRACE=0\n",
    "\n",
    "# location of our working files\n",
    "#WORKING_FOLDER=\"/content/folderOnColab\"\n",
    "WORKING_FOLDER=\"./folderOnColab\"\n",
    "\n",
    "# Notebook Author details\n",
    "AUTHOR_NAME=\"Christopher G Wood\"\n",
    "GITHUB_USERNAME=\"christophergarthwood\"\n",
    "AUTHOR_EMAIL=\"christopher.g.wood@gmail.com\"\n",
    "\n",
    "# GenAI\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "TEXT_WIDTH=77\n",
    "IMG_SCALE=0.75\n",
    "\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# Encoding\n",
    "ENCODING  =\"utf-8\"\n",
    "os.environ['PYTHONIOENCODING']=ENCODING\n",
    "\n",
    "\n",
    "# Artificial Intelligence Variables\n",
    "BATCH_SIZE = 32\n",
    "TRAIN_DATA_DIR=f\"{WORKING_FOLDER}/ENTOMOLOGY/train\"\n",
    "VALIDATION_DATA_DIR=f\"{WORKING_FOLDER}/ENTOMOLOGY/validation\"\n",
    "VALIDATION_SPLIT=0.2\n",
    "IMG_HEIGHT=224\n",
    "IMG_WIDTH=224\n",
    "EPOCHS=50\n",
    "BOLD_START = \"\\033[1m\"\n",
    "BOLD_END = \"\\033[0;0m\"\n",
    "\n",
    "METRICS = metrics=['accuracy',]\n",
    "\n",
    "#You can also adjust the verbosity by changing the value of TF_CPP_MIN_LOG_LEVEL:\n",
    "#\n",
    "#0 = all messages are logged (default behavior)\n",
    "#1 = INFO messages are not printed\n",
    "#2 = INFO and WARNING messages are not printed\n",
    "#3 = INFO, WARNING, and ERROR messages are not printed\n",
    "TF_CPP_MIN_LOG_LEVEL_SETTING=0\n",
    "\n",
    "TEXT_WIDTH=77\n",
    "\n",
    "# Model variables\n",
    "categories=[\"ASIAN_LONGHORN_BEETLE\", \"SPOTTED_LANTERN_FLY\"]\n",
    "categories_short_name=[\"alb\", \"slf\"]\n",
    "range_max=5\n",
    "plot_max=330\n",
    "start = \"\\033[1m\"\n",
    "end = \"\\033[0;0m\"\n",
    "THE_DEVICE_NAME=\"/job:localhost/replica:0/task:0/device:GPU:0\"\n",
    "\n",
    "# Set the Seed for the experiment (ask me why?)\n",
    "# seed the pseudorandom number generator\n",
    "# THIS IS ESSENTIAL FOR CONSISTENT MODEL OUTPUT, remember these are random in nature.\n",
    "SEED_INIT=7\n",
    "random.seed(SEED_INIT)\n",
    "tf.random.set_seed(SEED_INIT)\n",
    "np.random.seed(SEED_INIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FUa8QJT9tw_"
   },
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lib Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1737665453699,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "v_CqUVLZ98Mz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lib_diagnostics() -> None:\n",
    "\n",
    "    import pkg_resources\n",
    "\n",
    "    package_name_length=20\n",
    "    package_version_length=10\n",
    "\n",
    "    # Show notebook details\n",
    "    #%watermark?\n",
    "    #%watermark --github_username christophergwood --email christopher.g.wood@gmail.com --date --time --iso8601 --updated --python --conda --hostname --machine --githash --gitrepo --gitbranch --iversions --gpu\n",
    "    # Watermark\n",
    "    print(the_watermark(author=f\"{AUTHOR_NAME}\", github_username=f\"GITHUB_USERNAME\", email=f\"{AUTHOR_EMAIL}\",iso8601=True, datename=True, current_time=True, python=True, updated=True, hostname=True, machine=True, gitrepo=True, gitbranch=True, githash=True))\n",
    "\n",
    "\n",
    "    print(f\"{BOLD_START}Packages:{BOLD_END}\")\n",
    "    print(\"\")\n",
    "    # Get installed packages\n",
    "    the_packages=[\"nltk\", \"numpy\", \"os\", \"pandas\", \"keras\", \"seaborn\",\"fastparquet\", \"zarr\", \"dask\", \"pystac\", \"polars\",\"xarray\",]# Functions are like legos that do one thing, this function outputs library version history of effort.\n",
    "\n",
    "    installed = {pkg.key: pkg.version for pkg in pkg_resources.working_set}\n",
    "    for package_idx, package_name in enumerate(installed):\n",
    "         if package_name in the_packages:\n",
    "             installed_version = installed[package_name]\n",
    "             print(f\"{package_name:<40}#: {str(pkg_resources.parse_version(installed_version)):<20}\")\n",
    "\n",
    "    try:\n",
    "        print(f\"{'TensorFlow version':<40}#: {str(tf.__version__):<20}\")\n",
    "        print(f\"{'     gpu.count:':<40}#: {str(len(tf.config.experimental.list_physical_devices('GPU')))}\")\n",
    "        print(f\"{'     cpu.count:':<40}#: {str(len(tf.config.experimental.list_physical_devices('CPU')))}\")\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        print(f\"{'Torch version':<40}#: {str(torch.__version__):<20}\")\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device('cuda')\n",
    "            print(f\"{'     GPUs available?':<40}#: {torch.cuda.is_available()}\")\n",
    "            print(f\"{'     count':<40}#: {torch.cuda.device_count()}\")\n",
    "            print(f\"{'     current':<40}#: {torch.cuda.get_device_name(0)}\")\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "            print('No GPU available, using CPU.')        \n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "      print(f\"{'OpenAI Azure Version':<40}#: {str(the_openai_version):<20}\")\n",
    "    except Exception as e:\n",
    "      pass\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 508 Compliance Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 256,
     "status": "ok",
     "timestamp": 1737665453948,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "Nl_kxpFUKKD5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Routines designed to support adding ALT text to an image generated through Matplotlib.\n",
    "\n",
    "def capture(figure):\n",
    "   buffer = io.BytesIO()\n",
    "   figure.savefig(buffer)\n",
    "   #return F\"data:image/png;base64,{base64.b64encode(buffer.getvalue()).decode()}\"\n",
    "   return F\"data:image/jpg;base64,{base64.b64encode(buffer.getvalue()).decode()}\"\n",
    "\n",
    "def make_accessible(figure, template, **kwargs):\n",
    "   return display.Markdown(F\"\"\"![]({capture(figure)} \"{template.render(**globals(), **kwargs)}\")\"\"\")\n",
    "\n",
    "\n",
    "# requires JPG's or TIFFs\n",
    "def add_alt_text(image_path, alt_text):\n",
    "    try:\n",
    "        if os.path.isfile(image_path):\n",
    "          img = PIL_Image.open(image_path)\n",
    "          if \"exif\" in img.info:\n",
    "              exif_dict = piexif.load(img.info[\"exif\"])\n",
    "          else:\n",
    "              exif_dict={}\n",
    "\n",
    "          w, h = img.size\n",
    "          if \"0th\" not in exif_dict:\n",
    "            exif_dict[\"0th\"]={}\n",
    "          exif_dict[\"0th\"][piexif.ImageIFD.XResolution] = (w, 1)\n",
    "          exif_dict[\"0th\"][piexif.ImageIFD.YResolution] = (h, 1)\n",
    "\n",
    "          software_version=\" \".join([\"STEM-001 with Python v\", str(sys.version).split(\" \")[0]])\n",
    "          exif_dict[\"0th\"][piexif.ImageIFD.Software]=software_version.encode(\"utf-8\")\n",
    "\n",
    "          if \"Exif\" not in exif_dict:\n",
    "            exif_dict[\"Exif\"]={}\n",
    "          exif_dict[\"Exif\"][piexif.ExifIFD.UserComment] = UserComment.dump(alt_text, encoding=\"unicode\")\n",
    "\n",
    "          exif_bytes = piexif.dump(exif_dict)\n",
    "          img.save(image_path, \"jpeg\", exif=exif_bytes)\n",
    "        else:\n",
    "          rprint(f\"Cound not fine {image_path} for ALT text modification, please check your paths.\")\n",
    "\n",
    "    except (FileExistsError, FileNotFoundError, Exception) as e:\n",
    "        process_exception(e)\n",
    "\n",
    "# Appears to solve a problem associated with GPU use on Colab, see: https://github.com/explosion/spaCy/issues/11909\n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exception Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1737665453948,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "X8FdPtZzKMyw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this function displays the stack trace on errors from a central location making adjustments to the display on an error easier to manage\n",
    "# functions perform useful solutions for highly repetitive code\n",
    "def process_exception(inc_exception: Exception) -> None:\n",
    "  if DEBUG_STACKTRACE==1:\n",
    "    traceback.print_exc()\n",
    "    console.print_exception(show_locals=True)\n",
    "  else:\n",
    "    rprint(repr(inc_exception))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Stats for a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def quick_df_stats(inc_df:pd.DataFrame,\n",
    "                   inc_header_count: int,\n",
    "                   ) -> None:\n",
    "    '''\n",
    "    Load the data and return as a pd.DataFrame.\n",
    "\n",
    "            Parameters:\n",
    "                   inc_df (pd.DataFrame): Dataframe to be inspected, displayed\n",
    "                   inc_header_count (int): Anticipated number of columns to read in (validation check)\n",
    "\n",
    "            Returns:\n",
    "                    Printed output\n",
    "    '''\n",
    "    print(\"Data Resolution has: \" + str(inc_df.columns))\n",
    "    print(\"\\n\")\n",
    "    print(f\"\"\"{\"size\":20} : {inc_df.size:15,} \"\"\")\n",
    "    print(f\"\"\"{\"shape\":20} : {str(inc_df.shape):15} \"\"\")\n",
    "    print(f\"\"\"{\"ndim\":20} : {inc_df.ndim:15,} \"\"\")\n",
    "    print(f\"\"\"{\"column size\":20} : {inc_df.columns.size:15,} \"\"\")\n",
    "\n",
    "    #index added so you get an extra column\n",
    "    print(f\"\"\"{\"Read\":20} : {inc_df.columns.size:15,} \"\"\")\n",
    "    print(f\"\"\"{\"Expected\":20} : {inc_header_count:15,} \"\"\")\n",
    "    if ( (inc_df.columns.size) == inc_header_count):\n",
    "        print(f\"{BOLD_START}Expectations met{BOLD_END}.\")\n",
    "    else:\n",
    "        print(f\"Expectations {BOLD_START}not met{BOLD_END}, check your datafile, columns don't match.\")\n",
    "    rprint(\"\\n\")\n",
    "    #rprint(str(inc_df.describe()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RG0mFzUX-DV1"
   },
   "source": [
    "## Function Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "executionInfo": {
     "elapsed": 338,
     "status": "ok",
     "timestamp": 1737665454279,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "SSOOEwn8-FKg",
    "outputId": "f1d7c56b-5717-480a-f2f8-93d95eeecfa6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5793/1493056045.py:3: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Christopher G Wood\n",
      "\n",
      "Github username: GITHUB_USERNAME\n",
      "\n",
      "Email: christopher.g.wood@gmail.com\n",
      "\n",
      "Last updated: 2025-03-11T12:20:48.028219-05:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.12.9\n",
      "IPython version      : 8.30.0\n",
      "\n",
      "Compiler    : GCC 13.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.15.167.4-microsoft-standard-WSL2\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 16\n",
      "Architecture: 64bit\n",
      "\n",
      "Hostname: ThulsaDoom\n",
      "\n",
      "Git hash: 28b7caa03aeeb733d2bbd192bfa88d6e39b9c655\n",
      "\n",
      "Git repo: git@github.com:christophergarthwood/jbooks.git\n",
      "\n",
      "Git branch: Updates\n",
      "\n",
      "\u001b[1mPackages:\u001b[0;0m\n",
      "\n",
      "dask                                    #: 2024.12.1           \n",
      "fastparquet                             #: 2024.11.0           \n",
      "keras                                   #: 3.9.0               \n",
      "numpy                                   #: 2.0.2               \n",
      "pandas                                  #: 2.2.3               \n",
      "polars                                  #: 1.24.0              \n",
      "pystac                                  #: 1.12.1              \n",
      "seaborn                                 #: 0.13.2              \n",
      "xarray                                  #: 2024.11.0           \n",
      "zarr                                    #: 3.0.5               \n",
      "TensorFlow version                      #: 2.18.0              \n",
      "     gpu.count:                         #: 1\n",
      "     cpu.count:                         #: 1\n",
      "Torch version                           #: 2.6.0+cu124         \n",
      "     GPUs available?                    #: True\n",
      "     count                              #: 1\n",
      "     current                            #: NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "lib_diagnostics()\n",
    "#setup the text wrapper\n",
    "wrapper = textwrap.TextWrapper(width=TEXT_WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTrnAspo3CWR"
   },
   "source": [
    "## Check your resources from a CPU/GPU perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1737665454280,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "hmGUvC7M3B0H",
    "outputId": "638ecead-d943-42f2-a2eb-99790d7fe3bf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mList Devices\u001b[0;0m #########################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741713648.516531    5793 service.cc:148] XLA service 0x55ba7f8cc4f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1741713648.517106    5793 service.cc:156]   StreamExecutor device (0): Host, Default Version\n",
      "I0000 00:00:1741713648.768027    5793 service.cc:148] XLA service 0x55ba7f8b9a40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1741713648.768053    5793 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "I0000 00:00:1741713648.809124    5793 gpu_device.cc:2022] Created device /device:GPU:0 with 4056 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    name: <span style=\"color: #008000; text-decoration-color: #008000\">\"/device:CPU:0\"</span>\n",
       "device_type: <span style=\"color: #008000; text-decoration-color: #008000\">\"CPU\"</span>\n",
       "memory_limit: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">268435456</span>\n",
       "locality <span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "incarnation: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3319495511874724322</span>\n",
       "xla_global_id: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>\n",
       ",\n",
       "    name: <span style=\"color: #008000; text-decoration-color: #008000\">\"/device:XLA_CPU:0\"</span>\n",
       "device_type: <span style=\"color: #008000; text-decoration-color: #008000\">\"XLA_CPU\"</span>\n",
       "memory_limit: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17179869184</span>\n",
       "locality <span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "incarnation: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17829430002669854535</span>\n",
       "physical_device_desc: <span style=\"color: #008000; text-decoration-color: #008000\">\"device: XLA_CPU device\"</span>\n",
       "xla_global_id: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>\n",
       ",\n",
       "    name: <span style=\"color: #008000; text-decoration-color: #008000\">\"/device:XLA_GPU:0\"</span>\n",
       "device_type: <span style=\"color: #008000; text-decoration-color: #008000\">\"XLA_GPU\"</span>\n",
       "memory_limit: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17179869184</span>\n",
       "locality <span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "incarnation: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11127211328592708468</span>\n",
       "physical_device_desc: <span style=\"color: #008000; text-decoration-color: #008000\">\"device: XLA_GPU device\"</span>\n",
       "xla_global_id: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>\n",
       ",\n",
       "    name: <span style=\"color: #008000; text-decoration-color: #008000\">\"/device:GPU:0\"</span>\n",
       "device_type: <span style=\"color: #008000; text-decoration-color: #008000\">\"GPU\"</span>\n",
       "memory_limit: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4253024256</span>\n",
       "locality <span style=\"font-weight: bold\">{</span>\n",
       "  bus_id: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "  links <span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "incarnation: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16582028071150929975</span>\n",
       "physical_device_desc: <span style=\"color: #008000; text-decoration-color: #008000\">\"device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\"</span>\n",
       "xla_global_id: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">416903419</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    name: \u001b[32m\"/device:CPU:0\"\u001b[0m\n",
       "device_type: \u001b[32m\"CPU\"\u001b[0m\n",
       "memory_limit: \u001b[1;36m268435456\u001b[0m\n",
       "locality \u001b[1m{\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n",
       "incarnation: \u001b[1;36m3319495511874724322\u001b[0m\n",
       "xla_global_id: \u001b[1;36m-1\u001b[0m\n",
       ",\n",
       "    name: \u001b[32m\"/device:XLA_CPU:0\"\u001b[0m\n",
       "device_type: \u001b[32m\"XLA_CPU\"\u001b[0m\n",
       "memory_limit: \u001b[1;36m17179869184\u001b[0m\n",
       "locality \u001b[1m{\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n",
       "incarnation: \u001b[1;36m17829430002669854535\u001b[0m\n",
       "physical_device_desc: \u001b[32m\"device: XLA_CPU device\"\u001b[0m\n",
       "xla_global_id: \u001b[1;36m-1\u001b[0m\n",
       ",\n",
       "    name: \u001b[32m\"/device:XLA_GPU:0\"\u001b[0m\n",
       "device_type: \u001b[32m\"XLA_GPU\"\u001b[0m\n",
       "memory_limit: \u001b[1;36m17179869184\u001b[0m\n",
       "locality \u001b[1m{\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n",
       "incarnation: \u001b[1;36m11127211328592708468\u001b[0m\n",
       "physical_device_desc: \u001b[32m\"device: XLA_GPU device\"\u001b[0m\n",
       "xla_global_id: \u001b[1;36m-1\u001b[0m\n",
       ",\n",
       "    name: \u001b[32m\"/device:GPU:0\"\u001b[0m\n",
       "device_type: \u001b[32m\"GPU\"\u001b[0m\n",
       "memory_limit: \u001b[1;36m4253024256\u001b[0m\n",
       "locality \u001b[1m{\u001b[0m\n",
       "  bus_id: \u001b[1;36m1\u001b[0m\n",
       "  links \u001b[1m{\u001b[0m\n",
       "  \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n",
       "incarnation: \u001b[1;36m16582028071150929975\u001b[0m\n",
       "physical_device_desc: \u001b[32m\"device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\"\u001b[0m\n",
       "xla_global_id: \u001b[1;36m416903419\u001b[0m\n",
       "\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mDevices Counts\u001b[0;0m ########################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Num GPUs Available: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Num GPUs Available: \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Num CPUs Available: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Num CPUs Available: \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mOptional Enablement\u001b[0;0m ####################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741713648.828330    5793 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4056 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> Physical GPUs,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> Logical GPU\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1\u001b[0m Physical GPUs,\u001b[1;36m1\u001b[0m Logical GPU\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"{BOLD_START}List Devices{BOLD_END} #########################################\")\n",
    "try:\n",
    "  from tensorflow.python.client import device_lib\n",
    "  rprint(device_lib.list_local_devices())\n",
    "  print(\"\")\n",
    "except RuntimeError as e:\n",
    "  # Visible devices must be set before GPUs have been initialized\n",
    "  rprint(str(repr(e)))\n",
    "\n",
    "print(f\"{BOLD_START}Devices Counts{BOLD_END} ########################################\")\n",
    "try:\n",
    "  rprint(f\"Num GPUs Available: {str(len(tf.config.experimental.list_physical_devices('GPU')))}\" )\n",
    "  rprint(f\"Num CPUs Available: {str(len(tf.config.experimental.list_physical_devices('CPU')))}\" )\n",
    "  print(\"\")\n",
    "except RuntimeError as e:\n",
    "  # Visible devices must be set before GPUs have been initialized\n",
    "  rprint(str(repr(e)))\n",
    "\n",
    "print(f\"{BOLD_START}Optional Enablement{BOLD_END} ####################################\")\n",
    "try:\n",
    "  gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "except RuntimeError as e:\n",
    "  # Visible devices must be set before GPUs have been initialized\n",
    "  rprint(str(repr(e)))\n",
    "\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    rprint( str( str(len(gpus)) + \" Physical GPUs,\" + str(len(logical_gpus)) + \" Logical GPU\") )\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    rprint(str(repr(e)))\n",
    "  print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-CaUT8B3T8V"
   },
   "source": [
    "#### OS Configuration Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1737665522573,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "dwPl2ODJ3Tic",
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = str(TF_CPP_MIN_LOG_LEVEL_SETTING)\n",
    "\n",
    "#To disable GPU access to the current runtime enable -1 for \"no GPUs\"\n",
    "#confirmed to work on the Command Line Interface (CLI) of all systems but this one...\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup the rich print console for future use\n",
    "if DEBUG_STACKTRACE==1:\n",
    "  console = Console()\n",
    "\n",
    "# Use the 'Agg' backend for non-interactive environments\n",
    "#matplotlib.use('Agg')\n",
    "\n",
    "# Ensure UTF-8 Encoding is set\n",
    "locale.getpreferredencoding = getpreferredencoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46JMSTY2QjWD"
   },
   "source": [
    "## Input Sources\n",
    "#### Create the storage locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1737665454282,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "pu8f4w5XK6i8",
    "outputId": "2aa1c04c-7c5a-4348-93a1-67ea14f79c83",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Creating project infrastructure:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Creating project infrastructure:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">...</span>creating <span style=\"font-weight: bold\">(</span>.<span style=\"color: #800080; text-decoration-color: #800080\">/folderOnColab/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">downloads</span><span style=\"font-weight: bold\">)</span> to store project data.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m...\u001b[0mcreating \u001b[1m(\u001b[0m.\u001b[35m/folderOnColab/\u001b[0m\u001b[95mdownloads\u001b[0m\u001b[1m)\u001b[0m to store project data.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......folder named (./folderOnColab/downloads) \u001b[1malready exists\u001b[0;0m, we won't try to create a new folder.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">...</span>creating <span style=\"font-weight: bold\">(</span>.<span style=\"color: #800080; text-decoration-color: #800080\">/folderOnColab/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">data</span><span style=\"font-weight: bold\">)</span> to store project data.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m...\u001b[0mcreating \u001b[1m(\u001b[0m.\u001b[35m/folderOnColab/\u001b[0m\u001b[95mdata\u001b[0m\u001b[1m)\u001b[0m to store project data.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......folder named (./folderOnColab/data) \u001b[1malready exists\u001b[0;0m, we won't try to create a new folder.\n"
     ]
    }
   ],
   "source": [
    "# Create the folder that will hold our content.\n",
    "target_folder=WORKING_FOLDER\n",
    "sub_folders=[\"downloads\",\"data\"]\n",
    "rprint(f\"Creating project infrastructure:\")\n",
    "try:\n",
    "  for idx, subdir in enumerate(sub_folders):\n",
    "      target_directory=f\"{target_folder}{os.sep}{subdir}\"\n",
    "      rprint(f\"...creating ({target_directory}) to store project data.\")\n",
    "      if os.path.isfile(target_directory):\n",
    "        raise OSError(f\"Cannot create your folder ({target_directory}) a file of the same name already exists there, work with your instructor or remove it yourself.\")\n",
    "      elif os.path.isdir(target_directory):\n",
    "        print(f\"......folder named ({target_directory}) {BOLD_START}already exists{BOLD_END}, we won't try to create a new folder.\")\n",
    "      else:\n",
    "        subprocess.run([\"mkdir\", \"-p\" , target_directory], check=True)\n",
    "except (subprocess.CalledProcessError, Exception) as e:\n",
    "  process_exception(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the FIADB Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 66496,
     "status": "ok",
     "timestamp": 1737665520749,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "AZcbq467sgrc",
    "outputId": "0a82f71c-4bcc-45bb-8681-8cce7803c49a",
    "tags": []
   },
   "source": [
    "#https://research.fs.usda.gov/programs/fia#data-and-tools\n",
    "#Forest Inventory Asset Database (FIADB)\n",
    "dataset_long_names=[\n",
    "\"ALASKA_AK\", \"CALIFORNIA_CA\", \"HAWAII_HI\", \"IDAHO_ID\", \"NEVADA_NV\", \"OREGON_OR\", \"WASHINGTON_WA\", \"ARIZONA_AZ\", \"ARKANSAS_AR\", \"COLORADO_CO\", \"IOWA_IA\", \"KANSAS_KS    \", \"LOUISIANA_LA\", \"MINNESOTA_MN\", \"MISSOURI_MO\", \"MONTANA_MT\", \"NEBRASKA_NE\", \"NEW_MEXICO_NM\", \"NORTH_DAKOTA_ND\", \"OKLAHOMA_OK\", \"SOUTH_DAKOTA_SD\", \"TEXAS_TX\", \"U    TAH_UT\", \"WYOMING_WY\", \"ALABAMA_AL\", \"CONNECTICUT_CT\", \"DELAWARE_DE\", \"FLORIDA_FL\", \"GEORGIA_GA\", \"ILLINOIS_IL\", \"INDIANA_IN\", \"KENTUCKY_KY\", \"MAINE_ME\", \"MARYLAND    _MD\", \"MASSACHUSETTS_MA\", \"MICHIGAN_MI\", \"MISSISSIPPI_MS\", \"NEW_HAMPSHIRE_NH\", \"NEW_JERSEY_NJ\", \"NEW_YORK_NY\", \"NORTH_CAROLINA_NC\", \"OHIO_OH\", \"PENNSYLVANIA_PA\", \"    RHODE_ISLAND_RI\", \"SOUTH_CAROLINA_SC\", \"TENNESSEE_TN\", \"VERMONT_VT\", \"VIRGINIA_VA\", \"WEST_VIRGINIA_WV\", \"WISCONSIN_WI\", \"GUAM_GU\", \"FEDERATED_STATES_OF_MICRONES_FM    \", \"NORTHERN_MARIANA_ISLANDS_MP\", \"PALAU_PW\", \"AMERICAN_SAMOA_AS\", \"PUERTO_RICO_PR\", \"US_VIRGIN_ISLANDS_VI\", \n",
    "]\n",
    "dataset_short_names=[\n",
    "     \"AK\", \"AL\", \"AR\", \"AS\", \"AZ\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \"GU\", \"HI\", \"IA\", \"ID\", \"IL\", \"IN\", \"KS\", \"KY\", \"LA\", \"MA\", \"MD\", \"ME\", \"MI\", \"MN\", \"MO\", \"MP\", \"MS\", \"MT\", \"NC\", \"ND\", \"NE\", \"NH\", \"NJ\", \"NM\", \"NV\", \"NY\", \"OH\", \"OK\", \"OR\", \"PA\", \"PR\", \"PW\", \"RI\", \"SC\", \"SD\", \"SFM\", \"TN\", \"TX\", \"UT\", \"VA\", \"VI\", \"VT\", \"WA\", \"WI\", \"WV\", \"WY\", \n",
    "]\n",
    "#dataset_pattern=\"https://apps.fs.usda.gov/fia/datamart/CSV/MT_VEG_SUBPLOT.zip\"\n",
    "dataset_pattern=\"https://apps.fs.usda.gov/fia/datamart/CSV/\"\n",
    "\n",
    "rprint(\"Performing `wget` on target FIA records.\")\n",
    "target_folder=WORKING_FOLDER\n",
    "if os.path.isdir(target_folder):\n",
    "    target_directory=f\"{target_folder}{os.sep}downloads\"\n",
    "    for idx,filename in enumerate(dataset_short_names):\n",
    "        if os.path.isdir(target_directory):\n",
    "            target_filename=f\"{filename}_CSV.zip\"\n",
    "            target_url=f\"{dataset_pattern}{target_filename}\"\n",
    "            try:\n",
    "              rprint(f\"...copying {dataset_long_names[idx]} to target folder: {target_directory}\")\n",
    "              subprocess.run([\"/usr/bin/wget\", \"--show-progress\", f\"--directory-prefix={target_directory}\", f\"{target_url}\"], check=True)            \n",
    "              rprint(\"......completed\")\n",
    "            except (subprocess.CalledProcessError, Exception) as e:\n",
    "              rprocess_exception(e)\n",
    "        else:\n",
    "            rprint(f\"...target folder: {target_directory} isn't present for {filename} download.\")\n",
    "        break;\n",
    "else:\n",
    "    rprint(\"ERROR: Local downloads folder not found/created.  Check the output to ensure your folder is created.\")\n",
    "    rprint(f\"...target folder: {target_directory}\")\n",
    "    rprint(\"...if you can't find the problem contact the instructor.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now Unzip those downloads"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 66496,
     "status": "ok",
     "timestamp": 1737665520749,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "AZcbq467sgrc",
    "outputId": "0a82f71c-4bcc-45bb-8681-8cce7803c49a",
    "tags": []
   },
   "source": [
    "rprint(\"Uncompressing the downloads...\")\n",
    "if os.path.isdir(target_folder):\n",
    "    source_directory=f\"{target_folder}{os.sep}downloads\"\n",
    "    target_directory=f\"{target_folder}{os.sep}data\"\n",
    "    if os.path.isdir(target_directory) and os.path.isdir(source_directory):\n",
    "        for idx,filename in enumerate(dataset_short_names):\n",
    "            target_filename=f\"{filename}_CSV.zip\"\n",
    "            final_directory=f\"{target_directory}{os.sep}{filename}{os.sep}\"\n",
    "            try:\n",
    "              if os.path.isfile(f\"{source_directory}{os.sep}{target_filename}\"):\n",
    "                  rprint(f\"...unzipping {dataset_long_names[idx]} to created target folder: {final_directory}\")\n",
    "                  subprocess.run([\"mkdir\", \"-p\" , final_directory], check=True)\n",
    "                  subprocess.run([\"/usr/bin/unzip\", \"-o\", \"-qq\", \"-d\", f\"{final_directory}\", f\"{source_directory}{os.sep}{target_filename}\"], check=True)          \n",
    "                  process1 = subprocess.Popen([\"/usr/bin/find\", f\"{final_directory}\", \"-type\", \"f\", \"-print\",], stdout=subprocess.PIPE)\n",
    "                  process2 = subprocess.Popen(['wc', '-l'], stdin=process1.stdout, stdout=subprocess.PIPE)\n",
    "\n",
    "                  # Close the output of process1 to allow process2 to receive EOF\n",
    "                  process1.stdout.close()\n",
    "                  output, error = process2.communicate()\n",
    "                  process2.stdout.close()\n",
    "                  number_files=output.decode().strip()\n",
    "                  rprint(f\"......completed, {number_files} files extracted.\")\n",
    "              else:\n",
    "                rprint(f\"......failed, unable to find ({source_directory}{os.sep}{target_filename}{os.sep})\")\n",
    "            except (subprocess.CalledProcessError, Exception) as e:\n",
    "              process_exception(e)\n",
    "            break;\n",
    "    else:\n",
    "        rprint(f\"...either the source directory ({source_directory})  or the ({target_directory}) isn't present for extraction.\")\n",
    "else:\n",
    "    rprint(\"ERROR: Local downloads folder not found/created.  Check the output to ensure your folder is created.\")\n",
    "    rprint(f\"...target folder: {target_directory}\")\n",
    "    rprint(\"...if you can't find the problem contact the instructor.\")\n",
    "          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDLoEWmVR9Sk"
   },
   "source": [
    "#### List the files copied, are they there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1737665520751,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "IZrJ8FhpR78m",
    "outputId": "111a3aec-6ad8-4889-c3ed-7f8e9ed4e737",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Display of top-level files in target folder: .<span style=\"color: #800080; text-decoration-color: #800080\">/folderOnColab/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">data</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Display of top-level files in target folder: .\u001b[35m/folderOnColab/\u001b[0m\u001b[95mdata\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">acs.npy</span>                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/\u001b[0m\u001b[95macs.npy\u001b[0m                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">MissBight_2020010900.nc</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\u001b[35m/\u001b[0m\u001b[95mMissBight_2020010900.nc\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(f\"Display of top-level files in target folder: {WORKING_FOLDER}{os.sep}data\")\n",
    "\n",
    "from pathlib import Path\n",
    "source = Path(f\"{WORKING_FOLDER}{os.sep}data\")\n",
    "the_files=[x.name for x in source.iterdir()]\n",
    "for file in the_files:\n",
    "  rprint(f\"./{file:50}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">...</span>no need to download MissBight_2020010900.nc again.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m...\u001b[0mno need to download MissBight_2020010900.nc again.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "############################################\n",
    "#APPLICATION VARIABLES\n",
    "############################################\n",
    "#define ACS data setup\n",
    "THE_FILE=\"ACS.txt\"\n",
    "THE_ID=\"12L8VRY6J1Sj-B1vIf-ODh4kjHWHqIzm8\"\n",
    "\n",
    "THE_FILE=\"MissBight_2020010900.nc\"\n",
    "THE_ID=\"1uYMFrdeVD7_qvG2wRbyu6ir9C6b4wAZC\"\n",
    "\n",
    "target_folder=f\"{WORKING_FOLDER}{os.sep}data\"\n",
    "\n",
    "target_ids=[THE_ID]\n",
    "target_filenames=[THE_FILE]\n",
    "\n",
    "for idx, the_id in enumerate(target_ids):\n",
    "  try:\n",
    "    if os.path.isfile(f\"{target_folder}{os.sep}{target_filenames[idx]}\"):\n",
    "        rprint(f\"...no need to download {target_filenames[idx]} again.\")\n",
    "    else:\n",
    "        rprint(f\"...downloading {target_filenames[idx]}.\")\n",
    "        subprocess.run([\"gdown\", f\"{the_id}\", \"--no-check-certificate\",  \"--continue\", \"-O\", f\"{target_folder}{os.sep}{target_filenames[idx]}\"], check=True)\n",
    "  except (subprocess.CalledProcessError, Exception) as e:\n",
    "    process_exception(e)\n",
    "    raise SystemError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Base NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Files downloaded:\n",
      "./MissBight_2020010900.nc                           \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Reading base NetCDF4 for tests.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Reading base NetCDF4 for tests.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">...</span>reading NetCDF4 <span style=\"font-weight: bold\">(</span>.<span style=\"color: #800080; text-decoration-color: #800080\">/folderOnColab/data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">MissBight_2020010900.nc</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m...\u001b[0mreading NetCDF4 \u001b[1m(\u001b[0m.\u001b[35m/folderOnColab/data/\u001b[0m\u001b[95mMissBight_2020010900.nc\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#READ Input NetCDF\n",
    "print(\"\\n\")\n",
    "print(\"Files downloaded:\")\n",
    "\n",
    "source = Path(f\"{WORKING_FOLDER}{os.sep}data{os.sep}\")\n",
    "the_files=[x.name for x in source.iterdir() if THE_FILE in x.name]\n",
    "for file in the_files:\n",
    "  print(f\"./{file:50}\")\n",
    "\n",
    "target_filename=f\"{target_folder}{os.sep}{target_filenames[0]}\"\n",
    "target_columns=175\n",
    "\n",
    "rprint(f\"Reading base NetCDF4 for tests.\")\n",
    "try:\n",
    "    rprint(f\"...reading NetCDF4 ({target_filename})\")\n",
    "    the_netcdf = Dataset(target_filename, \"r\", format=\"NETCDF4\")\n",
    "except Exception as e:\n",
    "   process_exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4.Dataset'>\n",
       "root group (NETCDF3_CLASSIC data model, file format NETCDF3):\n",
       "    source: BioCAST 1.1.5\n",
       "    title: ./MissBight_2020010900.nc\n",
       "    version: 1.1.5\n",
       "    rp_organization: NAVOCEANO\n",
       "    rp_phone: 228-688-5176\n",
       "    rp_email: cso.navo.fct@navy.mil\n",
       "    rp_name: NAVOCEANO CSO\n",
       "    conventions: National System for Geospatial Integlligence (NSG) Meatadata Foundation (NMF), Version 3.0, 2016-08-31 (NGA.STD.0012-3.0)\n",
       "    geoBoundingBox_northBoundLatitude: 31.0065\n",
       "    geoBoundingBox_southBoundLatitude: 28.3900\n",
       "    geoBoundingBox_eastBoundLongitude: -84.5053\n",
       "    geoBoundingBox_westBoundLongitude: -90.5075\n",
       "    geoDescription: Pseudo-Mercator\n",
       "    referenceSystem_code: Geodetic Geographic 3D\n",
       "    referenceSystem_title: EPSG:4326 (WGS 84)\n",
       "    createDate: 2020-03-24 10:59:00\n",
       "    start_date: 2020-01-09\n",
       "    start_time: 00:00:00\n",
       "    stop_date: 2020-01-09\n",
       "    stop_time: 00:00:00\n",
       "    lineage: Generated by BioCAST 1.1.5 using optics seed /export/tods-rt/biocast3D/biocast_data/npp.2020007.0107.2020013.0113.D.L4_7DLP.viirsn.MissBight.v08.750m.nc\n",
       "    ism_NoticeText: Distribution Statement A: Approved for public release; distribution unlimited.\n",
       "    ism_classification: Unclassified\n",
       "    ism_ownerProducer: USA\n",
       "    aps_fileTitle: NRL Level-4 Data\n",
       "    aps_fileVersion: 4.0\n",
       "    aps_cdm_data_type: grid\n",
       "    aps_sensor: sensor\n",
       "    aps_sensorPlatform: npp\n",
       "    aps_sensorType: whishbroom\n",
       "    aps_sensorAgency: IPO\n",
       "    aps_sensorPlatformType: Polar-orbiting Satellite\n",
       "    aps_sensorResolutionInKM: 0.7500\n",
       "    aps_mapProjectionSystem: NRL(USGS)\n",
       "    aps_geospatial_lat_units: degrees_north\n",
       "    aps_geospatial_lon_units: degrees_east\n",
       "    aps_geospatial_lat_max: 31.0065\n",
       "    aps_geospatial_lat_min: 28.3900\n",
       "    aps_geospatial_lon_max: -84.5053\n",
       "    aps_geospatial_lon_min: -90.5075\n",
       "    aps_creator_institution: NRL/SSC/Oceans\n",
       "    aps_creator_name: NRL/SSC/Oceans\n",
       "    aps_creator_email: apssupport@nrlssc.navy.mil\n",
       "    aps_creator_url: http://www7333.nrlssc.navy.mil\n",
       "    aps_inputParameters: -m LAND,ATMFAIL,CLDICE,SPARE3,ATMWARN,MAXAERITER,LOWLW,TRIMPIXEL -T 5 -H chlor_a,vis_lmi_c,vis_lmi_a,vis_lmi_bb,vis_lmi_Kd,Kd_486_lee,Kd_551_lee,bb_551_qaa,bb_486_qaa,c_551_qaa,c_486_qaa,Kd_532,Kd_490,Zeu_lee,Zeu_morel,cloud_albedo,l2_flags,latitude,longi\n",
       "    aps_start_date: 2020-01-06\n",
       "    aps_start_time: 18:54:22\n",
       "    aps_stop_date: 2020-01-13\n",
       "    aps_stop_time: 20:05:18\n",
       "    aps_prodList: chlor_a\n",
       "    dimensions(sizes): lon(800), lat(400), depth(29), time(1)\n",
       "    variables(dimensions): float32 lon(lon), float32 lat(lat), float32 depth(depth), float32 time(time), float32 chlor_a(time, depth, lat, lon)\n",
       "    groups: "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_netcdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gather data as simple arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mLatitude data type:           \u001b[0;0m<class 'numpy.ndarray'>\n",
      ".......shape:(400,)\n",
      "....datatype:float64\n",
      "\u001b[1mLongitude data type:          \u001b[0;0m<class 'numpy.ndarray'>\n",
      ".......shape:(800,)\n",
      "....datatype:float64\n",
      "\u001b[1mOceanogrpahic data type:      \u001b[0;0m<class 'numpy.ndarray'>\n",
      ".......shape:(1, 29, 400, 800)\n",
      "....datatype:float64\n"
     ]
    }
   ],
   "source": [
    "geospatial_lat_nm='lat'\n",
    "geospatial_lon_nm='lon'\n",
    "product_nm=\"chlor_a\"\n",
    "#note x,y values are shown below as they are part of the APS meta-data\n",
    "#based on the NetCDF Best Practice subject x,y vars should not exist.\n",
    "#keeping for continuity between BIOCAST code already written to read APS input.\n",
    "geospatial_vars = [geospatial_lat_nm, geospatial_lon_nm, ]\n",
    "\n",
    "#lat   =np.array(the_netcdf.variables[geospatial_lat_nm][:][:]).flatten()\n",
    "lat   =np.array(the_netcdf.variables[geospatial_lat_nm][:][:],dtype=np.double)\n",
    "print(f\"{BOLD_START}{\"Latitude data type:\":30}{BOLD_END}{str(type(lat)):20}\")\n",
    "print(f\".......shape:{lat.shape}\")\n",
    "print(f\"....datatype:{lat.dtype}\")\n",
    "#df_describe = pd.DataFrame(lat)\n",
    "#print(df_describe.describe())\n",
    "\n",
    "#lon   =np.array(the_netcdf.variables[geospatial_lon_nm][:][:]).flatten()\n",
    "lon   =np.array(the_netcdf.variables[geospatial_lon_nm][:][:],dtype=np.double)\n",
    "print(f\"{BOLD_START}{\"Longitude data type:\":30}{BOLD_END}{str(type(lon)):20}\")\n",
    "print(f\".......shape:{lon.shape}\")\n",
    "print(f\"....datatype:{lon.dtype}\")\n",
    "#df_describe = pd.DataFrame(lon)\n",
    "#print(df_describe.describe())\n",
    "\n",
    "varAry=np.array(the_netcdf.variables[product_nm][:][:],dtype=np.double)\n",
    "print(f\"{BOLD_START}{\"Oceanogrpahic data type:\":30}{BOLD_END}{str(type(varAry)):20}\")\n",
    "print(f\".......shape:{varAry.shape}\")\n",
    "print(f\"....datatype:{varAry.dtype}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mLatitude data type:           \u001b[0;0m<class 'numpy.ndarray'>\n",
      ".......shape:(2000,)\n",
      "....datatype:float64\n",
      "\u001b[1mLongitude data type:          \u001b[0;0m<class 'numpy.ndarray'>\n",
      ".......shape:(4000,)\n",
      "....datatype:float64\n",
      "\u001b[1mOceanogrpahic data type:      \u001b[0;0m<class 'numpy.ndarray'>\n",
      ".......shape:(1, 29, 2000, 4000)\n",
      "....datatype:float64\n"
     ]
    }
   ],
   "source": [
    "DATASET_SIZE=5\n",
    "final_lat = np.tile(lat, DATASET_SIZE,)\n",
    "lat=final_lat\n",
    "print(f\"{BOLD_START}{\"Latitude data type:\":30}{BOLD_END}{str(type(lat)):20}\")\n",
    "print(f\".......shape:{lat.shape}\")\n",
    "print(f\"....datatype:{lat.dtype}\")\n",
    "\n",
    "final_lon = np.tile(lon, DATASET_SIZE,)\n",
    "lon=final_lon\n",
    "print(f\"{BOLD_START}{\"Longitude data type:\":30}{BOLD_END}{str(type(lon)):20}\")\n",
    "print(f\".......shape:{lon.shape}\")\n",
    "print(f\"....datatype:{lon.dtype}\")\n",
    "\n",
    "final_varAry = np.tile(varAry, (DATASET_SIZE, DATASET_SIZE),)\n",
    "varAry=final_varAry\n",
    "print(f\"{BOLD_START}{\"Oceanogrpahic data type:\":30}{BOLD_END}{str(type(varAry)):20}\")\n",
    "print(f\".......shape:{varAry.shape}\")\n",
    "print(f\"....datatype:{varAry.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pandas_filename=f\"{WORKING_FOLDER}{os.sep}data{os.sep}acs.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Resolution has: Index(['lat', 'lon', 'chlor_a'], dtype='object')\n",
      "\n",
      "\n",
      "size                 :      24,000,000 \n",
      "shape                : (8000000, 3)    \n",
      "ndim                 :               2 \n",
      "column size          :               3 \n",
      "Read                 :               3 \n",
      "Expected             :               3 \n",
      "\u001b[1mExpectations met\u001b[0;0m.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataframe memory use:          192,000,132\n"
     ]
    }
   ],
   "source": [
    "latSeries=pd.Series(lat.flatten())\n",
    "lonSeries=pd.Series(lon.flatten())\n",
    "varSeries=pd.Series(varAry[0,0,:,:].flatten())\n",
    "\n",
    "#define a Panda.DataFrame()\n",
    "frame={geospatial_lat_nm: latSeries, geospatial_lon_nm: lonSeries, product_nm: varSeries}\n",
    "\n",
    "#instantiate a dataframe\n",
    "df=pd.DataFrame(frame)\n",
    "\n",
    "#ensure the data is cast as expected\n",
    "df[geospatial_lat_nm].astype('float64')\n",
    "df[geospatial_lon_nm].astype('float64')\n",
    "df[geospatial_lon_nm].astype('float64')\n",
    "\n",
    "#quick stats\n",
    "quick_df_stats(df, 3)\n",
    "\n",
    "# Get memory usage of each column in bytes\n",
    "memory_usage_per_column = df.memory_usage(deep=True)\n",
    "\n",
    "# Get total memory usage of the DataFrame in bytes\n",
    "total_memory_usage = df.memory_usage().sum()\n",
    "\n",
    "print(f\"Original Dataframe memory use: {total_memory_usage:20,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314 ms Â± 195 ms per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\"\"\"\n",
    "if os.path.isfile(target_pandas_filename):\n",
    "  try:\n",
    "    #removing existing file, else you would append\n",
    "    subprocess.run([\"rm\", \"-rf\", f\"{target_pandas_filename}\"], check=True)\n",
    "  except (subprocess.CalledProcessError, Exception) as e:\n",
    "    process_exception(e)\n",
    "    raise SystemError\n",
    "\"\"\"\n",
    "df.to_pickle(target_pandas_filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 ms Â± 1 ms per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df = pd.read_pickle(target_pandas_filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m df, latSeries, lonSeries, varSeries, frame\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "del df, latSeries, lonSeries, varSeries, frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_numpy_filename=f\"{WORKING_FOLDER}{os.sep}data{os.sep}acs.npy\"\n",
    "if os.path.isfile(target_numpy_filename):\n",
    "  try:\n",
    "    #removing existing file, else you would append\n",
    "    subprocess.run([\"rm\", \"-rf\", f\"{target_numpy_filename}\"], check=True)\n",
    "  except (subprocess.CalledProcessError, Exception) as e:\n",
    "    process_exception(e)\n",
    "    raise SystemError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.55 s Â± 1.22 s per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#df_numpy=df.to_numpy()\n",
    "#np.save(target_numpy_filename, df_numpy)\n",
    "\n",
    "#varying sized arrays\n",
    "np.savez(target_numpy_filename, lat=lat, lon=lon, product=varAry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 Î¼s Â± 297 ns per loop (mean Â± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "loaded_arr = np.load(target_numpy_filename+\".npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_arr = np.load(target_numpy_filename+\".npz\")\n",
    "new_lat = loaded_arr['lat']\n",
    "new_lon = loaded_arr['lon']\n",
    "new_product = loaded_arr['product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "del loaded_arr, new_lat,new_lon,new_product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pytorch_filename=f\"{WORKING_FOLDER}{os.sep}data{os.sep}acs.pt\"\n",
    "if os.path.isfile(target_pytorch_filename):\n",
    "  try:\n",
    "    #removing existing file, else you would append\n",
    "    subprocess.run([\"rm\", \"-rf\", f\"{target_pytorch_filename}\"], check=True)\n",
    "  except (subprocess.CalledProcessError, Exception) as e:\n",
    "    process_exception(e)\n",
    "    raise SystemError\n",
    "\n",
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_tensor = input_tensor.to(device)\n",
    "lat_tensor = torch.tensor(lat.flatten()).to(dev)\n",
    "lon_tensor = torch.tensor(lon.flatten()).to(dev)\n",
    "var_tensor = torch.tensor(varAry.flatten()).to(dev)\n",
    "\n",
    "#lonSeries=pd.Series(lon.flatten())\n",
    "#varSeries=pd.Series(varAry[0,0,:,:].flatten())\n",
    "\n",
    "# Save the tensor\n",
    "# Save multiple tensors as a list\n",
    "tensors_list = [lat_tensor,lon_tensor,var_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.91 s Â± 2.17 s per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "torch.save(tensors_list, target_pytorch_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915 ms Â± 77.4 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Load the tensor from the file\n",
    "tensor_loaded = torch.load(target_pytorch_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lat_tensor,lon_tensor,var_tensor,tensors_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tensorflow_filename=f\"{WORKING_FOLDER}{os.sep}data{os.sep}acs.bin\"\n",
    "if os.path.isfile(target_pandas_filename):\n",
    "  try:\n",
    "    #removing existing file, else you would append\n",
    "    subprocess.run([\"rm\", \"-rf\", f\"{target_tensorflow_filename}\"], check=True)\n",
    "  except (subprocess.CalledProcessError, Exception) as e:\n",
    "    process_exception(e)\n",
    "    raise SystemError\n",
    "# Convert Pandas DataFrame to TensorFlow tensor\n",
    "THE_DEVICE_NAME=\"/job:localhost/replica:0/task:0/device:GPU:0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(THE_DEVICE_NAME):\n",
    "    #tensor = tf.convert_to_tensor(df)   \n",
    "    lat_tensor = tf.convert_to_tensor(lat.flatten())\n",
    "    lon_tensor = tf.convert_to_tensor(lon.flatten())\n",
    "    var_tensor = tf.convert_to_tensor(varAry.flatten())\n",
    "\n",
    "    # Save the tensor\n",
    "    # Save multiple tensors as a list\n",
    "    tensors_list = [lat_tensor,lon_tensor,var_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 5.66 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "207 ms Â± 194 ms per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with tf.device(THE_DEVICE_NAME):\n",
    "    tf.io.write_file(target_tensorflow_filename, tf.io.serialize_tensor(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__ParseTensor_device_/job:localhost/replica:0/task:0/device:CPU:0}} Type mismatch between parsed tensor (double) and dtype (float) [Op:ParseTensor]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwith tf.device(THE_DEVICE_NAME):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    loaded_tensor = tf.io.parse_tensor(tf.io.read_file(target_tensorflow_filename), out_type=tf.float32)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/machine_learning_gpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2493\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2491\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2492\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2493\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2495\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2496\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2497\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.conda/envs/machine_learning_gpu/lib/python3.9/site-packages/IPython/core/magics/execution.py:1185\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m   1184\u001b[0m     number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m index\n\u001b[0;32m-> 1185\u001b[0m     time_number \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time_number \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m:\n\u001b[1;32m   1187\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/machine_learning_gpu/lib/python3.9/site-packages/IPython/core/magics/execution.py:173\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    171\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<magic-timeit>:2\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/machine_learning_gpu/lib/python3.9/site-packages/tensorflow/python/ops/gen_parsing_ops.py:2152\u001b[0m, in \u001b[0;36mparse_tensor\u001b[0;34m(serialized, out_type, name)\u001b[0m\n\u001b[1;32m   2150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2152\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2153\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   2154\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/machine_learning_gpu/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7215\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7214\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7215\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__ParseTensor_device_/job:localhost/replica:0/task:0/device:CPU:0}} Type mismatch between parsed tensor (double) and dtype (float) [Op:ParseTensor]"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with tf.device(THE_DEVICE_NAME):\n",
    "    loaded_tensor = tf.io.parse_tensor(tf.io.read_file(target_tensorflow_filename), out_type=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Xarray\n",
    "# Convert Pandas DataFrame to xarray Dataset\n",
    "target_xarray_filename=f\"{WORKING_FOLDER}{os.sep}data{os.sep}acs.nc\"\n",
    "if os.path.isfile(target_xarray_filename):\n",
    "  try:\n",
    "    #removing existing file, else you would append\n",
    "    subprocess.run([\"rm\", \"-rf\", f\"{target_xarray_filename}\"], check=True)\n",
    "  except (subprocess.CalledProcessError, Exception) as e:\n",
    "    process_exception(e)\n",
    "    raise SystemError\n",
    "ds_xr = xr.Dataset.from_dataframe(df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221 ms Â± 48.4 ms per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "ds_xr.to_netcdf(target_xarray_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.1 ms Â± 1.15 ms per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "ds_xr_loaded=xr.open_dataset(target_xarray_filename, engine=\"netcdf4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zaar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'zarr' has no attribute 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzarr\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcp\u001b[39;00m  \n\u001b[0;32m----> 8\u001b[0m \u001b[43mzarr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241m.\u001b[39menable_gpu()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'zarr' has no attribute 'config'"
     ]
    }
   ],
   "source": [
    "#Zarr\n",
    "# Save xarray Dataset to Zarr\n",
    "#ds_zarr=ds_xr.to_zarr('data.zarr')\n",
    "target_zarr_filename=f\"{WORKING_FOLDER}{os.sep}data{os.sep}acs_zarr_store.zarr\"\n",
    "ds_xr=xr.open_dataset(target_xarray_filename, engine=\"netcdf4\")    \n",
    "import zarr\n",
    "import cupy as cp  \n",
    "zarr.config.enable_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed ./folderOnColab/data/acs_zarr_store.zarr.\n",
      "Removed ./folderOnColab/data/acs_zarr_store.zarr.\n",
      "Removed ./folderOnColab/data/acs_zarr_store.zarr.\n",
      "Removed ./folderOnColab/data/acs_zarr_store.zarr.\n",
      "Removed ./folderOnColab/data/acs_zarr_store.zarr.\n",
      "Removed ./folderOnColab/data/acs_zarr_store.zarr.\n",
      "Removed ./folderOnColab/data/acs_zarr_store.zarr.\n",
      "Removed ./folderOnColab/data/acs_zarr_store.zarr.\n",
      "394 ms Â± 25.3 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "if os.path.isdir(target_zarr_filename):\n",
    "  try:\n",
    "    #removing existing file, else you would append\n",
    "    subprocess.run([\"rm\", \"-rf\", f\"{target_zarr_filename}\"], check=True)\n",
    "    print(f\"Removed {target_zarr_filename}.\")\n",
    "  except (subprocess.CalledProcessError, Exception) as e:\n",
    "    process_exception(e)\n",
    "    raise SystemError\n",
    "#ds_xr.chunk({'index': 1000}).to_zarr(target_zarr_filename)\n",
    "ds_xr.to_zarr(target_zarr_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.1 ms Â± 974 Âµs per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "ds_zarr = xr.open_zarr(target_zarr_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apache Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_parquet_filename=f\"{WORKING_FOLDER}{os.sep}data{os.sep}ACS.parquet.gzip\"\n",
    "if os.path.isfile(target_parquet_filename):\n",
    "  try:\n",
    "    #removing existing file, else you would append\n",
    "    subprocess.run([\"rm\", \"-rf\", f\"{target_parquet_filename}\"], check=True)\n",
    "  except (subprocess.CalledProcessError, Exception) as e:\n",
    "    process_exception(e)\n",
    "    raise SystemError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.54 s Â± 84.3 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df.to_parquet(target_parquet_filename,compression='gzip')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit\n",
    "df_parquet=pd.read_parquet(target_parquet_filename)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import dask.bag as db\n",
    "\n",
    "target_dask_filename=f\"{WORKING_FOLDER}{os.sep}data{os.sep}ACS\"\n",
    "      \n",
    "df_dask = dd.from_pandas(df, npartitions=1)\n",
    "\n",
    "# Convert DataFrame rows to dictionaries and create a Dask bag\n",
    "df_bag = db.from_sequence(df.to_dict(orient='records'))\n",
    "\n",
    "# Print the Dask bag (computation is lazy, so compute() is needed to see the result)\n",
    "print(df_bag.compute())\n",
    "\n",
    "schema = {'name': 'People', 'doc': \"Set of people's scores\",\n",
    "          'type': 'record',\n",
    "          'fields': [\n",
    "              {'name': 'name', 'type': 'string'},\n",
    "              {'name': 'value', 'type': 'int'}]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "#df_bag.to_avro(f\"{target_dask_filename}.*.avro\", schema)  \n",
    "df_bag.to_avro(f\"{target_dask_filename}.*.avro\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "loaded_df_bag = db.read_avro(f\"{target_dask_filename}.*.avro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Second(UTC)</th>\n",
       "      <th>Longitude(deg)</th>\n",
       "      <th>Latitude(deg)</th>\n",
       "      <th>Pressure(dbar)</th>\n",
       "      <th>...</th>\n",
       "      <th>A709.2</th>\n",
       "      <th>A713.4</th>\n",
       "      <th>A717.1</th>\n",
       "      <th>A720.8</th>\n",
       "      <th>A724.6</th>\n",
       "      <th>A728.6</th>\n",
       "      <th>A732.1</th>\n",
       "      <th>A735.6</th>\n",
       "      <th>A738.9</th>\n",
       "      <th>A742.7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>55.250000</td>\n",
       "      <td>82.500430</td>\n",
       "      <td>6.388097</td>\n",
       "      <td>56.674187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014609</td>\n",
       "      <td>0.018101</td>\n",
       "      <td>0.020589</td>\n",
       "      <td>0.023703</td>\n",
       "      <td>0.026160</td>\n",
       "      <td>0.027270</td>\n",
       "      <td>0.026489</td>\n",
       "      <td>0.027488</td>\n",
       "      <td>0.030790</td>\n",
       "      <td>0.032814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>56.250000</td>\n",
       "      <td>82.500432</td>\n",
       "      <td>6.388067</td>\n",
       "      <td>56.763824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007610</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.015743</td>\n",
       "      <td>0.019404</td>\n",
       "      <td>0.023228</td>\n",
       "      <td>0.028279</td>\n",
       "      <td>0.030916</td>\n",
       "      <td>0.030992</td>\n",
       "      <td>0.032134</td>\n",
       "      <td>0.030258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>57.249001</td>\n",
       "      <td>82.500433</td>\n",
       "      <td>6.388037</td>\n",
       "      <td>56.860547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018078</td>\n",
       "      <td>0.016237</td>\n",
       "      <td>0.015958</td>\n",
       "      <td>0.010981</td>\n",
       "      <td>0.007080</td>\n",
       "      <td>0.007578</td>\n",
       "      <td>0.005932</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>0.004662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>58.250000</td>\n",
       "      <td>82.500434</td>\n",
       "      <td>6.388008</td>\n",
       "      <td>56.958323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018148</td>\n",
       "      <td>0.019505</td>\n",
       "      <td>0.021039</td>\n",
       "      <td>0.022217</td>\n",
       "      <td>0.023576</td>\n",
       "      <td>0.031535</td>\n",
       "      <td>0.033917</td>\n",
       "      <td>0.028271</td>\n",
       "      <td>0.026150</td>\n",
       "      <td>0.023259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>59.249001</td>\n",
       "      <td>82.500434</td>\n",
       "      <td>6.387980</td>\n",
       "      <td>57.056766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.013016</td>\n",
       "      <td>0.012733</td>\n",
       "      <td>0.010946</td>\n",
       "      <td>0.010736</td>\n",
       "      <td>0.012069</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>0.019891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    Year  Month   Day  Hour  Minute  Second(UTC)  Longitude(deg)  \\\n",
       "0      0  2018.0    7.0  18.0   3.0    54.0    55.250000       82.500430   \n",
       "1      1  2018.0    7.0  18.0   3.0    54.0    56.250000       82.500432   \n",
       "2      2  2018.0    7.0  18.0   3.0    54.0    57.249001       82.500433   \n",
       "3      3  2018.0    7.0  18.0   3.0    54.0    58.250000       82.500434   \n",
       "4      4  2018.0    7.0  18.0   3.0    54.0    59.249001       82.500434   \n",
       "\n",
       "   Latitude(deg)  Pressure(dbar)  ...    A709.2    A713.4    A717.1    A720.8  \\\n",
       "0       6.388097       56.674187  ...  0.014609  0.018101  0.020589  0.023703   \n",
       "1       6.388067       56.763824  ...  0.007610  0.009700  0.015743  0.019404   \n",
       "2       6.388037       56.860547  ...  0.018078  0.016237  0.015958  0.010981   \n",
       "3       6.388008       56.958323  ...  0.018148  0.019505  0.021039  0.022217   \n",
       "4       6.387980       57.056766  ...  0.012500  0.013016  0.012733  0.010946   \n",
       "\n",
       "     A724.6    A728.6    A732.1    A735.6    A738.9    A742.7  \n",
       "0  0.026160  0.027270  0.026489  0.027488  0.030790  0.032814  \n",
       "1  0.023228  0.028279  0.030916  0.030992  0.032134  0.030258  \n",
       "2  0.007080  0.007578  0.005932  0.007313  0.007289  0.004662  \n",
       "3  0.023576  0.031535  0.033917  0.028271  0.026150  0.023259  \n",
       "4  0.010736  0.012069  0.014006  0.015610  0.014729  0.019891  \n",
       "\n",
       "[5 rows x 176 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PySTAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystac\n",
    "from pystac.utils import datetime_to_str\n",
    "from stacframes import df_from\n",
    "\n",
    "# Sample pandas DataFrame\n",
    "data = {'id': ['item1', 'item2'], \n",
    "        'geometry': [{'type': 'Point', 'coordinates': [1, 1]}, \n",
    "                     {'type': 'Point', 'coordinates': [2, 2]}],\n",
    "        'datetime': [pd.Timestamp('2023-01-01'), pd.Timestamp('2023-01-02')],\n",
    "        'properties': [{'prop1': 'value1'}, {'prop1': 'value2'}]}\n",
    "\n",
    "# Create a STAC Catalog\n",
    "catalog = pystac.Catalog.from_dict({\"type\": \"Catalog\", \"id\": \"acs\", \"stac_version\": \"1.0.0\"})\n",
    "\n",
    "# Convert DataFrame to STAC Items and add to Catalog\n",
    "for index, row in df.iterrows():\n",
    "    item = pystac.Item(id=row['id'], \n",
    "                        geometry=row['geometry'],\n",
    "                        datetime=row['datetime'].to_pydatetime(),\n",
    "                        properties=row['properties'])\n",
    "    catalog.add_item(item)\n",
    "\n",
    "# Write the catalog to a file\n",
    "catalog.normalize_hrefs(\"./pystac_data\")\n",
    "catalog.save_object(pystac.Catalog, \"acs.json\")\n",
    "\n",
    "# Read STAC catalog into a DataFrame\n",
    "#df_from_stac = df_from(catalog)\n",
    "#print(df_from_stac)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "STEM-004_ComputerVision.ipynb",
   "provenance": []
  },
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "033cb5a8c21c4ca5a13b5d03e8b78fa0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ebb9ca01cf52473699f21f15c5ec7d34",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_689fe090492947608518efc9f3bd6d5d",
      "value": "\n        <center><table><tr><td><h1 style=\"font-family: Roboto;font-size: 24px\"><b>&#128721; &#9888;&#65039; WARNING &#9888;&#65039;\t&#128721; </b></h1></td></tr></table</center></br></br>\n          "
     }
    },
    "0d8988d435644a928829ef71435a3e83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1015b1ce380943d48c7a6386444c768a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f5405303114146a28663cb1c46db7beb",
       "IPY_MODEL_bdc74a6d20a041819b6fc6d1c3f85a25",
       "IPY_MODEL_033cb5a8c21c4ca5a13b5d03e8b78fa0"
      ],
      "layout": "IPY_MODEL_2b447186de7a4571821ca59295744ce3"
     }
    },
    "202c8798fdda4778bf09a2124c37a6c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "usfs-ai-bootcamp",
       "usfa-ai-advanced-training",
       "I will setup my own"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Set Your Project:",
      "description_tooltip": null,
      "disabled": false,
      "index": 0,
      "layout": "IPY_MODEL_dd3de71c792f4762af3b280ac9b7f5e6",
      "style": "IPY_MODEL_fc3fc48bdebe4501998819fbda36152c"
     }
    },
    "2b447186de7a4571821ca59295744ce3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "31b012d7d41a4d06933aa38e8e3bd74a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "479233081fbc44c8afe9a044ebb95faf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "689fe090492947608518efc9f3bd6d5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ad3b9f4855d541e49303c03fb9f07db7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Accept",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_f196621910824a00a97d06e5433cb294",
      "style": "IPY_MODEL_31b012d7d41a4d06933aa38e8e3bd74a",
      "tooltip": ""
     }
    },
    "bdc74a6d20a041819b6fc6d1c3f85a25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_202c8798fdda4778bf09a2124c37a6c7",
       "IPY_MODEL_ad3b9f4855d541e49303c03fb9f07db7"
      ],
      "layout": "IPY_MODEL_0d8988d435644a928829ef71435a3e83"
     }
    },
    "cf363ab273bf4eeba7fbea4d79ed3a64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd3de71c792f4762af3b280ac9b7f5e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebb9ca01cf52473699f21f15c5ec7d34": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f196621910824a00a97d06e5433cb294": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5405303114146a28663cb1c46db7beb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf363ab273bf4eeba7fbea4d79ed3a64",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_479233081fbc44c8afe9a044ebb95faf",
      "value": "\n        <center><table><tr><td><h1 style=\"font-family: Roboto;font-size: 24px\"><b>&#128721; &#9888;&#65039; WARNING &#9888;&#65039;\t&#128721; </b></h1></td></tr></table</center></br></br>\n\n        <table><tr><td>\n            <span style=\"font-family: Tahoma;font-size: 18\">\n              This notebook was designed to work in Jupyter Notebook or Google Colab with the understnading that certain permissions might be enabled.</br>\n              Please verify that you are in the appropriate project and that the:</br>\n              <center><code><b>PROJECT_ID</b></code> </br></center>\n              aligns with the Project Id in the upper left corner of this browser and that the location:\n              <center><code><b>LOCATION</b></code> </br></center>\n              aligns with the instructions provided.\n            </span>\n          </td></tr></table></br></br>\n\n    "
     }
    },
    "fc3fc48bdebe4501998819fbda36152c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
