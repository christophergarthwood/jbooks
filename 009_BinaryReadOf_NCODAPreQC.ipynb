{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading FORTRAN generated binary output\n",
    "## NCODA Pre-QC\n",
    "\n",
    "Includes references to plotting using Matplotlib and related tools.\n",
    "\n",
    "This program reads in a single input file after definine a binary \"struct\" with which to read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish setup for graphics, appropriate for jupyter lab\n",
    "%matplotlib inline\n",
    "#use nbagg for interactivity\n",
    "#%matplotlib nbagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# INCLUDES\n",
    "############################################\n",
    "#libraries specific to this example\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#plotting\n",
    "import matplotlib as matplt\n",
    "import matplotlib.pyplot as plt\n",
    "#geographic libraries\n",
    "from cartopy import crs as ccrs\n",
    "\n",
    "#byte manipulation and endianess\n",
    "import sys\n",
    "\n",
    "# for NetCDF output\n",
    "from scipy.io import netcdf\n",
    "\n",
    "#a set of libraries that perhaps should always be in Python source\n",
    "import os \n",
    "from datetime import datetime\n",
    "import sys\n",
    "import gc\n",
    "import getopt\n",
    "import inspect\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "from pydoc import help                          # can type in the python console `help(name of function)` to get the documentation\n",
    "\n",
    "#a darn useful library for creating paths and one I recommend you load to your environment\n",
    "from pathlib import Path\n",
    "\n",
    "#Import a custom library, in this case a fairly useful logging framework\n",
    "if os.environ.get('LIB_LOCATION') is not None:\n",
    "    debug_lib_location = Path(os.getenv('LIB_LOCATION'))\n",
    "else:\n",
    "    debug_lib_location = Path(\"./\")\n",
    "                              \n",
    "if os.environ.get('DATA_LOCATION') is not None:\n",
    "    root_location = os.getenv('DATA_LOCATION')\n",
    "else:\n",
    "    root_location=\"..\" + os.sep + \"data\";                              \n",
    "sys.path.append(str(debug_lib_location))\n",
    "\n",
    "import debug\n",
    "\n",
    "warnings.filterwarnings('ignore')               # don't print out warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "#JUPYTER NOTEBOOK OUTPUT CONTROL / FORMATTING\n",
    "############################################\n",
    "#set floating point to 4 places to things don't run loose\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# GLOBAL VARIABLES\n",
    "############################################\n",
    "DEBUG = 1\n",
    "DEBUG_DATA = 0\n",
    "\n",
    "# CODE CONSTRAINTS\n",
    "VERSION_NAME    = \"NCODA_PREQC\"\n",
    "VERSION_MAJOR   = 0\n",
    "VERSION_MINOR   = 0\n",
    "VERSION_RELEASE = 1\n",
    "\n",
    "#used for values outside standard ASCII, just do it, you'll need it\n",
    "ENCODING  =\"utf-8\"\n",
    "\n",
    "############################################\n",
    "# GLOBAL CONSTANTS\n",
    "############################################\n",
    "\n",
    "\n",
    "############################################\n",
    "# APPLICATION VARIABLES\n",
    "############################################\n",
    "\n",
    "#variable persistence\n",
    "today = datetime.today()\n",
    "\n",
    "############################################\n",
    "# GLOBAL CONFIGURATION\n",
    "############################################\n",
    "os.environ['PYTHONIOENCODING']=ENCODING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Defining a Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lib_diagnostics():\n",
    "    debug.msg_debug(\"System version    #:{:>12}\".format(sys.version))\n",
    "    debug.msg_debug(\"Matplotlib version#:{:>12}\".format(matplt.__version__))\n",
    "    debug.msg_debug(\"Numpy version     #:{:>12}\".format(np.__version__))\n",
    "    debug.msg_debug(\"Pandas version    #:{:>12}\".format(pd.__version__))\n",
    "    debug.msg_debug(\"SciPy version     #:{:>12}\".format(sp.__version__))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Invocation\n",
    "### Note that it's also useful to use this code so that you carry around a list of version dependencies and know how you did something (version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-12-14 18:56:43 UTC]   DEBUG: System version    #:3.9.15 (main, Nov  4 2022, 16:13:54) \n",
      "[GCC 11.2.0] \n",
      "[2022-12-14 18:56:43 UTC]   DEBUG: Matplotlib version#:       3.5.3 \n",
      "[2022-12-14 18:56:43 UTC]   DEBUG: Numpy version     #:      1.23.4 \n",
      "[2022-12-14 18:56:43 UTC]   DEBUG: Pandas version    #:       1.5.1 \n",
      "[2022-12-14 18:56:43 UTC]   DEBUG: SciPy version     #:       1.9.3 \n"
     ]
    }
   ],
   "source": [
    "lib_diagnostics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOPS Parser Slice Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "#CONSTANTS\n",
    "#################################################################################   \n",
    "\n",
    "#Notice that this is a 300 MB binary file which is NOT included in these training sets.\n",
    "DATA_DIR=Path(\"..\"+os.sep+\"data\")\n",
    "\n",
    "#NRL employees\n",
    "#DATA_DIR=Path(\"/u/yamm/cwood/outgoing/VISOR\")\n",
    "\n",
    "DATA_FILE=[\"merged.2020032.0201.L5.6D.a_490_lmi.nc_202001270400_a_490_lmi_2.out\"]\n",
    "\n",
    "#each record in FORTRAN \"bounded\" by a value that specifies how big the next block to read is hence the RB or record boundary value\n",
    "FORTRAN_RB_CHUNK_SIZE=4\n",
    "\n",
    "#expressly defining data types as the original FORTRAN implementation is specific as well\n",
    "FORTRAN_INT_CHUNK_SIZE=4\n",
    "FORTRAN_REAL_CHUNK_SIZE=4\n",
    "DATA_CHUNK=0\n",
    "ENDIANESS='big'\n",
    "\n",
    "#Data formatting (least significant digit)\n",
    "LSD=4\n",
    "\n",
    "#Geospatial filter criteria, known for this specific data file (Gulf of Mexico)\n",
    "FLTR_NW_LAT=31.0519\n",
    "FLTR_NW_LON=-98.4798\n",
    "FLTR_SE_LAT=19.2310\n",
    "FLTR_SE_LON=-80.9669\n",
    "FLTR_DATA = (\"lat > \" + str(FLTR_SE_LAT) + \" & lat < \" + str(FLTR_NW_LAT) + \" & lon > \" + str(FLTR_NW_LON) + \" & lon < \" + str(FLTR_SE_LON) )\n",
    "\n",
    "#define data structure of the NCODA-PreQC/VISOR output\n",
    "preQC_datatype=np.dtype([('frb_nrec1', '>i4'),\n",
    "                         ('nrec','>i4'),\n",
    "                         ('frb_nrec2', '>i4'),\n",
    "                         ('frb_dtype1', '>i4'),\n",
    "                         ('dtype','>i4'),\n",
    "                         ('frb_dtype2', '>i4'),\n",
    "                         ('frb_dtg1', '>i4'),\n",
    "                         ('dtg','>a12'),\n",
    "                         ('frb_dtg2', '>i4')\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "#Mapping routines to show where data resides (leaves much to be desired and\n",
    "#doesn't make use of 008_mapping*.ipynb.\n",
    "#################################################################################   \n",
    "def show_map_coverage(inc_dataframe):\n",
    "\n",
    "    TARGET_DATAFRAME = inc_dataframe\n",
    "\n",
    "    central_longitude = np.median(TARGET_DATAFRAME[\"lon\"])\n",
    "    central_latitude = np.median(TARGET_DATAFRAME[\"lat\"])\n",
    "    west = np.min(TARGET_DATAFRAME[\"lon\"]) - 1.5\n",
    "    east = np.max(TARGET_DATAFRAME[\"lon\"]) + 1.5\n",
    "    north = np.max(TARGET_DATAFRAME[\"lat\"]) + 1.5\n",
    "    south = np.min(TARGET_DATAFRAME[\"lat\"]) - 1.5\n",
    "\n",
    "    matplt.use('Agg')\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "    ax.set_extent([west, east, south, north])\n",
    "    ax.coastlines()\n",
    "    ax.stock_img()\n",
    "    ax.gridlines()\n",
    "    ax.add_wms(wms=\"http://vmap0.tiles.osgeo.org/wms/vmap0\", layers=[\"basic\"])\n",
    "\n",
    "    DATA_COLOR = \"red\"\n",
    "    DATA_SIZE = 0.10 \n",
    "    ax.scatter(TARGET_DATAFRAME[\"lon\"], TARGET_DATAFRAME[\"lat\"], c=DATA_COLOR, s=DATA_SIZE)\n",
    "\n",
    "    #output_filename=PROJ_OUTPUT_LOC / str( build_output_graphic_filename(inc_area,inc_date,inc_depth_index)+str(\"_\") + inc_name+(\"_map.png\") )\n",
    "    #debug.msg_debug(\"Graphics output filename:\"+str(output_filename))\n",
    "    #plt.savefig(output_filename)\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-12-14 18:58:39 UTC]   DEBUG: Processing 202001270400a for ../data/merged.2020032.0201.L5.6D.a_490_lmi.nc_202001270400_a_490_lmi_2.out \n",
      "[2022-12-14 18:58:39 UTC]   DEBUG: [(4, 26154810, 4, 4, 219, 4, 12, b'202001270400', 12)] \n",
      "[2022-12-14 18:58:39 UTC]   DEBUG: Total records to read in for each array:26154810 \n",
      "[2022-12-14 18:58:39 UTC]   DEBUG: Total bytes to read in for each array:[104619240] \n",
      "[2022-12-14 18:58:39 UTC]    INFO: ...processing lat data from PreQC \n",
      "[2022-12-14 18:58:39 UTC]   DEBUG: ......statistics: \n",
      "[2022-12-14 18:58:39 UTC]   DEBUG: .........min:-74.99 \n",
      "[2022-12-14 18:58:39 UTC]   DEBUG: .........max:50.31 \n",
      "[2022-12-14 18:58:39 UTC]   DEBUG: ........mean:-12.222337 \n",
      "[2022-12-14 18:58:39 UTC]   DEBUG: Lat size:26154810 \n",
      "[2022-12-14 18:58:39 UTC]    INFO: ...processing lon data from PreQC \n",
      "[2022-12-14 18:58:39 UTC]   DEBUG: ......statistics: \n",
      "[2022-12-14 18:58:39 UTC]   DEBUG: .........min:-100.0 \n",
      "[2022-12-14 18:58:39 UTC]   DEBUG: .........max:-60.01 \n",
      "[2022-12-14 18:58:39 UTC]   DEBUG: ........mean:-82.78701 \n",
      "[2022-12-14 18:58:39 UTC]   DEBUG: Lon size:26154810 \n",
      "[2022-12-14 18:58:39 UTC]    INFO: ...processing optics data from PreQC \n",
      "[2022-12-14 18:58:39 UTC]   DEBUG: ......statistics: \n",
      "[2022-12-14 18:58:39 UTC]   DEBUG: .........min:0.00069999695 \n",
      "[2022-12-14 18:58:39 UTC]   DEBUG: .........max:3.266 \n",
      "[2022-12-14 18:58:39 UTC]   DEBUG: ........mean:0.034290344 \n",
      "[2022-12-14 18:58:40 UTC]   DEBUG: Optics size:26154810 \n",
      "[2022-12-14 18:58:42 UTC]   DEBUG: Original dataset shape:(26154810, 3) \n",
      "[2022-12-14 18:58:42 UTC]   DEBUG:    GOMEX dataset shape:(1433620, 3) \n",
      "[2022-12-14 18:58:42 UTC]   DEBUG:    GOMEX lat dimension:1433620 \n",
      "[2022-12-14 18:58:42 UTC]   DEBUG:    GOMEX lon dimension:1433620 \n",
      "[2022-12-14 18:58:48 UTC]    INFO:   \n",
      "[2022-12-14 18:58:48 UTC]    INFO: ##################################################################################################################### \n"
     ]
    }
   ],
   "source": [
    "#loop through the datafiles provided\n",
    "for file in DATA_FILE:\n",
    "    target_input_file=Path(DATA_DIR / file)\n",
    "    netcdf_filename=Path(DATA_DIR / str(file + \".nc\") )\n",
    "    \n",
    "    #meta-data capture from filename (merged_2019317_201911130400_a_490_lmi_2)\n",
    "    file_meta_data = file.split('_')\n",
    "    product_name=\"\".join(file_meta_data[3:5:1])\n",
    "    debug.msg_debug(\"Processing \" + str(product_name) + \" for \"+ str(target_input_file))\n",
    "\n",
    "    in_file=open(target_input_file, 'rb')\n",
    "    \n",
    "    #################################################################################\n",
    "    #Binary read using the pre-defined structure\n",
    "    #################################################################################    \n",
    "    x=np.fromfile(in_file, dtype=preQC_datatype,count=1)\n",
    "    DATA_CHUNK= FORTRAN_REAL_CHUNK_SIZE * x['nrec']\n",
    "    debug.msg_debug(x)\n",
    "    debug.msg_debug(\"Total records to read in for each array:\"+str(x['nrec'][0]))\n",
    "    debug.msg_debug(\"Total bytes to read in for each array:\"+str(DATA_CHUNK))\n",
    "    \n",
    "    number_records=str(x['nrec'][0])\n",
    "    array_structure=\">\"+ number_records +\"f4\"\n",
    "    array_dtype=np.dtype([('frb_ary1', '>i4'),('array',array_structure),('frb_ary2', '>i4')])\n",
    "\n",
    "    debug.msg_info(\"...processing lat data from PreQC\")\n",
    "    y=np.fromfile(in_file, dtype=array_dtype,count=1)\n",
    "    array=y['array']\n",
    "    debug.msg_debug(\"......statistics:\")\n",
    "    debug.msg_debug(\".........min:\" + str(np.nanmin(array)))\n",
    "    debug.msg_debug(\".........max:\" + str(np.nanmax(array)))\n",
    "    debug.msg_debug(\"........mean:\" + str(np.nanmean(array)))\n",
    "    lat=np.array(array).byteswap().newbyteorder()\n",
    "    debug.msg_debug(\"Lat size:\"+str(lat.size))\n",
    "    \n",
    "    debug.msg_info(\"...processing lon data from PreQC\")\n",
    "    y=np.fromfile(in_file, dtype=array_dtype,count=1)\n",
    "    array=y['array']\n",
    "    debug.msg_debug(\"......statistics:\")\n",
    "    debug.msg_debug(\".........min:\" + str(np.nanmin(array)))\n",
    "    debug.msg_debug(\".........max:\" + str(np.nanmax(array)))\n",
    "    debug.msg_debug(\"........mean:\" + str(np.nanmean(array)))\n",
    "    lon=np.array(array).byteswap().newbyteorder()\n",
    "    debug.msg_debug(\"Lon size:\"+str(lon.size))\n",
    "\n",
    "    debug.msg_info(\"...processing optics data from PreQC\")\n",
    "    y=np.fromfile(in_file, dtype=array_dtype,count=1)\n",
    "    array=y['array']\n",
    "    debug.msg_debug(\"......statistics:\")\n",
    "    debug.msg_debug(\".........min:\" + str(np.nanmin(array)))\n",
    "    debug.msg_debug(\".........max:\" + str(np.nanmax(array)))\n",
    "    debug.msg_debug(\"........mean:\" + str(np.nanmean(array)))\n",
    "    optics=np.array(array).byteswap().newbyteorder()\n",
    "    debug.msg_debug(\"Optics size:\"+str(optics.size))\n",
    "    \n",
    "    #################################################################################\n",
    "    #casting data-types from float 32 to int64 to support .query operation\n",
    "    #################################################################################    \n",
    "    df=pd.DataFrame({'lat':lat[0,:], 'lon':lon[0,:], 'optics':optics[0,:]})\n",
    "    lat=df['lat']\n",
    "    df['lat'] = lat.astype('float', copy=True)\n",
    "    lon=df['lon']\n",
    "    df['lon'] = lon.astype('float', copy=True)\n",
    "    optics=df['optics']\n",
    "    df['optics'] = optics.astype('float', copy=True)\n",
    "    \n",
    "    #################################################################################\n",
    "    #Pandas, filtering data down to focal area\n",
    "    #################################################################################    \n",
    "    GOMEX=df.query(FLTR_DATA)\n",
    "\n",
    "    #################################################################################\n",
    "    #Debug output showing data reduction due to the filter\n",
    "    #################################################################################    \n",
    "    debug.msg_debug(\"Original dataset shape:\"+ str(df.shape))\n",
    "    debug.msg_debug(\"   GOMEX dataset shape:\"+ str(GOMEX.shape))\n",
    "    debug.msg_debug(\"   GOMEX lat dimension:\" + str(GOMEX['lat'].size))\n",
    "    debug.msg_debug(\"   GOMEX lon dimension:\" + str(GOMEX['lon'].size))\n",
    "\n",
    "    #################################################################################\n",
    "    #Create a map showing the total swath of the output\n",
    "    #################################################################################    \n",
    "    show_map_coverage(df)\n",
    "    #################################################################################\n",
    "    #Create a map showing the filtered data set and focal point of analysis\n",
    "    #################################################################################    \n",
    "    show_map_coverage(GOMEX)\n",
    "\n",
    "    #################################################################################\n",
    "    #Clean up unused variables\n",
    "    #################################################################################    \n",
    "    del x\n",
    "    del array\n",
    "    del lat\n",
    "    del lon\n",
    "    del optics\n",
    "    del df    \n",
    "   \n",
    "    #################################################################################\n",
    "    # NetCDF build after marshaling data.\n",
    "    #################################################################################    \n",
    "    inc_lat_dim = GOMEX['lat'].size\n",
    "    inc_lon_dim = GOMEX['lon'].size  \n",
    "    \n",
    "    #close data file read in\n",
    "    in_file.close()\n",
    "\n",
    "    #################################################################################\n",
    "    #NetCDF global attributes\n",
    "    #################################################################################    \n",
    "    dataset = netcdf.netcdf_file(netcdf_filename, \"w\")\n",
    "    meta_data_input=\"Visible Band Satellite Data to Improve Ocean Model Radiative Transfer (VISOR)\"\n",
    "    dataset.title = meta_data_input.encode(ENCODING, errors='ignore').strip()\n",
    "    meta_data_input=\"Test validation for \" + str(file)\n",
    "    dataset.subtitle = meta_data_input.encode(ENCODING, errors='ignore')\n",
    "    meta_data_input=\"Created with Jupyter Lab, NetCDF4 libraries, GOPS VISOR Parser input file.\"\n",
    "    dataset.description = meta_data_input.encode(ENCODING, errors='ignore')\n",
    "    meta_data_input=\"Created \" + today.strftime(\"%d/%m/%y\")\n",
    "    dataset.history = meta_data_input.encode(ENCODING, errors='ignore')\n",
    "\n",
    "\n",
    "    #################################################################################\n",
    "    #NetCDF dimension declaration\n",
    "    #################################################################################    \n",
    "    lat_dim = dataset.createDimension(\"lat\", inc_lat_dim)\n",
    "    lon_dim = dataset.createDimension(\"lon\", inc_lon_dim)\n",
    "    optics_dim = dataset.createDimension(\"optics\", inc_lon_dim)\n",
    "    x_dim = dataset.createDimension(\"x\", inc_lat_dim)\n",
    "    y_dim = dataset.createDimension(\"y\", inc_lon_dim)\n",
    "\n",
    " \n",
    "    #NetCDF Variable creation and data assignment\n",
    "    #################################################################################\n",
    "    # Latitude\n",
    "    #################################################################################    \n",
    "    lat_reference = dataset.createVariable(\"lat\", \"f8\", (\"lat\",))\n",
    "    lat_reference.units=\"degrees north\"\n",
    "    lat_reference[:] = GOMEX['lat']\n",
    "    \n",
    "    #################################################################################\n",
    "    # Longitude\n",
    "    #################################################################################    \n",
    "    lon_reference = dataset.createVariable(\"lon\", \"f8\", (\"lon\",))\n",
    "    lon_reference.units=\"degrees east\"\n",
    "    lon_reference[:] = GOMEX['lon']\n",
    "    \n",
    "    #################################################################################\n",
    "    # Optics Data\n",
    "    #################################################################################    \n",
    "    optics_reference = dataset.createVariable(\"optics\", \"f8\", (\"optics\",))\n",
    "    optics_reference[:] = GOMEX['optics']\n",
    "    optics_reference.units=\"m^-1\"\n",
    "    optics_reference.warning = str(product_name) + \" generated from GOPS Parser, originated from GOPS processing system.\"\n",
    "\n",
    "    dataset.close()\n",
    "    debug.msg_info(\" \")\n",
    "    debug.msg_info(\"#####################################################################################################################\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
