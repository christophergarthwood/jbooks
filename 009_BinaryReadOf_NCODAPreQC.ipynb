{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG9kZtn1--J7"
      },
      "source": [
        "# Reading FORTRAN generated binary output\n",
        "## NCODA Pre-QC\n",
        "\n",
        "Includes references to plotting using Matplotlib and related tools.\n",
        "\n",
        "This program reads in a single input file after definine a binary \"struct\" with which to read in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uC9aAcY4--J7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724800110586,
          "user_tz": 300,
          "elapsed": 245,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "#Establish setup for graphics, appropriate for jupyter lab\n",
        "%matplotlib inline\n",
        "#use nbagg for interactivity\n",
        "#%matplotlib nbagg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUCKET_NAME     = \"ai-training-2024-08-09-bucket\"\n",
        "PROJECT_ID      = \"ai-training-2024-08-09\"\n",
        "LOCATION        = \"us-central1\"\n",
        "secret_name     = \"ai-training-key-secret\"\n",
        "secret_version  = \"latest\"\n",
        "project_id      = \"usfs-tf-admin\"\n",
        "resource_name   = f\"projects/{project_id}/secrets/{secret_name}/versions/{secret_version}\""
      ],
      "metadata": {
        "id": "f6PuTfX0--6r",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724800110587,
          "user_tz": 300,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "#- Google Colab Check\n",
        "# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "RunningInCOLAB = False\n",
        "RunningInCOLAB = 'google.colab' in str(get_ipython())\n",
        "\n",
        "if RunningInCOLAB:\n",
        "    print(\"You are running this notebook in Google Colab.\")\n",
        "else:\n",
        "    print(\"You are running this notebook with Jupyter iPython runtime.\")\n",
        "    print(\"Assumption is you have the required libraries to execute this notebook.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a78h7weS-_nU",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724800110856,
          "user_tz": 300,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "aebffcd1-1603-48bd-ebc6-f01523a4f3f9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are running this notebook in Google Colab.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import subprocess\n",
        "import importlib.util"
      ],
      "metadata": {
        "id": "enIM74Q3_CCd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724800111080,
          "user_tz": 300,
          "elapsed": 1,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "libraries=[\"numpy\", \"pandas\", \"scipy\", \"sklearn\", \"matplotlib\", \"xarray\", \"seaborn\", \"cartopy\", \"owslib\"]\n",
        "import importlib.util\n",
        "\n",
        "for library in libraries:\n",
        "    if library == \"Pillow\":\n",
        "      spec = importlib.util.find_spec(\"PIL\")\n",
        "    else:\n",
        "      spec = importlib.util.find_spec(library)\n",
        "    if spec is None:\n",
        "      print(\"Installing library \" + library)\n",
        "      subprocess.run([\"pip\", \"install\" , library, \"--quiet\"])\n",
        "    else:\n",
        "      print(\"Library \" + library + \" already installed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUjuAPqT_EIF",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724800121438,
          "user_tz": 300,
          "elapsed": 10196,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "7547b638-33ff-485c-af4f-d9a7f1fee236"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Library numpy already installed.\n",
            "Library pandas already installed.\n",
            "Library scipy already installed.\n",
            "Library sklearn already installed.\n",
            "Library matplotlib already installed.\n",
            "Library xarray already installed.\n",
            "Library seaborn already installed.\n",
            "Installing library cartopy\n",
            "Installing library owslib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Includes and Libraries"
      ],
      "metadata": {
        "id": "SdYaMw78_MwO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gopya9UK--J7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724800339192,
          "user_tz": 300,
          "elapsed": 251,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "############################################\n",
        "# INCLUDES\n",
        "############################################\n",
        "#libraries specific to this example\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#plotting\n",
        "import matplotlib as matplt\n",
        "import matplotlib.pyplot as plt\n",
        "#geographic libraries\n",
        "from cartopy import crs as ccrs\n",
        "from matplotlib.offsetbox import AnchoredText\n",
        "from shapely.geometry import Polygon\n",
        "import owslib\n",
        "import geopandas as gd\n",
        "\n",
        "#byte manipulation and endianess\n",
        "import sys\n",
        "\n",
        "# for NetCDF output\n",
        "from scipy.io import netcdf\n",
        "\n",
        "#a set of libraries that perhaps should always be in Python source\n",
        "import os\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import gc\n",
        "import getopt\n",
        "import inspect\n",
        "import math\n",
        "import warnings\n",
        "\n",
        "from pydoc import help                          # can type in the python console `help(name of function)` to get the documentation\n",
        "\n",
        "#a darn useful library for creating paths and one I recommend you load to your environment\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')               # don't print out warnings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pull in Library Functions"
      ],
      "metadata": {
        "id": "wc7N_8Y6_SMn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y45sSLJd--J8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724800124556,
          "user_tz": 300,
          "elapsed": 457,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "e79d4a20-c875-42c3-c0ea-a4d723ad9c82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating a folder (./folderOnColab) to store project data.\n",
            "Performing wget on:\n",
            "...support_debug.ipynb to target folder: ./folderOnColab\n",
            "...verified copy.\n",
            "...importing code.\n",
            "...support_functions.ipynb to target folder: ./folderOnColab\n",
            "...verified copy.\n",
            "...importing code.\n"
          ]
        }
      ],
      "source": [
        "#!rm -rf ./folderOnColab && echo \"Ok, removed.\" || { echo \"No folder to remove.\"; exit 1; }\n",
        "#!mkdir -p ./folderOnColab && echo \"Folder created.\" || { echo \"Failed to create folder, it might already exist.\";  }\n",
        "#!gsutil -m cp -r gs://usfs-gcp-rand-test-data-usc1/public_source/jbooks/ANewHope.txt ./folderOnColab\n",
        "\n",
        "target_folder=\"./folderOnColab\"\n",
        "target_repo=\"https://raw.githubusercontent.com//christophergarthwood/jbooks/main\"\n",
        "target_files=[\"support_debug.ipynb\", \"support_functions.ipynb\"]\n",
        "print(f\"Creating a folder ({target_folder}) to store project data.\")\n",
        "subprocess.run([\"mkdir\", \"-p\" , target_folder])\n",
        "if os.path.isdir(target_folder):\n",
        "  print(\"Performing wget on:\")\n",
        "  for idx, filename in enumerate(target_files):\n",
        "    print(f\"...{filename} to target folder: {target_folder}\")\n",
        "    try:\n",
        "      subprocess.run([\"wget\", f\"--directory-prefix={target_folder}\", f\"{target_repo}/{filename}\"])\n",
        "    except Exception as e:\n",
        "      print(\"\")\n",
        "      print(f\"ERROR: There was a problem performing wget on the target file ({filename}), see Exception: {str(e)}\")\n",
        "      print(\"...talk to the instructor.\")\n",
        "    if os.path.isfile(target_folder+os.sep+filename):\n",
        "      print(\"...verified copy.\")\n",
        "      print(\"...importing code.\")\n",
        "      target_filename=f\"{target_folder+os.sep+filename}\"\n",
        "      os.environ[\"target_filename\"]=target_filename\n",
        "      %run $target_filename\n",
        "    else:\n",
        "      print(f\"...copy NOT verified, check the {target_folder} for the existence of {filename}\")\n",
        "else:\n",
        "    print(\"ERROR: Local folder not found/created.  Check the output to ensure your folder is created.\")\n",
        "    print(f\"...target folder: {target_folder}\")\n",
        "    print(\"...if you can't find the problem contact the instructor.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Library (Pandas/Numpy) Configuration"
      ],
      "metadata": {
        "id": "EASg3yWx_WWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "msg_info(\"Setting Library Configuration\")\n",
        "set_library_configuration()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcnYnKWv_Y7d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724800124745,
          "user_tz": 300,
          "elapsed": 194,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "2c457b1f-2d51-4e75-c90d-2ef16f83e376"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:08:44 UTC]    INFO: Setting Library Configuration \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:msg_logs:Setting Library Configuration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_CASEfG--J8"
      },
      "source": [
        "# Variable declaration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jVuTo7WT--J8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724800124746,
          "user_tz": 300,
          "elapsed": 8,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "############################################\n",
        "# GLOBAL VARIABLES\n",
        "############################################\n",
        "DEBUG = 1\n",
        "DEBUG_DATA = 0\n",
        "\n",
        "# CODE CONSTRAINTS\n",
        "VERSION_NAME    = \"NCODA_PREQC\"\n",
        "VERSION_MAJOR   = 0\n",
        "VERSION_MINOR   = 0\n",
        "VERSION_RELEASE = 1\n",
        "\n",
        "#used for values outside standard ASCII, just do it, you'll need it\n",
        "ENCODING  =\"utf-8\"\n",
        "\n",
        "############################################\n",
        "# GLOBAL CONSTANTS\n",
        "############################################\n",
        "\n",
        "\n",
        "############################################\n",
        "# APPLICATION VARIABLES\n",
        "############################################\n",
        "\n",
        "#variable persistence\n",
        "today = datetime.today()\n",
        "\n",
        "############################################\n",
        "# GLOBAL CONFIGURATION\n",
        "############################################\n",
        "os.environ['PYTHONIOENCODING']=ENCODING\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTzipAUj--J8"
      },
      "source": [
        "# Check your library versions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEMGqu1k--J8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724800124746,
          "user_tz": 300,
          "elapsed": 7,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "8b95faed-a4c9-45bb-e098-381eb5cd2138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:08:44 UTC]    INFO: Library Diagnostics \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:msg_logs:Library Diagnostics\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matplotlib                              #: 3.7.1               \n",
            "numpy                                   #: 1.26.4              \n",
            "pandas                                  #: 2.1.4               \n",
            "seaborn                                 #: 0.13.1              \n",
            "xarray                                  #: 2024.6.0            \n"
          ]
        }
      ],
      "source": [
        "msg_info(\"Library Diagnostics\")\n",
        "lib_diagnostics()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "lHEJ8La1_kPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -rf ./folderOnColab && echo \"Ok, removed.\" || { echo \"No folder to remove.\"; exit 1; }\n",
        "#!mkdir -p ./folderOnColab && echo \"Folder created.\" || { echo \"Failed to create folder, it might already exist.\";  }\n",
        "#!gsutil -m cp -r gs://usfs-gcp-rand-test-data-usc1/public_source/jbooks/ANewHope.txt ./folderOnColab\n",
        "\n",
        "target_folder=\"./folderOnColab\"\n",
        "target_files=[\"merged.2020032.0201.L5.6D.a_490_lmi.nc_202001270400_a_490_lmi_2.out\"]\n",
        "print(f\"Creating a folder ({target_folder}) to store project data.\")\n",
        "subprocess.run([\"mkdir\", \"-p\" , target_folder])\n",
        "if os.path.isdir(target_folder):\n",
        "  for idx, filename in enumerate(target_files):\n",
        "    print(f\"Copying {filename} to target folder: {target_folder}\")\n",
        "    subprocess.run([\"gsutil\", \"-m\" , \"cp\", \"-r\", f\"gs://{BUCKET_NAME}/public_source/jbooks/{filename}\",  target_folder], check=True)\n",
        "else:\n",
        "    print(\"ERROR: Local folder not found/created.  Check the output to ensure your folder is created.\")\n",
        "    print(f\"...target folder: {target_folder}\")\n",
        "    print(\"...if you can't find the problem contact the instructor.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJuESvzI_lTl",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724800134879,
          "user_tz": 300,
          "elapsed": 10137,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "7d73b201-f916-4735-923a-54b88939c246"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating a folder (./folderOnColab) to store project data.\n",
            "Copying merged.2020032.0201.L5.6D.a_490_lmi.nc_202001270400_a_490_lmi_2.out to target folder: ./folderOnColab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBk6SmMD--J8"
      },
      "source": [
        "# GOPS Parser Slice Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "H_QP0BIJ--J8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724800134879,
          "user_tz": 300,
          "elapsed": 19,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "#################################################################################\n",
        "#CONSTANTS\n",
        "#################################################################################\n",
        "\n",
        "#Notice that this is a 300 MB binary file which is NOT included in these training sets.\n",
        "DATA_DIR=Path(target_folder+os.sep)\n",
        "\n",
        "#NRL employees\n",
        "#DATA_DIR=Path(\"/u/yamm/cwood/outgoing/VISOR\")\n",
        "\n",
        "DATA_FILE=[\"merged.2020032.0201.L5.6D.a_490_lmi.nc_202001270400_a_490_lmi_2.out\"]\n",
        "\n",
        "#each record in FORTRAN \"bounded\" by a value that specifies how big the next block to read is hence the RB or record boundary value\n",
        "FORTRAN_RB_CHUNK_SIZE=4\n",
        "\n",
        "#expressly defining data types as the original FORTRAN implementation is specific as well\n",
        "FORTRAN_INT_CHUNK_SIZE=4\n",
        "FORTRAN_REAL_CHUNK_SIZE=4\n",
        "DATA_CHUNK=0\n",
        "ENDIANESS='big'\n",
        "\n",
        "#Data formatting (least significant digit)\n",
        "LSD=4\n",
        "\n",
        "#Geospatial filter criteria, known for this specific data file (Gulf of Mexico)\n",
        "FLTR_NW_LAT=31.0519\n",
        "FLTR_NW_LON=-98.4798\n",
        "FLTR_SE_LAT=19.2310\n",
        "FLTR_SE_LON=-80.9669\n",
        "FLTR_DATA = (\"lat > \" + str(FLTR_SE_LAT) + \" & lat < \" + str(FLTR_NW_LAT) + \" & lon > \" + str(FLTR_NW_LON) + \" & lon < \" + str(FLTR_SE_LON) )\n",
        "\n",
        "#define data structure of the NCODA-PreQC/VISOR output\n",
        "preQC_datatype=np.dtype([('frb_nrec1', '>i4'),\n",
        "                         ('nrec','>i4'),\n",
        "                         ('frb_nrec2', '>i4'),\n",
        "                         ('frb_dtype1', '>i4'),\n",
        "                         ('dtype','>i4'),\n",
        "                         ('frb_dtype2', '>i4'),\n",
        "                         ('frb_dtg1', '>i4'),\n",
        "                         ('dtg','>a12'),\n",
        "                         ('frb_dtg2', '>i4')\n",
        "                        ])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create a function for dynamic Polygon creation\n",
        "def get_polygon(df, offset):\n",
        "    #find the geographic boundaries of the total dataset\n",
        "    bounds_df = df.bounds\n",
        "    nlat = bounds_df['maxy'].max() + offset\n",
        "    slat = bounds_df['miny'].max() - offset\n",
        "    elon = bounds_df['maxx'].max() + offset\n",
        "    wlon = bounds_df['minx'].max() - offset\n",
        "    #report those boundaries\n",
        "    msg_info(\"------------------------ COORDINATES ------------------------\")\n",
        "    msg_debug(\"  Northern Latitude:{:8.4f}\".format(nlat))\n",
        "    msg_debug(\"  Southern Latitude:{:8.4f}\".format(slat))\n",
        "    msg_debug(\" Northern Longitude:{:8.4f}\".format(wlon))\n",
        "    msg_debug(\" Northern Longitude:{:8.4f}\".format(elon))\n",
        "    msg_debug(\" Polygon( [ ({:8.4f},{:8.4f}), ({:8.4f},{:8.4f}), ({:8.4f},{:8.4f}), ({:8.4f},{:8.4f}), ({:8.4f},{:8.4f}) ])\".format(wlon,nlat,wlon,slat,elon,slat,elon,nlat,wlon,nlat))\n",
        "    #create a polygon for highlighting the data\n",
        "    #polygon = Polygon([(0, 0), (0, 90), (180, 90), (180, 0), (0, 0)])\n",
        "    polygon = Polygon([ (wlon,nlat), (wlon,slat), (elon,slat), (elon,nlat), (wlon,nlat) ])\n",
        "    #poly_gdf = geopandas.GeoDataFrame([1], geometry=[polygon], crs=world.crs)\n",
        "    poly_gdf = gd.GeoDataFrame([1], geometry=[polygon], crs=df.crs)\n",
        "\n",
        "    return poly_gdf"
      ],
      "metadata": {
        "id": "7CD-vAweC_Dj",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724800134879,
          "user_tz": 300,
          "elapsed": 18,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "H04r4N1f--J8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724800134879,
          "user_tz": 300,
          "elapsed": 17,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "#################################################################################\n",
        "#Mapping routines to show where data resides (leaves much to be desired and\n",
        "#doesn't make use of 008_mapping*.ipynb.\n",
        "#################################################################################\n",
        "def show_map_coverage(inc_dataframe):\n",
        "\n",
        "  TARGET_DATAFRAME = inc_dataframe\n",
        "\n",
        "  central_longitude = np.median(TARGET_DATAFRAME[\"lon\"])\n",
        "  central_latitude = np.median(TARGET_DATAFRAME[\"lat\"])\n",
        "  west = np.min(TARGET_DATAFRAME[\"lon\"]) - 1.5\n",
        "  east = np.max(TARGET_DATAFRAME[\"lon\"]) + 1.5\n",
        "  north = np.max(TARGET_DATAFRAME[\"lat\"]) + 1.5\n",
        "  south = np.min(TARGET_DATAFRAME[\"lat\"]) - 1.5\n",
        "\n",
        "  #let's define some basic variables\n",
        "  highlight_box='red'\n",
        "  highlight_color='blue'\n",
        "  color_map='Spectral'\n",
        "  focus_area='Gulf of Mexico'\n",
        "  offset=5                    #degrees\n",
        "  show_plot=1\n",
        "  target_column=\"optics\"\n",
        "\n",
        "  #labeling\n",
        "  # Add a text annotation for the license information to the bottom right corner.\n",
        "  font_size=8\n",
        "  SOURCE = 'Natural Earth'\n",
        "  LICENSE = 'public domain'\n",
        "  text = AnchoredText(r'$\\mathcircled{{c}}$ {}; license: {}'\n",
        "                      ''.format(SOURCE, LICENSE),\n",
        "                      loc=4, prop={'size': font_size}, frameon=True)\n",
        "\n",
        "\n",
        "  #GeoDataFrame needs a shapely object. We use geopandas points_from_xy() to transform Longitude and Latitude into a list of shapely.Point objects and set it as a geometry while creating the GeoDataFrame.\n",
        "  gdf = gd.GeoDataFrame(TARGET_DATAFRAME, geometry=gd.points_from_xy(TARGET_DATAFRAME.Longitude, TARGET_DATAFRAME.Latitude))\n",
        "  #let's make the coordinate system explicit, normally you don't have to if showing data quickly\n",
        "  gdf.crs = \"EPSG:3857\"\n",
        "\n",
        "  #create a polygon to \"bound\" the data graphically\n",
        "  poly_gdf=get_polygon(gdf, offset)\n",
        "\n",
        "  fig1=plt.figure(figsize=(8.5,11))\n",
        "  fig1.suptitle('Optics from Binary File')\n",
        "\n",
        "  ############################################\n",
        "  # AX2, Upper right\n",
        "  ############################################\n",
        "  from cartopy.io.img_tiles import Stamen\n",
        "  tiler=Stamen('terrain-background')\n",
        "\n",
        "  ax2=fig1.add_subplot(1,1,1, projection=ccrs.PlateCarree())\n",
        "  ax2.set_title(\"Gulf of Mexico\");\n",
        "\n",
        "  increased_offset=10\n",
        "  boundary=gdf\n",
        "  #Western Longitude,\n",
        "  ax2.set_extent([boundary.total_bounds[0]-increased_offset, boundary.total_bounds[2]+increased_offset, boundary.total_bounds[1]-increased_offset, boundary.total_bounds[3]+increased_offset], crs=ccrs.PlateCarree())\n",
        "  xlim = ([boundary.total_bounds[0]-increased_offset,  boundary.total_bounds[2]+increased_offset])\n",
        "  ylim = ([boundary.total_bounds[1]-increased_offset,  boundary.total_bounds[3]+increased_offset])\n",
        "  ax2.set_xlim(xlim)\n",
        "  ax2.set_ylim(ylim)\n",
        "  #6 = terrain, it's in the example, no idea\n",
        "  ax2.add_image(tiler,6)\n",
        "  ax2.coastlines('10m')\n",
        "  ax2.add_feature(cfeature.LAND)\n",
        "  ax2.add_feature(cfeature.OCEAN)\n",
        "  ax2.add_feature(cfeature.COASTLINE)\n",
        "  ax2.add_feature(cfeature.BORDERS, linestyle=':')\n",
        "  ax2.add_feature(cfeature.LAKES, alpha=0.5)\n",
        "  ax2.add_feature(cfeature.RIVERS)\n",
        "\n",
        "  gdf.plot(ax=ax2, color=highlight_color)\n",
        "  poly_gdf=get_polygon(gdf, 1)\n",
        "  poly_gdf.boundary.plot(ax=ax2, color=highlight_box)\n",
        "\n",
        "  plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfCiY_NF--J8",
        "outputId": "2f7a66a7-8740-4438-9a00-da41dd0d5db2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:26 UTC]   DEBUG: Processing 202001270400a for folderOnColab/merged.2020032.0201.L5.6D.a_490_lmi.nc_202001270400_a_490_lmi_2.out \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:msg_logs:Processing 202001270400a for folderOnColab/merged.2020032.0201.L5.6D.a_490_lmi.nc_202001270400_a_490_lmi_2.out\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:26 UTC]   DEBUG: [(4, 26154810, 4, 4, 219, 4, 12, b'202001270400', 12)] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:msg_logs:[(4, 26154810, 4, 4, 219, 4, 12, b'202001270400', 12)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:26 UTC]   DEBUG: Total records to read in for each array:26154810 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:msg_logs:Total records to read in for each array:26154810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:26 UTC]   DEBUG: Total bytes to read in for each array:[104619240] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:msg_logs:Total bytes to read in for each array:[104619240]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:26 UTC]    INFO: ...processing lat data from PreQC \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:msg_logs:...processing lat data from PreQC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:28 UTC]   DEBUG: ......statistics: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:msg_logs:......statistics:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:28 UTC]   DEBUG: .........min:-74.99 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:msg_logs:.........min:-74.99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:28 UTC]   DEBUG: .........max:50.31 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:msg_logs:.........max:50.31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:28 UTC]   DEBUG: ........mean:-12.222337 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:msg_logs:........mean:-12.222337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:28 UTC]   DEBUG: Lat size:26154810 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:msg_logs:Lat size:26154810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:28 UTC]    INFO: ...processing lon data from PreQC \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:msg_logs:...processing lon data from PreQC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:29 UTC]   DEBUG: ......statistics: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:msg_logs:......statistics:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:29 UTC]   DEBUG: .........min:-100.0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:msg_logs:.........min:-100.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:29 UTC]   DEBUG: .........max:-60.01 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:msg_logs:.........max:-60.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:29 UTC]   DEBUG: ........mean:-82.78701 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:msg_logs:........mean:-82.78701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:29 UTC]   DEBUG: Lon size:26154810 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:msg_logs:Lon size:26154810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:29 UTC]    INFO: ...processing optics data from PreQC \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:msg_logs:...processing optics data from PreQC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:30 UTC]   DEBUG: ......statistics: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:msg_logs:......statistics:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:30 UTC]   DEBUG: .........min:0.00069999695 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:msg_logs:.........min:0.00069999695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:30 UTC]   DEBUG: .........max:3.266 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:msg_logs:.........max:3.266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:31 UTC]   DEBUG: ........mean:0.034290344 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:msg_logs:........mean:0.034290344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:31 UTC]   DEBUG: Optics size:26154810 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:msg_logs:Optics size:26154810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:33 UTC]   DEBUG: Original dataset shape:(26154810, 5) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:msg_logs:Original dataset shape:(26154810, 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:33 UTC]   DEBUG:    GOMEX dataset shape:(1433620, 5) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:msg_logs:   GOMEX dataset shape:(1433620, 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:33 UTC]   DEBUG:    GOMEX lat dimension:1433620 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:msg_logs:   GOMEX lat dimension:1433620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-27 23:12:33 UTC]   DEBUG:    GOMEX lon dimension:1433620 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:msg_logs:   GOMEX lon dimension:1433620\n"
          ]
        }
      ],
      "source": [
        "#loop through the datafiles provided\n",
        "for file in DATA_FILE:\n",
        "    target_input_file=Path(DATA_DIR / file)\n",
        "    netcdf_filename=Path(DATA_DIR / str(file + \".nc\") )\n",
        "\n",
        "    #meta-data capture from filename (merged_2019317_201911130400_a_490_lmi_2)\n",
        "    file_meta_data = file.split('_')\n",
        "    product_name=\"\".join(file_meta_data[3:5:1])\n",
        "    msg_debug(\"Processing \" + str(product_name) + \" for \"+ str(target_input_file))\n",
        "\n",
        "    in_file=open(target_input_file, 'rb')\n",
        "\n",
        "    #################################################################################\n",
        "    #Binary read using the pre-defined structure\n",
        "    #################################################################################\n",
        "    x=np.fromfile(in_file, dtype=preQC_datatype,count=1)\n",
        "    DATA_CHUNK= FORTRAN_REAL_CHUNK_SIZE * x['nrec']\n",
        "    msg_debug(x)\n",
        "    msg_debug(\"Total records to read in for each array:\"+str(x['nrec'][0]))\n",
        "    msg_debug(\"Total bytes to read in for each array:\"+str(DATA_CHUNK))\n",
        "\n",
        "    number_records=str(x['nrec'][0])\n",
        "    array_structure=\">\"+ number_records +\"f4\"\n",
        "    array_dtype=np.dtype([('frb_ary1', '>i4'),('array',array_structure),('frb_ary2', '>i4')])\n",
        "\n",
        "    msg_info(\"...processing lat data from PreQC\")\n",
        "    y=np.fromfile(in_file, dtype=array_dtype,count=1)\n",
        "    array=y['array']\n",
        "    msg_debug(\"......statistics:\")\n",
        "    msg_debug(\".........min:\" + str(np.nanmin(array)))\n",
        "    msg_debug(\".........max:\" + str(np.nanmax(array)))\n",
        "    msg_debug(\"........mean:\" + str(np.nanmean(array)))\n",
        "    lat=np.array(array).byteswap().newbyteorder()\n",
        "    msg_debug(\"Lat size:\"+str(lat.size))\n",
        "\n",
        "    msg_info(\"...processing lon data from PreQC\")\n",
        "    y=np.fromfile(in_file, dtype=array_dtype,count=1)\n",
        "    array=y['array']\n",
        "    msg_debug(\"......statistics:\")\n",
        "    msg_debug(\".........min:\" + str(np.nanmin(array)))\n",
        "    msg_debug(\".........max:\" + str(np.nanmax(array)))\n",
        "    msg_debug(\"........mean:\" + str(np.nanmean(array)))\n",
        "    lon=np.array(array).byteswap().newbyteorder()\n",
        "    msg_debug(\"Lon size:\"+str(lon.size))\n",
        "\n",
        "    msg_info(\"...processing optics data from PreQC\")\n",
        "    y=np.fromfile(in_file, dtype=array_dtype,count=1)\n",
        "    array=y['array']\n",
        "    msg_debug(\"......statistics:\")\n",
        "    msg_debug(\".........min:\" + str(np.nanmin(array)))\n",
        "    msg_debug(\".........max:\" + str(np.nanmax(array)))\n",
        "    msg_debug(\"........mean:\" + str(np.nanmean(array)))\n",
        "    optics=np.array(array).byteswap().newbyteorder()\n",
        "    msg_debug(\"Optics size:\"+str(optics.size))\n",
        "\n",
        "    #################################################################################\n",
        "    #casting data-types from float 32 to int64 to support .query operation\n",
        "    #################################################################################\n",
        "    df=pd.DataFrame({'lat':lat[0,:], 'lon':lon[0,:], 'optics':optics[0,:]})\n",
        "    lat=df['lat']\n",
        "    df['lat'] = lat.astype('float', copy=True)\n",
        "    lon=df['lon']\n",
        "    df['lon'] = lon.astype('float', copy=True)\n",
        "    optics=df['optics']\n",
        "    df['optics'] = optics.astype('float', copy=True)\n",
        "\n",
        "    df['Latitude']=df['lat']\n",
        "    df['Longitude']=df['lon']\n",
        "\n",
        "    #################################################################################\n",
        "    #Pandas, filtering data down to focal area\n",
        "    #################################################################################\n",
        "    GOMEX=df.query(FLTR_DATA)\n",
        "\n",
        "    #################################################################################\n",
        "    #Debug output showing data reduction due to the filter\n",
        "    #################################################################################\n",
        "    msg_debug(\"Original dataset shape:\"+ str(df.shape))\n",
        "    msg_debug(\"   GOMEX dataset shape:\"+ str(GOMEX.shape))\n",
        "    msg_debug(\"   GOMEX lat dimension:\" + str(GOMEX['lat'].size))\n",
        "    msg_debug(\"   GOMEX lon dimension:\" + str(GOMEX['lon'].size))\n",
        "\n",
        "    #################################################################################\n",
        "    #Create a map showing the total swath of the output\n",
        "    #################################################################################\n",
        "    show_map_coverage(df)\n",
        "    #################################################################################\n",
        "    #Create a map showing the filtered data set and focal point of analysis\n",
        "    #################################################################################\n",
        "    show_map_coverage(GOMEX)\n",
        "\n",
        "    #################################################################################\n",
        "    #Clean up unused variables\n",
        "    #################################################################################\n",
        "    del x\n",
        "    del array\n",
        "    del lat\n",
        "    del lon\n",
        "    del optics\n",
        "    del df\n",
        "\n",
        "    #################################################################################\n",
        "    # NetCDF build after marshaling data.\n",
        "    #################################################################################\n",
        "    inc_lat_dim = GOMEX['lat'].size\n",
        "    inc_lon_dim = GOMEX['lon'].size\n",
        "\n",
        "    #close data file read in\n",
        "    in_file.close()\n",
        "\n",
        "    #################################################################################\n",
        "    #NetCDF global attributes\n",
        "    #################################################################################\n",
        "    dataset = netcdf.netcdf_file(netcdf_filename, \"w\")\n",
        "    meta_data_input=\"Visible Band Satellite Data to Improve Ocean Model Radiative Transfer (VISOR)\"\n",
        "    dataset.title = meta_data_input.encode(ENCODING, errors='ignore').strip()\n",
        "    meta_data_input=\"Test validation for \" + str(file)\n",
        "    dataset.subtitle = meta_data_input.encode(ENCODING, errors='ignore')\n",
        "    meta_data_input=\"Created with Jupyter Lab, NetCDF4 libraries, GOPS VISOR Parser input file.\"\n",
        "    dataset.description = meta_data_input.encode(ENCODING, errors='ignore')\n",
        "    meta_data_input=\"Created \" + today.strftime(\"%d/%m/%y\")\n",
        "    dataset.history = meta_data_input.encode(ENCODING, errors='ignore')\n",
        "\n",
        "\n",
        "    #################################################################################\n",
        "    #NetCDF dimension declaration\n",
        "    #################################################################################\n",
        "    lat_dim = dataset.createDimension(\"lat\", inc_lat_dim)\n",
        "    lon_dim = dataset.createDimension(\"lon\", inc_lon_dim)\n",
        "    optics_dim = dataset.createDimension(\"optics\", inc_lon_dim)\n",
        "    x_dim = dataset.createDimension(\"x\", inc_lat_dim)\n",
        "    y_dim = dataset.createDimension(\"y\", inc_lon_dim)\n",
        "\n",
        "\n",
        "    #NetCDF Variable creation and data assignment\n",
        "    #################################################################################\n",
        "    # Latitude\n",
        "    #################################################################################\n",
        "    lat_reference = dataset.createVariable(\"lat\", \"f8\", (\"lat\",))\n",
        "    lat_reference.units=\"degrees north\"\n",
        "    lat_reference[:] = GOMEX['lat']\n",
        "\n",
        "    #################################################################################\n",
        "    # Longitude\n",
        "    #################################################################################\n",
        "    lon_reference = dataset.createVariable(\"lon\", \"f8\", (\"lon\",))\n",
        "    lon_reference.units=\"degrees east\"\n",
        "    lon_reference[:] = GOMEX['lon']\n",
        "\n",
        "    #################################################################################\n",
        "    # Optics Data\n",
        "    #################################################################################\n",
        "    optics_reference = dataset.createVariable(\"optics\", \"f8\", (\"optics\",))\n",
        "    optics_reference[:] = GOMEX['optics']\n",
        "    optics_reference.units=\"m^-1\"\n",
        "    optics_reference.warning = str(product_name) + \" generated from GOPS Parser, originated from GOPS processing system.\"\n",
        "\n",
        "    dataset.close()\n",
        "    msg_info(\" \")\n",
        "    msg_info(\"#####################################################################################################################\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DTIEVLHKHKfq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "name": "009_BinaryReadOf_NCODAPreQC.ipynb"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}