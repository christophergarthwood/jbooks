##############################################
#- GitHub Codespaces
##############################################
#if [[ -z "${CODESPACES}" ]]; then
#    export CODESPACE_ORIGIN="172.178.50.60";
#else
#    export CODESPACE_ORIGIN=${hostname};
#fi

export CODESPACE_ORIGIN=${hostname};
export CODESPACE_IP_ADDR="0.0.0.0";
export CODESPACE_PORT="8080";

##############################################
#- Anaconda
##############################################

export PARENT_DIR="$(pwd)";
export THE_ROOT="$(dirname ${PARENT_DIR})"
export PROJECT_DIR="${THE_ROOT}/jbooks";
#if [[ -z "${CODESPACES}" ]]; then
#    export THE_ROOT="/projects/work/chris";
#    export PROJECT_DIR="${THE_ROOT}/usda_jbooks";
#else
#    export THE_ROOT="/workspaces";
#    export PROJECT_DIR="${THE_ROOT}/jbooks";
#fi

echo "##############################################################";
echo "Root folder: ${THE_ROOT}";
echo "##############################################################";

export CONDA_ENV="machine_learning_gpu";
export CONDA_ENV_NAME="${CONDA_ENV}";
export CONDA_DIR="/opt/conda";
export CONDA_EXE="";
export CONDA_PROFILE="${CONDA_DIR}/etc/profile.d/conda.sh";
export JUPYTER_EXE="${CONDA_DIR}/envs/${CONDA_ENV}/bin/jupyter lab";
export PAPERMILL_EXE="${CONDA_DIR}/envs/${CONDA_ENV}/bin/papermill";
export CONDA_LINK="/etc/profile.d/conda.sh";
#export THE_ANACONDA_ENV="${PROJECT_DIR}/environment/environment.yml";
#export THE_ANACONDA_ENV="${PROJECT_DIR}/environment/archless_environment.yml";
export THE_ANACONDA_ENV=( archless_environment );

##############################################
#- Misc
##############################################
export THE_GID="1066";
export THE_GROUP="conda";
export THE_APP="conda";
export PYTHON_VERSION="3.9";
export THE_DIRS=( data logs tmp );
#export GOOGLE_FILE_ID="1vSq-KCfEL_KoxdE4lxeO2rEKU77kiEkR";
export GOOGLE_FILE_ID="1imWsvo5svRmDAblJCdru71HDYEa1d_h8";
export THE_DATA="${THE_ROOT}/data.tgz";

export THE_RC="${THE_ROOT}/.codespaces/.persistedshare/dotfiles/.bashrc";
export CONDA_EXE=""
export WGET_EXE=""
export TAR_EXE=""
export CHMOD_EXE=""
export RM_EXE=""
export CONDA_EXE="$(which conda)";
export WGET_EXE=$(which wget)
export TAR_EXE=$(which tar)
export CHMOD_EXE=$(which chmod)
export RM_EXE=$(which rm)

##############################################
#- Custom System Env Settings in support of TensorFlow
##############################################
export TF_ENABLE_ONEDNN_OPTS="1"                    #turn on OneDNN Intel Optimization, already on by default as of 2.9
export CUDA_VISIBLE_DEVICES="0"                     #turn on GPU:0, -1 means no GPU's will be used
export TF_XLA_FLAGS="--tf_xla_enable_xla_devices"   #XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear algebra that can accelerate TensorFlow models with potentially no source code changes.
export XLA_FLAGS="--xla_gpu_cuda_data_dir=/usr/local/cuda-11.8/lib64/libcudart.so.11.0"
                                                    #set explicit path for cuda libraries
