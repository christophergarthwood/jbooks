{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed training with TensorFlow\n",
    "\n",
    "**Note that this training doesn't work well with codespaces and virtualized environments as actual CPU/GPU's are not readily available.**\n",
    "\n",
    "Overview\n",
    "\n",
    "tf.distribute.Strategy is a TensorFlow API to distribute training across multiple GPUs, multiple machines or TPUs. Using this API, you can distribute your existing models and training code with minimal code changes.\n",
    "\n",
    "tf.distribute.Strategy has been designed with these key goals in mind:\n",
    "\n",
    "    Easy to use and support multiple user segments, including researchers, ML engineers, etc.\n",
    "    Provide good performance out of the box.\n",
    "    Easy switching between strategies.\n",
    "\n",
    "tf.distribute.Strategy can be used with a high-level API like Keras, and can also be used to distribute custom training loops (and, in general, any computation using TensorFlow).\n",
    "\n",
    "In TensorFlow 2.0, you can execute your programs eagerly, or in a graph using tf.function. tf.distribute.Strategy intends to support both these modes of execution. Although we discuss training most of the time in this guide, this API can also be used for distributing evaluation and prediction on different platforms.\n",
    "\n",
    "Reference: \n",
    "+ https://www.tensorflow.org/guide/distributed_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 20:57:24.196473: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "# Python 3.7.3\n",
    "############################################\n",
    "# INCLUDES\n",
    "############################################\n",
    "#libraries specific to this example\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# seed the pseudorandom number generator\n",
    "from random import seed\n",
    "from random import random\n",
    "from random import randint\n",
    "\n",
    "#a set of libraries that perhaps should always be in Python source\n",
    "import os \n",
    "import datetime\n",
    "import sys\n",
    "import gc\n",
    "import getopt\n",
    "import inspect\n",
    "import math\n",
    "import warnings\n",
    "import types\n",
    "\n",
    "#Data Science Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.ndimage\n",
    "\n",
    "#Plotting libraries\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#a darn useful library for creating paths and one I recommend you load to your environment\n",
    "from pathlib import Path\n",
    "\n",
    "# can type in the python console `help(name of function)` to get the documentation\n",
    "from pydoc import help                          \n",
    "\n",
    "#Import a custom library, in this case a fairly useful logging framework\n",
    "debug_lib_location = Path(\"./\")\n",
    "sys.path.append(str(debug_lib_location))\n",
    "import debug\n",
    "\n",
    "warnings.filterwarnings('ignore')               # don't print out warnings\n",
    "\n",
    "\n",
    "root_location=\"..\" + os.sep + \"data\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn on Eager Execution\n",
    "#tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "#JUPYTER NOTEBOOK OUTPUT CONTROL / FORMATTING\n",
    "############################################\n",
    "#set floating point to 4 places to things don't run loose\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# GLOBAL VARIABLES\n",
    "############################################\n",
    "DEBUG = 1                            #General ledger output so you know what's happening.\n",
    "DEBUG_DATA = 1                       #Extremely verbose output, change to zero (0) to supress the volume of output.\n",
    "\n",
    "# CODE CONSTRAINTS\n",
    "VERSION_NAME    = \"TensorFlowDistributed\"\n",
    "VERSION_ACRONYM = \"ML-TFDIST\"\n",
    "VERSION_MAJOR   = 0\n",
    "VERSION_MINOR   = 0\n",
    "VERSION_RELEASE = \"0b\"\n",
    "VERSION_TITLE   = VERSION_NAME + \" (\" + VERSION_ACRONYM + \") \" + str(VERSION_MAJOR) + \".\" + str(VERSION_MINOR) + \".\" + str(VERSION_RELEASE) + \" generated SEED.\"\n",
    "\n",
    "ENCODING  =\"utf-8\"\n",
    "############################################\n",
    "# GLOBAL CONSTANTS\n",
    "############################################\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "############################################\n",
    "# APPLICATION VARIABLES\n",
    "############################################\n",
    "\n",
    "############################################\n",
    "# GLOBAL CONFIGURATION\n",
    "############################################\n",
    "os.environ['PYTHONIOENCODING']=ENCODING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Function Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# WARNING / ERROR Management\n",
    "############################################\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()\n",
    "\n",
    "\n",
    "############################################\n",
    "# FUNCTIONS\n",
    "############################################\n",
    "\n",
    "def prototype(incMonth):\n",
    "\n",
    "    debug.msg_info(\"Entering {}.{}\".format(__name__, inspect.stack()[0][3]))\n",
    "    debug.msg_info(\"The month you passed in was \" + str(incMonth))\n",
    "    debug.msg_info(\"Exiting {}.{}\".format(__name__, inspect.stack()[0][3]))\n",
    "    return 1\n",
    "\n",
    "def lib_diagnostics():\n",
    "    debug.msg_debug(\"System version    #:{:>12}\".format(sys.version))\n",
    "    netcdf4_version_info = nc.getlibversion().split(\" \")\n",
    "    debug.msg_debug(\"netCDF4 version   #:{:>12}\".format(netcdf4_version_info[0]))\n",
    "    debug.msg_debug(\"Matplotlib version#:{:>12}\".format(matplt.__version__))\n",
    "    debug.msg_debug(\"Numpy version     #:{:>12}\".format(np.__version__))\n",
    "    debug.msg_debug(\"Pandas version    #:{:>12}\".format(pd.__version__))\n",
    "    debug.msg_debug(\"SciPy version     #:{:>12}\".format(sp.__version__))\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def get_full_version():\n",
    "\n",
    "    resultant = str(VERSION_NAME) + \"  v\" + str(VERSION_MAJOR) + \".\" + str(VERSION_MINOR) + \".\" + str(VERSION_RELEASE)\n",
    "    return resultant\n",
    "\n",
    "def get_version():\n",
    "\n",
    "    resultant = str(VERSION_MAJOR) + \".\" + str(VERSION_MINOR) + \".\" + str(VERSION_RELEASE)\n",
    "    return resultant\n",
    "\n",
    "def printversion():\n",
    "\n",
    "    print(get_full_version())\n",
    "\n",
    "def printusage():\n",
    "\n",
    "    print(\"\")\n",
    "    printversion()\n",
    "    print(\"  -v, --version    prints the version of this software package.\")\n",
    "    print(\"\")\n",
    "    print(\"  * - indicates required argument.\")\n",
    "\n",
    "######################################################################\n",
    "#Support routines to see columns in DataFrames\n",
    "######################################################################\n",
    "def show_columns_plain(inc_ary):\n",
    "    new_ary = []\n",
    "    for col in inc_ary:\n",
    "        new_ary.append(np.char.lower(col))\n",
    "    new_ary.sort\n",
    "    myOutputString = \" \"\n",
    "    for col in new_ary:\n",
    "        myOutputString = myOutputString + \" \" + str(col)\n",
    "    return myOutputString\n",
    "\n",
    "def show_columns_true(inc_ary):\n",
    "    new_ary = []\n",
    "    for col in inc_ary:\n",
    "        new_ary.append(col)\n",
    "    new_ary.sort\n",
    "    myOutputString = \" \"\n",
    "    for col in new_ary:\n",
    "        myOutputString = myOutputString + \" \" + str(col)\n",
    "    return myOutputString\n",
    "\n",
    "######################################################################\n",
    "#Input Validation\n",
    "######################################################################\n",
    "# valid string:\n",
    "#  We don't want the following:\n",
    "#   - at the start of the file name (might be construed as a switch)\n",
    "#  $, &, |, ;, <, >, `, !, *, \", \\ (to start with)\n",
    "###\n",
    "def validstring(testsubject):\n",
    "\n",
    "    if testsubject[0] == \"-\":\n",
    "        return 0\n",
    "    elif \"$\" in testsubject or \"&\" in testsubject or \"|\" in testsubject:\n",
    "        return 0\n",
    "    elif \";\" in testsubject or \"`\" in testsubject or \"!\" in testsubject:\n",
    "        return 0\n",
    "    elif \"*\" in testsubject or '\"' in testsubject or \"\\\\\" in testsubject:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./libs.py\n",
    "#Title:     Displays the libraries in current use.\n",
    "#Objective: Invocation is intended as function calls within another program.\n",
    "#Assumptions:\n",
    "#           1. Should be stored in standardized location such as:\n",
    "#                      /p/home/{user_name}/usr/PYTHONLIB\n",
    "#           2. Developer loads the module (Jupyter Lab).\n",
    "#Pre-Requisites:\n",
    "#           1. Python v3.*\n",
    "#           2. Jupyter Lab / Notebook (%load libs.py)\n",
    "#Usage:\n",
    "#       %load libs.py\n",
    "#       find_loaded_modules().HTML\n",
    "#\n",
    "#Version History:\n",
    "# ------------------------------------------------------------------------\n",
    "# Version   Date       Modification                              Author\n",
    "# ------------------------------------------------------------------------\n",
    "# 1.0       2020/04/29 Inception                                 Radiance\n",
    "# ------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "#LIBRARIES\n",
    "#######################################################################\n",
    "import os\n",
    "import types\n",
    "\n",
    "def module_version(mod):\n",
    "    '''Return version string for module *mod*, or nothing if\n",
    "    it doesn't have a \"version\" or \"__version__\" attribute.'''\n",
    "    version = []\n",
    "    if hasattr(mod, '__dict__'):\n",
    "        keys = []\n",
    "        for key in mod.__dict__.keys():\n",
    "            if key.lower() == 'version' or key.lower() == '__version__':\n",
    "                v = mod.__dict__[key]\n",
    "                if (str):\n",
    "                    if isinstance(v, str):\n",
    "                        version.append(v)\n",
    "                else:\n",
    "                    version.append(\"No version\")\n",
    "        if keys:\n",
    "            print (mod, keys)\n",
    "    if version:\n",
    "        return ', '.join(version)\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def find_loaded_modules(only_versioned_modules=True):\n",
    "\n",
    "    def list_of_lists_to_HTML(lists, header_row=None):\n",
    "        '''Convert a list of a list of strings to a HTML table.'''\n",
    "        s = '<table>'\n",
    "        if header_row:\n",
    "            s += '\\n\\t<tr>\\n\\t\\t'\n",
    "            s += ''.join(['<th>%s</th>' % item for item in header_row])\n",
    "            s += '\\n\\t</tr>'\n",
    "        for inner_list in lists:\n",
    "            s += '\\n\\t<tr>\\n\\t\\t'\n",
    "            s += ''.join(['<td>%s</td>' % item for item in inner_list])\n",
    "            s += '\\n\\t</tr>'\n",
    "        s += '\\n</table>'\n",
    "        return s\n",
    "    \n",
    "    class LoadedModules(list):\n",
    "        '''Very simple wrapper for a list of lists of strings, with an attribute\n",
    "        for display in IPython Notebooks.'''\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            list.__init__(self, *args, **kwargs)\n",
    "            \n",
    "        @property\n",
    "        def HTML(self):\n",
    "            from IPython.display import HTML\n",
    "            return HTML(\n",
    "                    list_of_lists_to_HTML(\n",
    "                            self, header_row=['Name', 'Version']))\n",
    "                    \n",
    "    objs = LoadedModules()\n",
    "    for i, mod in enumerate(globals().values()):\n",
    "        if isinstance(mod, types.ModuleType):\n",
    "            if hasattr(mod, '__name__'):\n",
    "                name = mod.__name__\n",
    "            else:\n",
    "                name = ''\n",
    "            \n",
    "            version = module_version(mod)\n",
    "            \n",
    "            objs.append([mod.__name__, version])\n",
    "    objs.sort(key=lambda r: r[0])\n",
    "    return objs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "\t<tr>\n",
       "\t\t<th>Name</th><th>Version</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>builtins</td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>builtins</td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>datetime</td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>debug</td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>gc</td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>getopt</td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>inspect</td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>math</td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>matplotlib</td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>matplotlib.pyplot</td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>numpy</td><td>1.23.4</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>os</td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>pandas</td><td>1.5.1</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>scipy</td><td>1.9.3</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>scipy</td><td>1.9.3</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>sys</td><td>3.9.15 (main, Nov  4 2022, 16:13:54) \n",
       "[GCC 11.2.0]</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>tensorflow</td><td>2.4.1</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>tensorflow.keras</td><td>2.4.0</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>tensorflow.keras.layers</td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>types</td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>warnings</td><td></td>\n",
       "\t</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_loaded_modules().HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of strategies\n",
    "\n",
    "tf.distribute.Strategy intends to cover a number of use cases along different axes. Some of these combinations are currently supported and others will be added in the future. Some of these axes are:\n",
    "\n",
    "+ Synchronous vs asynchronous training: These are two common ways of distributing training with data parallelism. In sync training, all workers train over different slices of input data in sync, and aggregating gradients at each step. In async training, all workers are independently training over the input data and updating variables asynchronously. Typically sync training is supported via all-reduce and async through parameter server architecture.\n",
    "+ Hardware platform: You may want to scale your training onto multiple GPUs on one machine, or multiple machines in a network (with 0 or more GPUs each), or on Cloud TPUs.\n",
    "\n",
    "See the distributed training reference at the top for details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU's\n",
    "\n",
    "References\n",
    "+ https://www.howtogeek.com/414201/how-to-check-what-graphics-card-gpu-is-in-your-pc/\n",
    "+ https://www.howtogeek.com/508993/how-to-check-which-gpu-is-installed-on-linux/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MirroredStrategy\n",
    "\n",
    "tf.distribute.MirroredStrategy supports synchronous distributed training on multiple GPUs on one machine. It creates one replica per GPU device. Each variable in the model is mirrored across all the replicas. Together, these variables form a single conceptual variable called MirroredVariable. These variables are kept in sync with each other by applying identical updates.\n",
    "\n",
    "Efficient all-reduce algorithms are used to communicate the variable updates across the devices. All-reduce aggregates tensors across all the devices by adding them up, and makes them available on each device. It’s a fused algorithm that is very efficient and can reduce the overhead of synchronization significantly. There are many all-reduce algorithms and implementations available, depending on the type of communication available between devices. By default, it uses NVIDIA NCCL as the all-reduce implementation. You can choose from a few other options we provide, or write your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 20:57:35.387565: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib:/usr/lib64::\n",
      "2022-12-16 20:57:35.387596: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-16 20:57:35.387614: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (codespaces-c62148): /proc/driver/nvidia/version does not exist\n",
      "2022-12-16 20:57:35.387833: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-16 20:57:35.395281: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2793435000 Hz\n",
      "2022-12-16 20:57:35.395664: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14d2600 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-12-16 20:57:35.395685: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "#Mirrored Strategy\n",
    "####################################################\n",
    "startegy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "####################################################\n",
    "#This will create a MirroredStrategy instance which will use all \n",
    "#the GPUs that are visible to TensorFlow, and use NCCL as the cross device communication.\n",
    "#If you wish to use only some of the GPUs on your machine, you can do so like this:\n",
    "#   mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CentralStorageStrategy\n",
    "\n",
    "tf.distribute.experimental.CentralStorageStrategy does synchronous training as well. Variables are not mirrored, instead they are placed on the CPU and operations are replicated across all local GPUs. If there is only one GPU, all variables and operations will be placed on that GPU.\n",
    "\n",
    "This will create a CentralStorageStrategy instance which will use all visible GPUs and CPU. Update to variables on replicas will be aggregated before being applied to variables.\n",
    "\n",
    "Create an instance of CentralStorageStrategy by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:ParameterServerStrategy (CentralStorageStrategy if you are using a single machine) with compute_devices = ['/job:localhost/replica:0/task:0/device:CPU:0'], variable_device = '/job:localhost/replica:0/task:0/device:CPU:0'\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "#Central Storage Strategy\n",
    "#Reference: https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/CentralStorageStrategy\n",
    "####################################################\n",
    "strategy = tf.distribute.experimental.CentralStorageStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "tf.Tensor([2 3], shape=(2,), dtype=int64)\n",
      "tf.Tensor([4 5], shape=(2,), dtype=int64)\n",
      "tf.Tensor([6 7], shape=(2,), dtype=int64)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 20:57:51.105341: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Found an unshardable source dataset: name: \"RangeDataset/_3\"\n",
      "op: \"RangeDataset\"\n",
      "input: \"Const/_0\"\n",
      "input: \"Const/_1\"\n",
      "input: \"Const/_2\"\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2022-12-16 20:57:51.128178: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10).batch(2)\n",
    "dist_dataset = strategy.experimental_distribute_dataset(dataset)\n",
    "for x in dist_dataset:\n",
    "  print(x)  # Prints PerReplica values [0, 1], [2, 3],..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiWorkerMirroredStrategy\n",
    "\n",
    "tf.distribute.experimental.MultiWorkerMirroredStrategy is very similar to MirroredStrategy. It implements synchronous distributed training across multiple workers, each with potentially multiple GPUs. Similar to MirroredStrategy, it creates copies of all variables in the model on each device across all workers.\n",
    "\n",
    "It uses CollectiveOps as the multi-worker all-reduce communication method used to keep variables in sync. A collective op is a single op in the TensorFlow graph which can automatically choose an all-reduce algorithm in the TensorFlow runtime according to hardware, network topology and tensor sizes.\n",
    "\n",
    "It also implements additional performance optimizations. For example, it includes a static optimization that converts multiple all-reductions on small tensors into fewer all-reductions on larger tensors. In addition, we are designing it to have a plugin architecture - so that in the future, you will be able to plugin algorithms that are better tuned for your hardware. Note that collective ops also implement other collective operations such as broadcast and all-gather.\n",
    "\n",
    "Here is the simplest way of creating MultiWorkerMirroredStrategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_9336/3206723324.py:4: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "use distribute.MultiWorkerMirroredStrategy instead\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/device:CPU:0',)\n",
      "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:CPU:0',), communication = CommunicationImplementation.AUTO\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "#Multi-Worker Mirrored Strategy\n",
    "####################################################\n",
    "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultiWorkerMirroredStrategy currently allows you to choose between two different implementations of collective ops. CollectiveCommunication.RING implements ring-based collectives using gRPC as the communication layer. CollectiveCommunication.NCCL uses Nvidia's NCCL to implement collectives. CollectiveCommunication.AUTO defers the choice to the runtime. The best choice of collective implementation depends upon the number and kind of GPUs, and the network interconnect in the cluster. You can specify them in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/device:CPU:0',)\n",
      "WARNING:tensorflow:Enabled NCCL communication but no GPUs detected/specified.\n",
      "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:CPU:0',), communication = CommunicationImplementation.NCCL\n"
     ]
    }
   ],
   "source": [
    "multiworker_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(\n",
    "    tf.distribute.experimental.CollectiveCommunication.NCCL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the key differences to get multi worker training going, as compared to multi-GPU training, is the multi-worker setup. The TF_CONFIG environment variable is the standard way in TensorFlow to specify the cluster configuration to each worker that is part of the cluster. Learn more about setting up TF_CONFIG.\n",
    "Note: This strategy is experimental as we are currently improving it and making it work for more scenarios. As part of this, please expect the APIs to change in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPUStrategy\n",
    "\n",
    "tf.distribute.experimental.TPUStrategy lets you run your TensorFlow training on Tensor Processing Units (TPUs). TPUs are Google's specialized ASICs designed to dramatically accelerate machine learning workloads. They are available on Google Colab, the TensorFlow Research Cloud and Cloud TPU.\n",
    "\n",
    "In terms of distributed training architecture, TPUStrategy is the same MirroredStrategy - it implements synchronous distributed training. TPUs provide their own implementation of efficient all-reduce and other collective operations across multiple TPU cores, which are used in TPUStrategy.\n",
    "\n",
    "*Note that this notebook does not devle into Collab.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ParameterServerStrategy\n",
    "\n",
    "tf.distribute.experimental.ParameterServerStrategy supports parameter servers training on multiple machines. In this setup, some machines are designated as workers and some as parameter servers. Each variable of the model is placed on one parameter server. Computation is replicated across all GPUs of all the workers.\n",
    "\n",
    "For multi worker training, TF_CONFIG needs to specify the configuration of parameter servers and workers in your cluster.\n",
    "\n",
    "In terms of code, it looks similar to other strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'cluster_resolver'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m####################################################\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#Parameter Server\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Does not execute without configuration setup\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m####################################################\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m strategy \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParameterServerStrategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'cluster_resolver'"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "#Parameter Server\n",
    "#Does not execute without configuration setup\n",
    "####################################################\n",
    "strategy = tf.distribute.experimental.ParameterServerStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up TF_CONFIG environment variable\n",
    "\n",
    "For multi-worker training, as mentioned before, you need to set TF_CONFIG environment variable for each binary running in your cluster. The TF_CONFIG environment variable is a JSON string which specifies what tasks constitute a cluster, their addresses and each task's role in the cluster. We provide a Kubernetes template in the tensorflow/ecosystem repo which sets TF_CONFIG for your training tasks.\n",
    "\n",
    "One example of TF_CONFIG is:\n",
    "\n",
    "    os.environ[\"TF_CONFIG\"] = json.dumps({\n",
    "        \"cluster\": {\n",
    "            \"worker\": [\"host1:port\", \"host2:port\", \"host3:port\"],\n",
    "            \"ps\": [\"host4:port\", \"host5:port\"]\n",
    "        },\n",
    "       \"task\": {\"type\": \"worker\", \"index\": 1}\n",
    "    })\n",
    "\n",
    "This TF_CONFIG specifies that there are three workers and two ps tasks in the cluster along with their hosts and ports. The \"task\" part specifies that the role of the current task in the cluster, worker 1 (the second worker). Valid roles in a cluster is \"chief\", \"worker\", \"ps\" and \"evaluator\". There should be no \"ps\" job except when using tf.distribute.experimental.ParameterServerStrategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneDeviceStrategy\n",
    "\n",
    "tf.distribute.OneDeviceStrategy runs on a single device. This strategy will place any variables created in its scope on the specified device. Input distributed through this strategy will be prefetched to the specified device. Moreover, any functions called via strategy.run will also be placed on the specified device.\n",
    "\n",
    "You can use this strategy to test your code before switching to other strategies which actually distributes to multiple devices/machines.\n",
    "\n",
    "So far we've talked about what are the different strategies available and how you can instantiate them. In the next few sections, we will talk about the different ways in which you can use them to distribute your training. We will show short code snippets in this guide and link off to full tutorials which you can run end to end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using tf.distribute.Strategy with Keras\n",
    "\n",
    "We've integrated tf.distribute.Strategy into tf.keras which is TensorFlow's implementation of the Keras API specification. tf.keras is a high-level API to build and train models. By integrating into tf.keras backend, we've made it seamless for you to distribute your training written in the Keras training framework.\n",
    "\n",
    "Here's what you need to change in your code:\n",
    "\n",
    "    Create an instance of the appropriate tf.distribute.Strategy\n",
    "    Move the creation and compiling of Keras model inside strategy.scope.\n",
    "\n",
    "We support all types of Keras models - sequential, functional and subclassed.\n",
    "\n",
    "Here is a snippet of code to do this for a very simple Keras model with one dense layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "with mirrored_strategy.scope():\n",
    "  model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])\n",
    "  model.compile(loss='mse', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we used MirroredStrategy so we can run this on a machine with multiple GPUs. strategy.scope() indicated which parts of the code to run distributed. Creating a model inside this scope allows us to create mirrored variables instead of regular variables. Compiling under the scope allows us to know that the user intends to train this model using this strategy. Once this is set up, you can fit your model like you would normally. MirroredStrategy takes care of replicating the model's training on the available GPUs, aggregating gradients, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 20:58:50.107445: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Found an unshardable source dataset: name: \"TensorDataset/_2\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10/10 [==============================] - 1s 803us/step - loss: 0.2328\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 0s 721us/step - loss: 0.1029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 20:58:51.575217: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Found an unshardable source dataset: name: \"TensorDataset/_2\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 773us/step - loss: 0.0546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05456290394067764"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100).batch(10)\n",
    "model.fit(dataset, epochs=2)\n",
    "model.evaluate(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's supported now?\n",
    "\n",
    "In TF 2.0 release, MirroredStrategy, TPUStrategy, CentralStorageStrategy and MultiWorkerMirroredStrategy are supported in Keras. Except **MirroredStrategy**, others are currently experimental and are subject to change. Support for other strategies will be coming soon. The API and how to use will be exactly the same as above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Distributed training with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The tf.distribute.Strategy API provides an abstraction for distributing your training across multiple processing units. The goal is to allow users to enable distributed training using existing models and training code, with minimal changes.\n",
    "\n",
    "This tutorial uses the tf.distribute.MirroredStrategy, which does in-graph replication with synchronous training on many GPUs on one machine. Essentially, it copies all of the model's variables to each processor. Then, it uses all-reduce to combine the gradients from all processors and applies the combined value to all copies of the model.\n",
    "\n",
    "**MirroredStrategy** is one of several distribution strategy available in TensorFlow core. You can read about more strategies at distribution strategy guide.\n",
    "\n",
    "Reference:\n",
    "+ https://www.tensorflow.org/tutorials/distribute/keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Important:***\n",
    "\n",
    "    conda install -c conda-forge tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfds\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m tfds\u001b[38;5;241m.\u001b[39mdisable_progress_bar()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_datasets'"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the MNIST dataset and load it from TensorFlow Datasets. This returns a dataset in tf.data format.\n",
    "\n",
    "Setting with_info to True includes the metadata for the entire dataset, which is being saved here to info. Among other things, this metadata object includes the number of train and test examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset mnist (11.06 MiB) to C:\\Users\\ChristopherWood2\\tensorflow_datasets\\mnist\\1.0.0...\n",
      "WARNING:tensorflow:From C:\\Users\\ChristopherWood2\\Anaconda3\\envs\\machine_learning\\lib\\site-packages\\tensorflow_datasets\\core\\file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ChristopherWood2\\Anaconda3\\envs\\machine_learning\\lib\\site-packages\\tensorflow_datasets\\core\\file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset mnist downloaded and prepared to C:\\Users\\ChristopherWood2\\tensorflow_datasets\\mnist\\1.0.0. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
    "\n",
    "mnist_train, mnist_test = datasets['train'], datasets['test']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define distribution strategy\n",
    "\n",
    "Create a MirroredStrategy object. This will handle distribution, and provides a context manager (tf.distribute.MirroredStrategy.scope) to build your model inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup input pipeline\n",
    "\n",
    "When training a model with multiple GPUs, you can use the extra computing power effectively by increasing the batch size. In general, use the largest batch size that fits the GPU memory, and tune the learning rate accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also do info.splits.total_num_examples to get the total\n",
    "# number of examples in the dataset.\n",
    "\n",
    "num_train_examples = info.splits['train'].num_examples\n",
    "num_test_examples = info.splits['test'].num_examples\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "BATCH_SIZE_PER_REPLICA = 64\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pixel values, which are 0-255, have to be normalized to the 0-1 range. Define this scale in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image /= 255\n",
    "\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply this function to the training and test data, shuffle the training data, and batch it for training. Notice we are also keeping an in-memory cache of the training data to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "Create and compile the Keras model in the context of strategy.scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dense(10)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the callbacks\n",
    "\n",
    "The callbacks used here are:\n",
    "\n",
    "   + TensorBoard: This callback writes a log for TensorBoard which allows you to visualize the graphs.\n",
    "   + Model Checkpoint: This callback saves the model after every epoch.\n",
    "   + Learning Rate Scheduler: Using this callback, you can schedule the learning rate to change after every epoch/batch.\n",
    "\n",
    "For illustrative purposes, add a print callback to display the learning rate in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the checkpoint directory to store the checkpoints\n",
    "\n",
    "checkpoint_dir = '.'+os.sep+'tmp'+os.sep+'training_checkpoints'\n",
    "!mkdir {checkpoint_dir}\n",
    "\n",
    "\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback for printing the LR at the end of each epoch.\n",
    "class PrintLR(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n",
    "                                                      model.optimizer.lr.numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='.'+os.sep+'logs',\n",
    "                                   histogram_freq=0,  \n",
    "                                   embeddings_freq=0, \n",
    "                                   update_freq='epoch',\n",
    "                                   profile_batch=0),  #added this (which doesn't profile) to get the example to to work\n",
    "    \n",
    "    #When saving a model's weights, tf.keras defaults to the checkpoint format. \n",
    "    #Pass save_format='h5' to use HDF5 (or pass a filename that ends in .h5).\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "                                       #save_weights_only=True,\n",
    "                                       verbose=1),\n",
    "    PrintLR()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate\n",
    "\n",
    "Now, train the model in the usual way, calling fit on the model and passing in the dataset created at the beginning of the tutorial. This step is the same whether you are distributing the training or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    938/Unknown - 8s 9ms/step - loss: 0.1965 - accuracy: 0.9440\n",
      "Epoch 00001: saving model to .\\tmp\\training_checkpoints\\ckpt_1.h5\n",
      "\n",
      "Learning rate for epoch 1 is 0.0010000000474974513\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.1965 - accuracy: 0.9440\n",
      "Epoch 2/12\n",
      "922/938 [============================>.] - ETA: 0s - loss: 0.0667 - accuracy: 0.9802\n",
      "Epoch 00002: saving model to .\\tmp\\training_checkpoints\\ckpt_2.h5\n",
      "\n",
      "Learning rate for epoch 2 is 0.0010000000474974513\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0668 - accuracy: 0.9802\n",
      "Epoch 3/12\n",
      "925/938 [============================>.] - ETA: 0s - loss: 0.0462 - accuracy: 0.9860\n",
      "Epoch 00003: saving model to .\\tmp\\training_checkpoints\\ckpt_3.h5\n",
      "\n",
      "Learning rate for epoch 3 is 0.0010000000474974513\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0462 - accuracy: 0.9860\n",
      "Epoch 4/12\n",
      "923/938 [============================>.] - ETA: 0s - loss: 0.0354 - accuracy: 0.9894\n",
      "Epoch 00004: saving model to .\\tmp\\training_checkpoints\\ckpt_4.h5\n",
      "\n",
      "Learning rate for epoch 4 is 0.0010000000474974513\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0354 - accuracy: 0.9894\n",
      "Epoch 5/12\n",
      "920/938 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9921\n",
      "Epoch 00005: saving model to .\\tmp\\training_checkpoints\\ckpt_5.h5\n",
      "\n",
      "Learning rate for epoch 5 is 0.0010000000474974513\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0261 - accuracy: 0.9920\n",
      "Epoch 6/12\n",
      "929/938 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9936\n",
      "Epoch 00006: saving model to .\\tmp\\training_checkpoints\\ckpt_6.h5\n",
      "\n",
      "Learning rate for epoch 6 is 0.0010000000474974513\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0212 - accuracy: 0.9937\n",
      "Epoch 7/12\n",
      "930/938 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9952\n",
      "Epoch 00007: saving model to .\\tmp\\training_checkpoints\\ckpt_7.h5\n",
      "\n",
      "Learning rate for epoch 7 is 0.0010000000474974513\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0154 - accuracy: 0.9952\n",
      "Epoch 8/12\n",
      "932/938 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9961\n",
      "Epoch 00008: saving model to .\\tmp\\training_checkpoints\\ckpt_8.h5\n",
      "\n",
      "Learning rate for epoch 8 is 0.0010000000474974513\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0119 - accuracy: 0.9961\n",
      "Epoch 9/12\n",
      "932/938 [============================>.] - ETA: 0s - loss: 0.0093 - accuracy: 0.9967\n",
      "Epoch 00009: saving model to .\\tmp\\training_checkpoints\\ckpt_9.h5\n",
      "\n",
      "Learning rate for epoch 9 is 0.0010000000474974513\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0092 - accuracy: 0.9967\n",
      "Epoch 10/12\n",
      "929/938 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9978\n",
      "Epoch 00010: saving model to .\\tmp\\training_checkpoints\\ckpt_10.h5\n",
      "\n",
      "Learning rate for epoch 10 is 0.0010000000474974513\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0073 - accuracy: 0.9978\n",
      "Epoch 11/12\n",
      "929/938 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9976\n",
      "Epoch 00011: saving model to .\\tmp\\training_checkpoints\\ckpt_11.h5\n",
      "\n",
      "Learning rate for epoch 11 is 0.0010000000474974513\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0072 - accuracy: 0.9977\n",
      "Epoch 12/12\n",
      "924/938 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 00012: saving model to .\\tmp\\training_checkpoints\\ckpt_12.h5\n",
      "\n",
      "Learning rate for epoch 12 is 0.0010000000474974513\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0049 - accuracy: 0.9984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x267544f60c8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=12, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive E is Data\n",
      " Volume Serial Number is C0D8-A109\n",
      "\n",
      " Directory of E:\\Documents\\CWOOD\\projects\\my_jbooks\\tmp\\training_checkpoints\n",
      "\n",
      "09/12/2022  04:21 PM    <DIR>          .\n",
      "09/12/2022  04:21 PM    <DIR>          ..\n",
      "09/12/2022  04:20 PM         4,200,528 ckpt_1.h5\n",
      "09/12/2022  04:21 PM         4,200,528 ckpt_10.h5\n",
      "09/12/2022  04:21 PM         4,200,528 ckpt_11.h5\n",
      "09/12/2022  04:21 PM         4,200,528 ckpt_12.h5\n",
      "09/12/2022  04:21 PM         4,200,528 ckpt_2.h5\n",
      "09/12/2022  04:21 PM         4,200,528 ckpt_3.h5\n",
      "09/12/2022  04:21 PM         4,200,528 ckpt_4.h5\n",
      "09/12/2022  04:21 PM         4,200,528 ckpt_5.h5\n",
      "09/12/2022  04:21 PM         4,200,528 ckpt_6.h5\n",
      "09/12/2022  04:21 PM         4,200,528 ckpt_7.h5\n",
      "09/12/2022  04:21 PM         4,200,528 ckpt_8.h5\n",
      "09/12/2022  04:21 PM         4,200,528 ckpt_9.h5\n",
      "              12 File(s)     50,406,336 bytes\n",
      "               2 Dir(s)  304,131,563,520 bytes free\n"
     ]
    }
   ],
   "source": [
    "#See if the checkpoints are saved.\n",
    "from sys import platform\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    !ls {checkpoint_dir}\n",
    "elif platform == \"darwin\":\n",
    "    !ls {checkpoint_dir}\n",
    "elif platform == \"win32\":\n",
    "    !dir {checkpoint_dir}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how the model perform, load the latest checkpoint and call evaluate on the test data.\n",
    "\n",
    "Call evaluate as before using appropriate datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    157/Unknown - 1s 6ms/step - loss: 0.0623 - accuracy: 0.9842Eval loss: 0.062301204898187953, Eval Accuracy: 0.9842000007629395\n"
     ]
    }
   ],
   "source": [
    "#tutorials indicates to save weights only but I found this to be a problem / concern between \n",
    "#tensorflow and keras calls, so save the whole model (who cares anyway)\n",
    "#model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "#load the specific model name\n",
    "model=tf.keras.models.load_model(checkpoint_dir+os.sep+'ckpt_12.h5')\n",
    "\n",
    "\n",
    "eval_loss, eval_acc = model.evaluate(eval_dataset)\n",
    "\n",
    "print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
